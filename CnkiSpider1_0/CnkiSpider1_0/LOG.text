2018-08-01 16:49:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 16:49:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 16:49:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 16:49:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 16:49:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 16:49:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 16:49:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 16:49:40 [scrapy.core.engine] INFO: Spider opened
2018-08-01 16:49:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 16:50:19 [scrapy.core.scraper] ERROR: Error processing {'abstract': '当今世界,大数据正渗透到人类社会的方方面面,不仅改变人们的思维方式、工作方式和生活方式,改变社会的生产力与生产关系,而且成为未来的"新石油"、"新金矿"、"新资源"和创新的"新引擎"。自2012年以来,美国、英国、法国、日本、韩国等发达国家陆续将大数据上升为国家战略。经过多年的酝酿,我国2015年召开的党的十八届五中全会,明确提出"实施国家大数据战略"。政府必须和企业、高校及科研机构结盟,全民动员和广泛参与,才能应对"大数据"时代的挑战,高校必将是这次大数据浪潮的参与者和推动者。尽管我国教育大数据领域也存在"乔布斯之间"的困惑,但在研究高校大数据方面具有得天独厚的条件,教育管理大数据研究和应用的前景广阔。管理也是生产力。从某种程度上讲,管理比其它要素更重要。大数据教育管理,是高校教育管理发展的新阶段。一切过去皆为序曲,通过大数据预测规律,通过大数据发现价值,大数据使高校采用更加智慧的方式来激发和生产新的智慧。高校教育管理中的大数据与商业领域中的大数据运用有着根本的区别:高校大数据以相关关系为切入,最终寻找特殊的相关关系——因果关系,知其然并"知其所以然"。利用大数据、云计算和物联网等技术,优化办学要素的结构、提高管理水平,是高校提高办学效益、促进高等教育管理由增量发展向质量发展转变的重要工具和基础。目前,学术界在大数据与高校教育管理结合的系统研究成果不多,深度和广度不够,也缺乏具体的实证研究。本论文从科技哲学、管理学、教育学及社会学的视角,综合分析高校大数据教育管理的价值和潜在的风险,在调研我国高校大数据教育管理发展现状及存在问题的基础上,探寻促进我国高校大数据教育管理创新的对策。本研究的主要内容包括四个方面:一是对大数据进行系统深入研究以尽可能达到科学认识。分析大数据产生的科技背景、经济背景和文化背景,尤其深入分析了大数据与互联网、物联网、云计算等信息技术发展及运用的关系,厘清大数据、信息化与智慧化之间的区别与联系。深度剖析了大数据的本质特征。从大数据所引发的生产力与生产关系改革、政治改革、思维变革、商业变革、教育变革和管理变革等方面,揭示大数据对人类思维、科技、经济、文化、学科发展及社会发展的巨大价值,同时对大数据潜在的思维风险、安全风险、技术风险及伦理道德风险等进行系统研究。二是系统研究大数据对我国高校教育管理发展的积极影响和消极影响。在分析高校教育管理现代化本质特点的基础上,指出我国传统高校教育管理存在人文不足、形式单一、缺乏个性及反馈不足等弊端,这与现代化高校教育管理要求相悖。高校大数据教育管理具有个性化、及时性、科学性、差异性、互动性、整合性及权变性等特点,从而具备传统高校教育管理无法比拟的优势。大数据将对我国高校的数据采集、管理决策、治理模式、教育教学、科研服务、评估评价等方面变革带来机遇。同时,高校大数据教育管理面临着隐私与自由平衡问题、数据霸权问题、数据垃圾问题、数据标准问题以及数据安全等诸多挑战,并产生诸多消极影响。三是研究我国高校大数据教育管理发展现状及存在的问题。高校大数据教育管理是信息化发展的新阶段,运用专家访谈法及问卷调查法等研究方法进行调研发现:经过十多年的发展,我国高校教育管理信息化已经取得一定的成绩,如高校CIO制度已经初步建立,财政投入逐步加大,教育管理成效初显等。但是,我国高校大数据教育管理也存在着缺乏顶层设计、缺乏资金保障、数据人才缺乏、法律法规等支持体系不完善及共享机制缺失等问题。四是思考并提出促进我国高校大数据教育管理发展的对策。按照教育现代化的要求,围绕智慧化、人性化教育管理的目标,针对我国高校大数据教育管理存在的问题,在借鉴美国等发达国家高校大数据教育管理经验的基础上,提出促进我国高校大数据教育管理的对策。高校要树立大数据教育管理理念,坚持以人为本、扬长避短、疏堵结合的原则,通过加强顶层设计,加强制度规约,构建协同机制、分享机制和评价机制,打造数据师资等运维体系建设,从而实现"规避风险、发挥优势"的大数据发展目标。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017192249.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '武汉大学',
 'keywords': '高校、大数据、教育管理、影响、对策',
 'refer': '下载次数（6658）| 被引次数（17）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据对我国高校教育管理的影响及对策研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:50:20 [scrapy.core.scraper] ERROR: Error processing {'abstract': '近年来,大数据的思维和方法在社会经济生活领域引起了一场巨大变革,也为政府公共部门带来了新的机遇和挑战。在实践层面,各国政府都对大数据在公共管理中的决策支撑作用表示了肯定,但是对于大数据的使用是较为分散的,主要集中于医疗、交通、教育、舆情预测、消费预测等个别领域,且在这些领域中的应用主要以处理日常管理内容和应对突发紧急事件为主,而对于如何使用大数据支撑政府公共政策的制定尚没有通用的实践策略。在学术研究层面,众多学者也对大数据在促进政府信息公开、决策科学化、管理精细化等方面的作用提出了期望,认为其能够带来新一轮的公共管理变革。但是在公共管理和公共政策学术研究层面,对大数据方法的研究仍处于较为肤浅的介绍和讨论阶段,尚没有形成使用大数据工具辅助政策研究和政策分析的方法论。因此本文致力于研究大数据方法在公共政策研究中的应用问题,并选择了知识产权政策这一子政策体系作为研究的对象。大数据方法与其他所有类型的研究方法相同,都不是万能的而是有其适用边界的,并不是所用公共政策类型都适合使用大数据方法进行研究。知识产权政策领域在使用大数据方法方面具有天然的优势,知识产权政策相对于其他子政策类型,其研究资料的数据化程度较高,且具有数据化研究传统,表现为专利计量研究、专利情报研究等。因此,与其他政策领域相比,大数据方法在知识产权政策研究领域更加容易推进。也正是由于这个原因,本文选择知识产权政策体系作为大数据在公共政策研究中应用的具体对象。本文研究的是大数据方法在知识产权政策研究中的应用问题,属于多学科的交叉型研究,研究共由六章组成。第一章是绪论,主要探讨了研究大数据方法在知识产权政策研究中的应用问题的重要性。指出大数据方法是知识产权政策研究方法体系的重要组成部分,对于该问题的研究可以为知识产权政策研究增添新的研究工具。第二章是全文的理论基础,系统性地梳理了政策科学理论、科技政策理论、知识产权政策体系以及大数据的内涵和构成。政策科学理论中的政策过程理论为第四章的研究提供了基本框架,而对于科技政策、知识产权政策体系的梳理则对明确知识产权政策研究的范围和边界提供了理论指导,对于大数据内涵和构成的整理更是对之后三个章节具体分析提供了支撑。第三章讨论了知识产权政策研究中的数据来源问题,大数据对于知识产权政策研究的影响首先表现为对其数据来源的变革。主要探讨了传统知识产权政策研究的数据来源以及在大数据技术的影响下,研究者可以拓展的新兴知识产权政策数据来源。第四章探讨了大数据对具体知识产权政策过程的影响,依据公共政策实践中的政策过程,对于大数据方法的具体应用展开了细节性的讨论。主要依据安德森的政策过程五阶段划分方法,将知识产权政策的研究过程划分为政策议程、政策制定、政策选择、政策实施、政策评估五个阶段,并针对每一个具体政策过程中大数据技术的具体应用进行了展开,并在最后总结了大数据技术在知识产权政策具体过程应用中的作用。然而大数据除了会对传统公共政策过程实践产生影响以外,还会在更基本的层次对公共政策理念产生影响。因此,本文在第五章探讨了大数据工具对知识产权政策研究产生的变革性影响,包括政策规则算法化和政策调整动态化。第五章所探讨的两种变革具有一定的超前性,在现阶段还缺乏实施基础,但是未来政策研究发展的一个潜在方向。第六章是对大数据在知识产权政策应用中的评价以及全文的总结和展望。大数据虽然会对公共政策以及知识产权政策的研究产生影响,但是大数据在政策研究中也有其优势、劣势以及需要面对的挑战,这些问题也是研究者需要面对的难题。通过第三章、第四章、第五章、第六章的研究,初步形成了知识产权政策大数据研究的方法论体系,包括大数据对政策研究数据来源的影响,大数据对具体政策过程的影响,大数据对于政策理念基础的影响,以及对于大数据在政策研究中的应用的评价。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016107334.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中国科学技术大学',
 'keywords': '知识产权、政策、大数据、方法论、研究方法、方法应用',
 'refer': '下载次数（1550）| 被引次数（2）',
 'source': '博士论文',
 'time': '2016年',
 'title': '知识产权政策研究中的大数据方法应用研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:50:23 [scrapy.core.scraper] ERROR: Error processing {'abstract': '互联网时代数据信息正以惊人的速度膨胀,同时呈现出多元化和碎片化的趋势。如何合理利用这些错综复杂的信息,并将其有效运用到工作中,充分发挥大数据的价值显得迫在眉睫。基于以上背景,笔者认为在大数据时代,结合大数据的基本知识,对产业经济信息的分析进行系统研究,将有助于产业大数据的应用实践。未来,充分利用大数据的价值将推动产经部门工作发生革命性变化。本文以此为切入点,结合工作实际,系统分析大数据背景下产经信息的分析方法及其在宏观决策中的作用,并以钢铁行业和企业为例进行实证分析。本文以大数据基本理论和产业经济信息模型入手,结合产业经济信息分析方法,系统分析了大数据对宏观经济的服务价值。钢铁行业信息是产经信息的一个重要组成部分,本文重点分析了钢铁行业大数据应用,搭建了钢铁行业数据信息框架,运用大数据支撑技术,分析钢铁行业质量控制系统、成本管理系统、生产计划编制和电商平台建设等方面的应用。充分利用大数据分析,将数据获取、分析、提炼运用到钢铁行业的各个环节,极大地提高了钢铁行业获取、分析和运用数据信息的能力,推动钢铁行业的转型升级。最后以某钢企大数据的实施与应用为例进行实证分析,钢铁企业依托大数据技术,从数据采集、存储、分析和应用等环节构建大数据链条,并充分运用到生产、营销和管理中,实现数据集成和管理模式的融合,打造智能、高效的管理模式,培养在同行业中的核心竞争力。通过以上分析,本文得出以下结论:第一,运用大数据进行产业经济信息分析,提升信息分析效率是大势所趋。产业经济信息分析将会完全融入到从相关从业者到国家权威管理部门的服务中,但产经信息的分析仍需深层次挖掘大数据的价值。第二,产业经济信息分析虽需要借助大数据技术平台,而分析的关键在于不同行业、部门和机构的数据信息能够实现共享,并加以有效整合。第三,在大数据时代,将大数据技术充分运用到钢铁行业等传统行业中,有助于提高钢铁企业的生产效率和管理能力,提高行业和企业决策的科学性,有效改善钢铁行业产能过剩的状况,推动行业转型升级。钢铁行业须紧抓大数据时代的契机,打造钢铁行业大数据支持平台,构建大数据中心,并运用到钢铁行业全产业链中,从源头到终端进行科学管理,为进入工业4.0时代扫清障碍。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016184042.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中国地质大学(北京)',
 'keywords': '大数据、产业经济信息、宏观决策、钢铁行业',
 'refer': '下载次数（2502）| 被引次数（7）',
 'source': '博士论文',
 'time': '2016年',
 'title': '大数据时代产业经济信息分析及在宏观决策中的应用——以钢铁行业为例'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:50:23 [scrapy.core.scraper] ERROR: Error processing {'abstract': '本文通过对大数据的内涵、特征、前沿技术以及发展脉络的梳理,并结合利用微博大数据进行战略预见的案例研究,提出了基于大数据的战略预见,详细论述了该新型战略预见方法所带来的思维、方法论以及价值取向的变化。本文认为大数据有希望带来一个平行于自然世界和精神世界的数据世界。从战略预见的角度来看,基于大数据的预见是一种数据驱动的经验模型,它是一种不同于传统的逻辑加经验的预见模式。这种新的战略预见方法无疑将大大拓展人类认识和可预见的范围,并加强战略预见的工具理性,促进战略逻辑中价值理性和工具理性的统一。另外,本文对数据权、数据伦理以及大数据推进战略文明转型等问题进行了比较深入的哲学反思。下面将简述论文的行文结构。第一章将解析大数据的基本概念,发展历史及潜在风险。本章将介绍大数据的定义、特征、分类、主体以及前沿技术。其次,通过回顾大数据的发展历史,介绍科学研究的“第四范式”,即数据密集型科学。最后对大数据引发的一系列伦理问题进行考察。第二章首先讨论了战略预见的逻辑与意涵,并分析预见在战略思维、战略环境以及应对危机中的重要作用。其次,通过梳理三种经典的战略预见方法,展示了在大数据时代多种战略预见方法互补应用的重要性,以及基于大数据的战略预见的可能性。第三章首先分析了大数据作为战略预见的必要性。通过细述微博大数据进行战略预见的具体方法,展示了对“十八届五中全会”的网民态度以及对商业保险和社会保险替代关系这两组具体预见的案例。依托案例,本章总结了大数据作为战略预见的六项方法特征,分别是整体性、相关性、不确定性、网络化、众包化与人工智能化。第四章将对基于大数据的战略预见进行哲学反思。本章针对大数据作为战略预见的方法论和价值论进行思考。从方法论的角度来说,大数据作为战略预见不同于经典预见方法的逻辑加经验的模式,而是倡导一种数据驱动的经验模型,同时,大数据有希望带来平行于自然世界和精神世界的数据世界,将大为拓展人类认识和可预见的范围。在利用大数据进行战略预测的过程中,也要谨防数据拜物教的负面影响。从价值论的角度来说,本章讨论了大数据的技术价值与社会价值,以及新的战略制权——数据权的产生,还有大数据对人的自由全面发展的推动作用。论文完成之后,期望在战略运用方面对数据人才培养、新型智库建设、国家数据安全战略等问题提供有益的参考。最后,论文进行了总结与展望。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016210100.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中共中央党校',
 'keywords': '大数据、方法论、战略预见、战略、大战略',
 'refer': '下载次数（2409）| 被引次数（2）',
 'source': '博士论文',
 'time': '2016年',
 'title': '基于大数据的战略预见研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:50:25 [scrapy.core.scraper] ERROR: Error processing {'abstract': '在大数据时代,中国出版产业面临着新的业态转型和产业链重构的艰巨任务。如果说互联网通过重塑人类交往方式而改变了传统的出版生产体系和市场体系,那么,大数据则通过改变人类社会的信息和数据处理方式进而改变着传统的出版生产体系和市场体系。出版业兼具信息产业、文化创意产业和新闻传播业等多重属性,是以内容和服务创新为特征的知识型产业类别。大数据时代的大数据技术、大数据科学、大数据思维和大数据平台都特别适用于出版业进行知识创新和信息传播。当前,在中国进行以知识创新推动产业升级,着力建设“创新型国家”的大背景下,大数据是中国出版产业进行业态创新和产业链重构的必然选择。研究大数据条件下中国出版产业链的重构问题涉及传播学、出版学、产业链理论以及大数据理论等多学科理论。在大数据条件下,“按需出版”、“按需印刷”、“自主出版”、“众筹出版”等新出版模式不断出现,揭开了大众传播与分众传播关系的新篇章,大众传播与分众传播并存是大数据时代传播学融合的创新基础,分众传播体系和大众传播体系不是取代关系,而是并存关系,只是这种并存关系随着环境的变化在不断此消彼长。在大数据时代,“媒介即人”的传播学理念有了进一步的诠释,“数字的本质是人,数据挖掘就是在分析人类族群自身”,因此,基于大数据的“定制出版”,“分众出版”、“碎片化出版”等新出版方式的出现揭示着从聚众时代的人类族群到分众时代的人类族群关系的变化。大数据时代出版产业链的重构有三个维度：出版价值链维度、出版供需链维度和出版空间链维度。出版价值链是出版产业链价值关系的维度表达,出版供需链是出版产业链供需关系的维度表达,出版空间链是出版产业链空间关系的维度表达。任何产业活动都存在价值关系、供需关系和空间关系,出版产业也不例外,也存在着价值关系传递、供需关系关联和空间关系变迁。基于大数据进行出版价值链重构,其所运用的大数据原理包括：一是基于大数据的“相关性”理论推动出版价值链重构；二是基于大数据的“全数据原理”推动出版价值链重构；三是基于大数据的“第四范式”推动出版价值链重构。发挥大数据价值功能重构出版价值链的基本任务：一是基于大数据关系理解功能创新出版产品形态组合：二是基于大数据的用户挖掘功能创新市场用户组合;三是基于大数据的信息挖掘、用户挖掘和关系理解综合功能再造出版价值链结构。重构的立体、多元、网状的价值链可以尝试用2+++模型来概括,即2种介质(纸介质+光电介质)2种资源(内容资源+数据资源)、2种服务(产品服务+体验服务)。基于大数据对出版供需链进行重构的逻辑是：一是作为稿源的出版资源生长逻辑的转换；二是作为供需链驱动力的产业发展逻辑的转变；三是作为供需终端的市场成长逻辑的转换。基于大数据建构的出版供需链模型是立体、多维、柔性的网状结构,这种出版供需链可以尝试用2+++模型来概括,即2种作者稿源(专业作者+业余作者)、2种出版生产方式(标准出版+按需出版)、2种市场划分(大众市场+分众市场)。基于大数据进行出版空间链的重构,其基本任务：一是在出版产业层面实现出版地域空间和出版网络空间新组合以及凭藉“三业融合”扩大出版产业运行空间范围；二是在出版业务层面实现有限空间向无限空间以及单业务空间向多业务空间的拓展。基于大数据建构出版空间链有两个新的构造,一是存在空间+选择空间+活动空间的网络空间构造,二是纸质版+网络版+手机版的媒介空间构造。基于大数据实现出版产业链重构,存在着诸多不同层面的障碍和问题,但大数据时代中国出版产业链的重构是大势所趋,而基于大数据的出版产业链重构的产业形态应该是智能出版。智能化是大数据应用的高级境界,如果说大数据时代城市化的出路是“智慧城市”,商业化的出路是“智能商务”,那么,出版现代化的出路则是“智能出版”。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1015593301.nh&dbcode=CDFD&year=2015&dflag=cajdown',
 'institution': '华中科技大学',
 'keywords': '大数据、大数据时代、出版产业链、出版产业链重构',
 'refer': '下载次数（2165）| 被引次数（10）',
 'source': '博士论文',
 'time': '2015年',
 'title': '大数据时代中国出版产业链的重构'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:50:26 [scrapy.core.scraper] ERROR: Error processing {'abstract': '当前,随着人类社会数据规模和种类的飞速增长,大数据时代已经到来,大数据的特性与治理理论在"多元化、扁平化、协作化"等方面相互契合,并将革命性地推动政府治理向现代化方向发展。论文围绕大数据技术对政府治理现代化的影响,对基于大数据的政府治理现代化体系、评价模型以及建设路径等内容进行了系统研究,提出了应用大数据推进政府治理现代化的对策和建议,这将有助于客观的认识政府治理现代化问题,为政府利用大数据技术推动治理理念的创新和治理模式的变革提供了参考依据,具有重要的理论意义和现实意义。作者从系统科学视角对大数据重新进行定义,指出大数据是由海量的、分层次的、相互纠缠的全数据集组成的具有自组织性的、动态的、开放的大系统数据集,并提出了大数据"集量成智"的本质特性;通过理论研究和比较研究,提出了基于大数据技术的"DW神经系统型"政府治理机制;通过案例研究分析了大数据对政府治理现代化的积极影响,剖析了面临的风险和挑战;通过实地研究对河南省鹤壁市政府治理现代化有关情况进行了问卷调查,对行政工作效率等12项内容进行了满意度分析;运用PEMSTI特征指标分析模型从人口、经济、工业、服务、交通和信息化六个维度对鹤壁市政府治理现代化情况进行了评价;通过定性研究,提出了鹤壁市政府治理现代化的建设路径;最后采取宏观与微观相结合的方法,对应用大数据推进政府治理现代化的对策和建议进行了探讨。通过研究,作者得出如下结论:1.大数据时代,强烈的政治诉求、公民权利的现实压力,以及传统政府治理存在的种种弊端,共同形成了对政府治理走向现代化的迫切需求。2.海量数据的集聚和相互作用的过程,能够实现数据创造智慧的过程,即"集量成智"。基于大数据技术的"DW神经系统型"政府治理机制,将摆脱"随机抽样"和"因果逻辑"的研究范式,通过"全样本分析"和"相关性分析"等方法获得智慧,并被运用到政府治理领域,打破拉塞尔·阿克夫提出的"数据—信息—知识—智慧"(Data-Information-Knowledge-Wisdom)关系,形成一种"数据—智慧"(Data-Wisdom)的新型关系。3.大数据对政府治理的结构、机制、职能、工具、能力、评估等6个方面具有重要的积极影响:一是多元的治理结构,从垂直走向扁平,从单一走向多元;二是规范的治理机制,从人治走向法治,从封闭走向透明;三是人本的治理职能,从全能走向有限,从管制走向服务;四是现代的治理工具,从强制走向协作,从经验走向数据;五是高效的治理能力,从粗放走向精准,从被动走向主动;六是科学的治理评估,从定性走向定量,从定时走向实时。但是,目前存在的数据异化、信息失真、数据垄断、隐私泄露等风险也不容忽视。4.基于大数据的政府治理现代化具有6方面表现:在治理结构方面呈现治理主体多元化、组织结构扁平化;在治理机制方面呈现信息公开透明化、治理机制法治化;在治理职能方面呈现资源配置市场化、公共服务人本化;在治理工具方面呈现治理方式数据化、社会管理协作化;在治理能力方面呈现行政决策精准化、危机管理预知化;在治理评估方面呈现绩效管理科学化、纪检监察监控化。5.探讨了政府治理现代化的评价方法,通过对传统方法的对比和改进,确定了人口、经济、工业、服务、交通和通信六个维度为模型指标,提出了PEMSTI特征指标分析模型。6.以鹤壁市为例,进行满意度问卷分析得出,民众对政府治理现代化的总体满意度为81.2%,其中对"公众参与治理便利程度"的满意度最高,达到了92.9%;而对"弱势群体覆盖水平"的满意度较低,只有64.7%。通过PEMSTI特征指标模型分析得出,一是政府治理现代化水平受人口和经济总量影响较大,经济越发达,政府治理现代化水平越高。二是随着政府治理现代化工作的实施,鹤壁市各项指标增长迅速,特别是现代服务业、通讯电信业方面增速明显,均位于其他样本城市的前列。三是鹤壁市各项指标呈现单项指针形态,整体发展仍不均衡。在政府治理现代化的建设路径方面,鹤壁市应采取以政府投资建设为主导,以公私合营的模式为辅助,以创新驱动发展,重点做好城市管理业务、社会民生业务、科技文化业务、资源环境业务和产业经济业务方面的治理服务。7.关于应用大数据推动政府治理现代化建设的问题,作者提出了合理定位政府角色、创新行政工作机制、全面实施大数据战略、打造统一数据信息平台、加强人才储备力度、动员民众广泛参与、优化投资融资模式等主要对策建议。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017164593.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '中国农业大学',
 'keywords': '政府治理现代化、大数据、DW神经系统模型、PEMSTI特征指标分析模型、建设路径',
 'refer': '下载次数（3374）| 被引次数（3）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据对政府治理现代化的影响研究——以鹤壁市为例'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:50:27 [scrapy.core.scraper] ERROR: Error processing {'abstract': '我国网民居世界之最,随着大数据时代的到来,大学生作为网民中的一个重要群体,深受其影响。大数据时代,数据呈现爆炸性增长,数据分析能力快速进步,一切皆可量化,数据成为重要的生产要素,人类的思维理念面临革命性的变革。大学生群体作为当代青年的优秀群体,思想最为活跃,最善于接受新鲜事物,最能适应时代要求。没有了地域界限、传统束缚、师长权威,而主张崇尚自我、标新立异的网络空间,没有了信息滞后、信息不对称,而充满着海量信息的大数据时代,给大学生提供了与以往时代迥然不同的社会基础。大数据时代的到来,既给大学生道德教育带来了前所未有的挑战,也为创新大学生道德教育提供了新的机遇。本研究以马克思主义理论为指导,综合运用法学、哲学、教育学、心理学并结合信息学、传播学、管理学、计算机科学、数据科学的知识进行交叉学科研究,整体上遵循从实然到应然的研究思路,从分析大数据时代的内涵和特征及对大学生道德教育的影响入手,力求从大数据时代大学生道德教育的指导思想与基本原则、内容与方法、措施与机制等方面提出系统教育的建议对策。本研究由导论、正文和结论三个部分组成。导论,主要阐述了本研究的选题缘由和选题意义,通过对国内外研究现状进行综述,厘清了研究思路和研究方法。第一章,大数据时代与大学生道德教育的基本问题。概念的厘定是研究的逻辑起点,大数据时代是本研究的时代背景,大学生道德教育是本研究的核心内容,因此,本章详细论述了大数据和大数据时代的内涵与特征,大数据时代的产生背景和发展趋势,分析了不同学者对道德和道德教育概念的阐释,在此基础上提出了大数据时代大学生道德教育的概念,并详细分析了大数据时代给大学生道德教育带来的影响。第二章,大数据时代大学生道德教育的重要性。面对大数据时代的影响,全球化、信息化和市场化带来的全方位多层次的挑战,大学生道德教育面临前所未有的机遇与挑战。本章分析了开展大数据时代的大学生道德教育研究是顺应了大数据时代带来的机遇与挑战,能够促进大学生在大数据时代更加全面的发展,实现道德教育在大数据时代的信息化发展。第三章,大数据时代大学生道德教育的指导思想和基本原则。理论是行动的先导,思想是行动的指南,原则是行动的准则。本章分析了马克思、恩格斯、列宁和我国党和国家领导人关于道德教育的思想,分析了大数据时代大学生道德教育基本原则,这对于开展大数据时代大学生道德教育提供了理论支撑,对大学生道德教育实践起着重要的导向作用,能够推动大学生道德教育活动的顺利开展和实施,为教育者如何开展大学生道德教育工作指明方向。第四章,大数据时代大学生道德教育的内容与方法。大学生个体的道德发展包括知、情、意、行四个方面,这四个方面交互影响、动态发展。大数据时代,处于转型期的中国,社会各个方面都受到了深刻影响,教育的网络化、信息化、数据化改变着教育活动自身。本章针对大数据时代的特点,整合知、情、意、行的教育内容和教育方式,采用网络道德教育与现实道德教育相结合、数字技术与人文精神相结合、数据思维与传统经验相结合、情境认知与泛在教育相结合的教育方法,以期提高大学生道德教育的针对性和实效性。第五章,大数据时代大学生道德教育的措施与机制。随着我国社会主义市场经济的深入发展,社会结构的深刻变革与转型,同时受到西方思潮和后现代主义的影响,伴随着大数据时代的到来,当代大学生思想的独立性和差异性不断增强。这在客观上要求大数据时代的大学生道德教育需要有新的视角,并积极灵活地探索新的教育措施和教育机制。本章分析了大数据时代大学生道德教育的措施,包括制定大数据发展战略、构建大数据教育模式、培养大数据素养、完善大数据政策与法律法规等。分析了大数据时代大学生道德教育的机制,包括预测预警机制、数据化管理机制、开放性机制、评价机制与保障机制,使大数据在大学生道德教育中发挥出其独特的优势。结论,社会实践的不断发展和需要推动着理论的产生与更新,只要信息技术在不断发展,大学生道德教育研究就不应止步。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017803510.nh&dbcode=CDFD&year=2015&dflag=cajdown',
 'institution': '西南大学',
 'keywords': '大数据时代、大学生、道德教育',
 'refer': '下载次数（1885）| 被引次数（0）',
 'source': '博士论文',
 'time': '2015年',
 'title': '大数据时代大学生道德教育研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:50:29 [scrapy.core.scraper] ERROR: Error processing {'abstract': '随着计算机和信息技术的迅猛发展和普及应用,行业数据爆炸性增长,全球已经进入了“大数据”时代。大数据已引起全球业界、学术界和各国政府的高度关注。大数据已经渗透到各行各业,巨大的数据资源已成为国家和企业的战略资源。大数据给全球带来了重大的发展机遇与挑战。一方面,大规模数据资源蕴涵着巨大的商业价值和社会价值,有效地管理和利用这些数据、挖掘数据的深度价值,对国家治理、社会管理、企业决策和个人生活将带来巨大的影响。另一方面,大数据带来新的发展机遇的同时,也带来很多技术挑战。格式多样、形态复杂、规模庞大的行业大数据给传统的计算技术带来了巨大挑战,传统的信息处理与计算技术已难以有效地应对大数据的处理。因此,需要从计算技术的多个层面出发,采用新的技术方法,才能提供有效的大数据处理技术手段和方法。大规模数据的有效处理面临数据的存储、计算和分析等几个层面上的主要技术困难。首先,动辄达到数百TB级甚至PB级规模的行业大数据,远远超出了传统数据库系统的处理能力。因此,需要研究提供有效的分布式大数据存储管理技术方法与系统。同时,大规模数据处理是一个非常耗时的计算过程,使得传统的单机系统远远无法满足大数据对计算性能的要求。因此,需要研究提供高效的并行化大数据计算技术方法与系统。进一步,大数据的有效分析利用通常涉及到对大规模数据的分析挖掘,而巨大的数据量使得传统的单机机器学习和数据挖掘算法都难以在可接受时间内完成计算,导致算法失效。因此,需要研究提供有效的并行化大数据机器学习与分析挖掘算法和大数据机器学习系统。大数据处理不同于传统的计算与信息处理技术的另一个重要特点是,它是一项涉及计算与信息处理技术众多方面的综合性技术,具有显著的技术综合性和交叉性特征,以任何一个单一和隔离的技术层面和技术方法,都难以有效完成大数据的处理。因此,大数据的有效处理需要将存储、计算与分析层面的技术紧密结合、交叉综合,以形成一种完整的大数据处理技术栈,构成一体化的大数据处理系统平台。基于以上问题背景,本文对大数据处理的多个技术层面进行了深入研究,在分布式存储技术与系统、并行化计算技术与系统、以及大数据并行化机器学习与数据分析算法与系统方面,进行了一系列的研究。具体而言,本文工作包括以下主要技术内容和贡献：(1)大数据分布式存储管理技术与系统研究。主要开展了三方面的研究工作。1)为了提升大数据分布式存储系统的性能,研究实现了分层式大数据存储系统缓存调度策略与性能优化方法,可显著提高分布式存储系统数据访问的性能；2)研究实现了一种通用的分布式文件系统性能测试方法与系统工具,可以用于各种分布式文件系统的性能评估和研究优化,或者用于大数据应用系统设计时选择合适的存储系统和参数优化配置；3)研究设计了分布式层次化大规模RDF语义数据存储技术与管理系统,可有效地存储管理大规模RDF语义数据。(2)主流大数据并行计算系统性能优化研究。主要研究了两方面的工作。1)Hadoop '
             'MapReduce作业执行调度优化技术,研究实现了优化的MapReduce作业与任务调度处理方法以及高效的任务执行状态通信方法,实现了一个与标准Hadoop完全兼容的优化版本Hadoop; '
             '2) Spark RDD数据堆外(Off '
             'Heap)内存存储机制,针对Spark在处理大规模数据性能受到JVM垃圾回收严重影响的问题,研究实现了一种基于分布式堆外内存存储的Spark '
             'RDD数据存储机制。(3)大数据并行化机器学习与数据分析方法与算法研究。主要研究实现了多个应用领域的复杂大数据机器学习与数据分析并行化算法,包括：1)针对数据挖掘领域中大规模神经网络训练性能低下的问题,研究实现了一个定制式大规模神经网络训练并行化算法与计算平台cNeural;2)针对在搜索引擎和信息检索领域重要的排序学习(Learning '
             'To Rank)算法GBRT (Gradient Boosting Regression '
             'Tree)训练耗时较长的问题,研究提出了基于K-Means直方图近似算法优化的加速方法及其并行化算法；3)针对语义网推理领域中RDFS和OWL推理规则集在大规模语义数据上推理耗时过长的问题,研究实现了基于Spark并行计算平台的高效并行化推理方法与系统。(4)统一大数据机器学习与数据分析编程模型与系统平台研究。针对大数据分析处理时面临的系统平台可编程性和易用性问题、以及大数据分析处理时的计算性能问题,研究提出了一种基于矩阵模型的统一大数据机器学习与数据分析编程模型与框架,并进一步设计实现了一个跨平台统一大数据机器学习与数据分析系统平台Octopus(大章鱼),该系统底层可与Hadoop、Spark、MPI、Flink等主流大数据平台集成,实现底层平台对上层数据分析程序员的透明性,而上层可使用R/Python编程语言与编程开发环境,基于矩阵模型,方便高效地完成大数据分析算法和应用的编程和计算。通过对上述大数据分布式存储、并行化计算、以及大数据分析层面关键技术方法与系统的研究,本文取得了一系列研究工作成果,这些成果可作为重要支撑技术与系统,有效运用于构建一体化的大数据处理系统平台。本文部分成果已经被成功运用于工业界的开源或者商业化大数据处理系统或应用产品中。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017008183.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '南京大学',
 'keywords': '大数据处理、分布式存储管理、并行化计算、性能优化、机器学习并行化算法、大数据分析编程模型、大数据机器学习系统',
 'refer': '下载次数（6953）| 被引次数（11）',
 'source': '博士论文',
 'time': '2016年',
 'title': '大数据处理技术与系统研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:50:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 16:50:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 16:50:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 16:50:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 16:50:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 16:50:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 16:50:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 16:50:32 [scrapy.core.engine] INFO: Spider opened
2018-08-01 16:50:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 16:51:10 [scrapy.core.scraper] ERROR: Error processing {'abstract': '当今世界,大数据正渗透到人类社会的方方面面,不仅改变人们的思维方式、工作方式和生活方式,改变社会的生产力与生产关系,而且成为未来的"新石油"、"新金矿"、"新资源"和创新的"新引擎"。自2012年以来,美国、英国、法国、日本、韩国等发达国家陆续将大数据上升为国家战略。经过多年的酝酿,我国2015年召开的党的十八届五中全会,明确提出"实施国家大数据战略"。政府必须和企业、高校及科研机构结盟,全民动员和广泛参与,才能应对"大数据"时代的挑战,高校必将是这次大数据浪潮的参与者和推动者。尽管我国教育大数据领域也存在"乔布斯之间"的困惑,但在研究高校大数据方面具有得天独厚的条件,教育管理大数据研究和应用的前景广阔。管理也是生产力。从某种程度上讲,管理比其它要素更重要。大数据教育管理,是高校教育管理发展的新阶段。一切过去皆为序曲,通过大数据预测规律,通过大数据发现价值,大数据使高校采用更加智慧的方式来激发和生产新的智慧。高校教育管理中的大数据与商业领域中的大数据运用有着根本的区别:高校大数据以相关关系为切入,最终寻找特殊的相关关系——因果关系,知其然并"知其所以然"。利用大数据、云计算和物联网等技术,优化办学要素的结构、提高管理水平,是高校提高办学效益、促进高等教育管理由增量发展向质量发展转变的重要工具和基础。目前,学术界在大数据与高校教育管理结合的系统研究成果不多,深度和广度不够,也缺乏具体的实证研究。本论文从科技哲学、管理学、教育学及社会学的视角,综合分析高校大数据教育管理的价值和潜在的风险,在调研我国高校大数据教育管理发展现状及存在问题的基础上,探寻促进我国高校大数据教育管理创新的对策。本研究的主要内容包括四个方面:一是对大数据进行系统深入研究以尽可能达到科学认识。分析大数据产生的科技背景、经济背景和文化背景,尤其深入分析了大数据与互联网、物联网、云计算等信息技术发展及运用的关系,厘清大数据、信息化与智慧化之间的区别与联系。深度剖析了大数据的本质特征。从大数据所引发的生产力与生产关系改革、政治改革、思维变革、商业变革、教育变革和管理变革等方面,揭示大数据对人类思维、科技、经济、文化、学科发展及社会发展的巨大价值,同时对大数据潜在的思维风险、安全风险、技术风险及伦理道德风险等进行系统研究。二是系统研究大数据对我国高校教育管理发展的积极影响和消极影响。在分析高校教育管理现代化本质特点的基础上,指出我国传统高校教育管理存在人文不足、形式单一、缺乏个性及反馈不足等弊端,这与现代化高校教育管理要求相悖。高校大数据教育管理具有个性化、及时性、科学性、差异性、互动性、整合性及权变性等特点,从而具备传统高校教育管理无法比拟的优势。大数据将对我国高校的数据采集、管理决策、治理模式、教育教学、科研服务、评估评价等方面变革带来机遇。同时,高校大数据教育管理面临着隐私与自由平衡问题、数据霸权问题、数据垃圾问题、数据标准问题以及数据安全等诸多挑战,并产生诸多消极影响。三是研究我国高校大数据教育管理发展现状及存在的问题。高校大数据教育管理是信息化发展的新阶段,运用专家访谈法及问卷调查法等研究方法进行调研发现:经过十多年的发展,我国高校教育管理信息化已经取得一定的成绩,如高校CIO制度已经初步建立,财政投入逐步加大,教育管理成效初显等。但是,我国高校大数据教育管理也存在着缺乏顶层设计、缺乏资金保障、数据人才缺乏、法律法规等支持体系不完善及共享机制缺失等问题。四是思考并提出促进我国高校大数据教育管理发展的对策。按照教育现代化的要求,围绕智慧化、人性化教育管理的目标,针对我国高校大数据教育管理存在的问题,在借鉴美国等发达国家高校大数据教育管理经验的基础上,提出促进我国高校大数据教育管理的对策。高校要树立大数据教育管理理念,坚持以人为本、扬长避短、疏堵结合的原则,通过加强顶层设计,加强制度规约,构建协同机制、分享机制和评价机制,打造数据师资等运维体系建设,从而实现"规避风险、发挥优势"的大数据发展目标。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017192249.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '武汉大学',
 'keywords': '高校、大数据、教育管理、影响、对策',
 'refer': '下载次数（6658）| 被引次数（17）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据对我国高校教育管理的影响及对策研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:12 [scrapy.core.scraper] ERROR: Error processing {'abstract': '数据是在社会发展和人类进步过程中不断演进的一种客观存在,伴随着社会现象和社会行为的产生而产生、发展而发展。大数据更是信息爆炸积累到了一个引发变革的程度的产物,是量变引起质变的结果。个体在互联网上既是数据的消费者又是数据的生产者,大规模生产、分享、应用数据的大数据时代已经来临。大数据数量大、类型多、速度快、价值密度低等重要特征使其成为宝贵的信息资源,彰显着巨大的科学价值和社会价值。在高校,包括大学生在内的每个人都是大数据的制造者、传播者、使用者和分析对象。在大数据蓬勃发展,多元文化相互影响的社会主义新时代,如何科学高效、合理合法地利用大数据,挖掘高校网络思想政治教育的深层次规律,有针对性地开展高校网络思想政治教育工作,提高高校思想政治教育质量,不仅关乎青年的成长成才,也关系到社会的发展与国家的前途。毫无疑问,大数据为高校网络思想政治教育提供了更加准确的数据背景和丰富可靠的教育方法及技术手段,提高了高校网络思想政治教育的针对性与科学性。与此同时,大数据所带来的网络环境、技术手段的快速发展和巨大变化也给高校网络思想政治教育施加了新的压力。因此,立足于大数据视阈,识别大数据给高校思想政治教育带来的种种机遇和挑战,利用大数据来科学发现高校网络思想政治教育的客观规律,构建大数据视阈下的高校网络思想政治教育创新系统,从而顺应大数据时代背景下高校网络思想政治教育发展的新形势、新规律和新要求,推动高校网络思想政治教育创新成为当前不得不深入研究并加以解决的重大问题。论文综合运用定性与定量分析,案例与实证分析,文献分析和大数据技术等方法,将大数据与高校网络思想政治教育二者紧密联系在一起,探讨在大数据视阈下如何利用大数据技术方法,发现和把握高校网络思想政治教育的规律,构建高校网络思想政治教育创新系统,进而推动高校网络思想政治教育创新。论文在对大数据视阈下高校网络思想政治教育创新的理论基础和现实状况进行全面分析的基础上,提出了大数据视阈下高校网络思想政治教育创新系统,并进一步采取结构化系统分析的方法对大数据视阈下高校网络思想政治教育创新系统进行了层层分解的深入研究。具体包括:首先,论文在对网络思想政治教育、大数据等基本范畴进行界定的基础上,对大数据视阈下高校网络思想政治教育创新的相关思想资源、理论基础进行了系统诠释和归纳总结。论文指出马克思主义为大数据运用于高校网络思想政治教育确立了价值导向、逻辑起点、功能导向和建设方向,大数据为高校网络思想政治教育提供了技术手段和实现途径,大数据丰富了马克思主义在高校网络思想政治教育中运用和传播的技术手段。其次,论文在对大数据视阈下高校网络思想政治教育创新的现实基础进行分析的基础上,提出了大数据视阈下高校网络思想政治教育创新的现实可能。论文指出,当前及未来社会,信息技术发展日新月异,网络环境变化翻天覆地,高校传统的网络思想政治教育已显现诸多的问题与不足,在面临大数据重大机遇和挑战的时代背景下,高校网络思想政治教育的理念有待创新、方法有待提升、技术有待进步。因此,在大数据视阈下创新高校网络思想政治教育既是来自时代的召唤,也是来自现实的要求。第三,论文在分析大数据视阈下高校网络思想政治教育创新系统构建的基本思路、任务、目标及原则的基础上,构建了大数据视阈下高校网络思想政治教育创新的系统构架。论文指出大数据视阈下高校网络思想政治教育创新系统由内及外由理念、机制、路径和载体等要素所构成,它们具有各自不同的特征及功能。大数据视阈下的高校网络思想政治教育创新应从这四个层面展开。第四,论文探讨了大数据视阈下高校网络思想政治教育的理念创新。论文指出大数据视阈下高校网络思想政治教育的理念创新是系统创新的核心,是引导其他几个层面创新的关键。大数据视阈下高校网络思想政治教育的理念创新应着力于树立全域育人理念、树立聚焦与再现的价值理念,以及树立定制化与定量化交融的理念。第五,论文探讨了大数据视阈下高校网络思想政治教育的路径创新。针对不同成因、动机以及复杂相关性所形成的高校网络思想政治教育的路径依赖,论文首先从思维突破、制度优化、自适应动态分析等角度进行了剖析,提出了在大数据视阈下高校传统网络思想政治教育“路径依赖”突破的最佳或最短路径的求解;其次,从教育内容层面的聚类筛选、识别界定,资源层面的动态配置,再到最后方法层面的协同联合,从理论到案例,从观念到实施,层层递进,利用大数据更新快、预测强、精准聚合、多维共享等特点,将高校网络思想政治教育以更生动、易接受、效果好的形式传递给学生,实现从“数据读心”到“留身入心”,再到“知心交心”,最后引导学生“修养有心”,将路径创新落实到高校网络思想政治教育的诸多阵地中。第六,论文探讨了大数据视阈下高校网络思想政治教育的载体创新。论文指出可以通过大数据平台架构、大数据技术突破与创新,以及大数据技术、互联网与新媒介的有机对接来推动高校网络思想政治教育的载体创新。最后,论文探讨了大数据视阈下高校网络思想政治教育的机制创新。论文通过对“兴趣簇”和“贡献值”的分析,提出了“激励相容”和“绩效促进”的激励机制;通过对教育评估、反馈模型的分析,提出了大数据视阈下高校网络思想政治教育创新的“动态评估反馈”机制;通过对技术安全、伦理道德、个人隐私等的分析,提出了大数据视阈下高校网络思想政治教育创新的安全保障机制。综上所述,论文在基于理论研究和现实分析的基础上,构建了大数据视阈下高校网络思想政治教育创新的系统构架,并依次对其理念创新、路径创新、载体创新和机制创新等系统层面进行层层剖开、详细论述,以期能为大数据视阈下高校网络思想政治教育创新提供有益的支撑和借鉴。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1018974845.nh&dbcode=CDFD&year=2018&dflag=cajdown',
 'institution': '电子科技大学',
 'keywords': '大数据、高校、网络、思想政治教育、创新',
 'refer': '下载次数（0）| 被引次数（0）',
 'source': '博士论文',
 'time': '2018年',
 'title': '大数据视阈下高校网络思想政治教育创新研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:13 [scrapy.core.scraper] ERROR: Error processing {'abstract': '根据时代发展的实际和要求,在教育观念、内容、手段和方法等方面与时俱进地改进创新,推进大学生思想政治教育个性化,是提升思想政治教育针对性和实效性的必然吁求。本文通过开展问卷调查和深度访谈,并引用相关问卷调查结果,论证指出当前大学生思想政治教育个性化仍存在受经验直觉化惯性思维束缚,无法满足需求,内容同质化,以及单向化、被动化等缺陷,根源在于受过分强调群体本位的传统文化及过分注重社会价值的思想政治教育价值观的影响和钳制,既有技术手段无法支撑,以及教育者个性缺乏和受教育者个性不完善等。作为信息时代的新标识,海量数据所蕴含的巨大的经济社会价值毋庸置疑,大数据开启的时代转型,以及引发变革的事实无法回避。大数据不仅是一种技术,也是一种价值观和方法论,它为大学生思想政治教育带来了方法论的变革,也为大学生思想政治教育提供了改进工作方式、方法和手段的一种可能。大数据时代大学生思想政治教育个性化的意义在于通过海量数据整合、挖掘和分析,科学研判学生个体的思想状态和行为特征,从而根据学生个人实际制定和采取有针对性的思想政治教育手段和方式。通过理论层面对大数据为大学生思想政治教育个性化带来的机遇和挑战的探讨,以及对现有大学生思想政治教育大数据应用案例的剖析,阐明借力大数据推进大学生思想政治个性化教育必要且可行。大数据时代大学生思想政治教育个性化的推进,既要有效利用大数据创造的有利条件,也要充分考虑可能引发的风险,应该坚持依托大数据与深入学生实际相统一、一般性分析与针对性教育有机结合、大数据采集与个人隐私保护相结合的原则,并通过大数据意识培育、大数据人才培养、大数据方法运用、智慧校园建构、大数据法律制定等途径,确保应用大数据推进大学生思想政治教育个性化的同时,保护好学生个人隐私,避免出现唯数据主义倾向。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1018085446.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '福建师范大学',
 'keywords': '大数据、大学生、思想政治教育、个性化',
 'refer': '下载次数（18）| 被引次数（）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据时代大学生思想政治教育个性化研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:15 [scrapy.core.scraper] ERROR: Error processing {'abstract': '当前信息技术发展迅速,世界主要国家积极制定科技政策以推动大数据技术发展。大数据作为基础性战略资源,我国也积极将其纳入国家战略。我国大数据产业还处于发展初期,市场潜力巨大。当前我国大数据发展总体仍处于起步阶段,大数据技术发展的政策体系目前尚不完善,有待进一步优化。本文首先研究了大数据发展历程,并对大数据技术相关理论进行梳理,同时对大数据技术相关概念进行界定。然后阐述了大数据技术的产生条件以及大数据技术发展的动态因素。本文将世界主要国家的政策体系与我国的政策体系进行比较,分析了各自政策体系的亮点,同时发现我国大数据技术发展的技术路线图。当前我国大数据技术基础研究薄弱,大数据技术人才短缺,大数据产业应用模式较为单一。本文从宏观、中观、微观三个方面进行分析,比较政策需求和政策供给的具体方面,努力寻求政策体系方面的供需平衡,鼓励技术创新,并研究我国大数据技术发展政策体系的优化路径。最后,我国政府应加强大数据基础研究,鼓励大数据关键技术研发,鼓励技术创新,并积极制定产业扶持政策和人才培养计划,加大大数据技术研发等方面的资金投入。在制定政策方面,应立足系统论视角,把握好国家和地方政府的关系。本文将实证研究与规范研究相结合,利用文本分析法、对比研究法以及系统工程方法对大数据技术发展的政策体系进行研究,具有积极意义。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017730228.nh&dbcode=CMFD&year=2017&dflag=cajdown',
 'institution': '云南师范大学',
 'keywords': '大数据技术、适配性、政策体系',
 'refer': '下载次数（458）| 被引次数（2）',
 'source': '硕士论文',
 'time': '2017年',
 'title': '我国大数据技术发展的政策体系研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:16 [scrapy.core.scraper] ERROR: Error processing {'abstract': '随着信息技术的飞速发展，人类社会进入数字信息时代。获取和掌握信息的能力己成为衡量一个国家实力强弱的标志。一切信息伴随需求不同决定其效益不同，而一切有益信息都是从大量数据中分析出来的。海量数据又随时间持续产生、不断流动、进而扩散形成大数据。大数据不仅用来描述数据的量非常巨大，还突出强调处理数据的速度。所以，大数据成为数据分析领域的前沿技术。数据成为当今每个行业和商业领域的重要因素。人们对于数据的海量挖掘和大量运用，不仅标志着产业生产率的增长和消费者的大量盈余，而且也明确地提示着大数据时代已经到来。数据正成为与物质资产和人力资本同样重要的基础生产要素，大数据的使用成为提高企业竞争力的关键要素。数据成为资产、产业垂直整合、泛互联网化是大数据时代的三大发展趋势。一个国家拥有的数据规模及运用的能力将成为综合国力的重要组成部分，对数据的占有权和控制权将成为陆权、海权、空权之外的国家核心权力。大数据与人类息息相关，越来越多的问题可以通过大数据解决。不仅在数据科学与技术层次，而且在商业模式、产业格局、生态价值与教育层面，大数据都能带来新理念和新思维，包括政府宏观部门、不同的产业界与学术界，甚至个人消费者。大数据与互联网一样，不仅是信息技术领域的革命，更加速企业创新，在全球范围引领社会变革并启动透明政府的发展。大数据正在引发一场思维革命，大数据正在改变人们考察世界的方式方法，以前所未有的速度引起社会、经济、学术、科研、国防、军事等领域的深刻变革。大数据除了将更好的解决商业问题，科技问题，还有各种社会问题，形成以人为本的大数据战略。大数据这一新概念不仅指数据规模庞大，也包括处理和应用数据，是数据对象、技术与应用三者的统一。大数据既可以是如政府部门或企业掌握的数据库这种有限数据集合，也可以是如微博、微信、社交网络上虚拟的无限数据集合。大数据技术包括数据采集、存储、管理、分析挖掘、可视化等技术及其集成。大数据应用是应用大数据技术对各种类型的大数据集合获得有价值信息的行为。充分实现大数据的价值惟有坚持对象、技术、应用三位一体同步发展。大数据是信息技术与各行业领域紧密融合的典型领域，有着旺盛需求和广阔前景。把握机遇需要不断跟踪研究大数据并不断提升对大数据的认知和理解，坚持技术创新与应用创新协同共进同时加快经济社会各领域的大数据开发与利用，推动国家、行业、企业对于数据的应用需求和发展水平进入新的阶段。在大数据时代数据作为一种独立存在的实体，其资产价值越来越突出，日益引起人们的重视。从具体的个人到形形色色的企业，从各国政府到各种组织都可以合法地去收集数据。不论个人还是企业，以及政府等都可以是数据的拥有者。今后个人隐私与数据归属权可能关系越来越少，欧洲民众要求政府公开信息的诉求极其强烈，民众有权向政府申请信息公开。除了涉及国家安全和个人隐私的公共信息外，大部分政府信息都可以公开。大数据主要有三个方面对人类经济社会发展影响巨大，归纳起来：一是能够推动实现巨大经济效益，二是能够推动增强社会管理水平，三是能够推动提高安全保障能力。大数据在政府和公共服务领域的应用可有效推动政务工作开展，提高政府部门的服务效率、决策水平和社会管理水平，产生巨大社会价值。总而言之，大数据将为人们提供强有力的新工具，使人们能更加容易地把握事物规律，更准确地认识世界、预测未来和改造世界。大数据问题涉及范围较广，本文在研究中注重概念分析与文献分析。具体来讲，研究中综合运用了科学技术哲学、社会学等学科的理论知识对大数据进行研究。同时做到问题导向、有的放矢，力求立足本专业理论知识，突出对涉及主题的深层次研究，注意多领域理论知识的综合和统一。本论文既从微观上探讨作为大数据源头与使用者的个体与企业面临的个人隐私风险与商业机密保护问题，又从宏观上分析整个产业乃至国家的大数据治理方针与发展策略，尽量找到实现国家、企业与个人协调发展与动态平衡的路径和方法。本论文通过历史发展的脉络来把握大数据的发展态势，运用科学技术哲学的视角探讨大数据的本质与内涵。以大数据的社会效应为理论和逻辑前提，在把握思维变化和产业发展转型的基础上，从技术、经济、社会等不同层面分析了大数据的动力机制和发展路径，总结了当前主要行业发展方式转型的经验，围绕科技与社会的互动关系梳理大数据与社会各相关产业的融合造成的广泛影响和巨大效益，突出分析了大数据金融产生的一系列重要影响，进而分析其背后蕴含的社会风险，探索相应的社会治理办法，最后就中国积极应对大数据时代、推动中国的大数据发展提出适合中国国情的国家战略设想。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1014336388.nh&dbcode=CDFD&year=2014&dflag=cajdown',
 'institution': '中共中央党校',
 'keywords': '大数据、发展动力、社会价值、大数据金融、风险、战略',
 'refer': '下载次数（35230）| 被引次数（204）',
 'source': '博士论文',
 'time': '2014年',
 'title': '大数据的社会价值与战略选择'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:17 [scrapy.core.scraper] ERROR: Error processing {'abstract': '伴随着信息通信技术的创新与发展,人类社会开始步入大数据时代。我们能够感知和记录更大规模和更多种类的数据,并且通过对这些数据的分析和处理,深度挖掘蕴含其中的内在信息及核心价值。作为“人类世界的下一个自然资源”,大数据正在成为促进组织创新、产业升级和经济发展的强大驱动力,在现代社会的诸多行业领域中有着旺盛的应用需求和广阔的应用前景。其中,教育领域被认为是一个大数据的重要应用领域,研究大数据应用与教育领域的深度融合,是我国教育发展的现实需求和未来趋势。本论文的主要研究内容是,基于大数据及其教育领域应用的理论探讨和实践解析,提出对我国发展大数据教育领域应用的建议。在理论探讨方面,从多视角出发诠释大数据的概念内涵,通过历史脉络梳理把握大数据教育领域应用的发展态势,对大数据应用在教育领域中的实践意义与途径进行了阐述；在实践解析方面,结合美国大数据教育领域应用实践中的现实案例阐释大数据应用驱动下的教育发展和变革,分析大数据教育领域应用在实际推进过程中面临的挑战和社会风险,最后在总结美国经验的基础上提出发展我国大数据教育领域应用的建议。在论文的第一章“绪论”中,主要涉及大数据教育领域应用的研究这一论题的引入,包括研究背景与研究意义的阐释、国内外研究成果的梳理以及研究思路与研究方法、研究创新与不足的说明等内容。第二、三、四、五、六章是论文的主体部分,主要围绕大数据的教育领域应用展开理论探讨和实践分析。第二章“大数据概览”对大数据的定义、理论基础、发展沿革、社会价值及潜在风险、关键技术和实践流程做出系统阐述；第三章“大数据教育领域应用的历史发展脉络、实践意义与途径”对大数据教育领域应用的历史发展阶段及其特征进行梳理,对大数据教育领域应用的实践意义与实践途径加以阐述；第四章“大数据在美国国家、区域和学校教育发展层面的应用”基于美国的应用实践,解析大数据在国家、区域和学校教育发展层面的应用场景和模式；第五章“大数据在美国教育重点领域中的应用”基于美国的应用实践,着重阐述大数据应用驱动下的教学、学习、评价、科研、管理和服务等教育重点领域的变革和发展；第六章“大数据教育领域应用面临的挑战”对可能影响大数据教育领域应用顺利开展的诸项因素进行剖析。第七章“发展我国大数据教育领域应用的建议”在分析和总结美国经验的基础上,分别从宏观和微观角度出发,提出促进我国大数据教育领域应用发展的实施建议。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016126724.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '华东师范大学',
 'keywords': '大数据、大数据应用、教育数据挖掘、学习分析、个性化教育、自适应学习',
 'refer': '下载次数（7789）| 被引次数（30）',
 'source': '博士论文',
 'time': '2016年',
 'title': '大数据的教育领域应用之研究——基于美国的应用实践'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:18 [scrapy.core.scraper] ERROR: Error processing {'abstract': '近年来,大数据的思维和方法在社会经济生活领域引起了一场巨大变革,也为政府公共部门带来了新的机遇和挑战。在实践层面,各国政府都对大数据在公共管理中的决策支撑作用表示了肯定,但是对于大数据的使用是较为分散的,主要集中于医疗、交通、教育、舆情预测、消费预测等个别领域,且在这些领域中的应用主要以处理日常管理内容和应对突发紧急事件为主,而对于如何使用大数据支撑政府公共政策的制定尚没有通用的实践策略。在学术研究层面,众多学者也对大数据在促进政府信息公开、决策科学化、管理精细化等方面的作用提出了期望,认为其能够带来新一轮的公共管理变革。但是在公共管理和公共政策学术研究层面,对大数据方法的研究仍处于较为肤浅的介绍和讨论阶段,尚没有形成使用大数据工具辅助政策研究和政策分析的方法论。因此本文致力于研究大数据方法在公共政策研究中的应用问题,并选择了知识产权政策这一子政策体系作为研究的对象。大数据方法与其他所有类型的研究方法相同,都不是万能的而是有其适用边界的,并不是所用公共政策类型都适合使用大数据方法进行研究。知识产权政策领域在使用大数据方法方面具有天然的优势,知识产权政策相对于其他子政策类型,其研究资料的数据化程度较高,且具有数据化研究传统,表现为专利计量研究、专利情报研究等。因此,与其他政策领域相比,大数据方法在知识产权政策研究领域更加容易推进。也正是由于这个原因,本文选择知识产权政策体系作为大数据在公共政策研究中应用的具体对象。本文研究的是大数据方法在知识产权政策研究中的应用问题,属于多学科的交叉型研究,研究共由六章组成。第一章是绪论,主要探讨了研究大数据方法在知识产权政策研究中的应用问题的重要性。指出大数据方法是知识产权政策研究方法体系的重要组成部分,对于该问题的研究可以为知识产权政策研究增添新的研究工具。第二章是全文的理论基础,系统性地梳理了政策科学理论、科技政策理论、知识产权政策体系以及大数据的内涵和构成。政策科学理论中的政策过程理论为第四章的研究提供了基本框架,而对于科技政策、知识产权政策体系的梳理则对明确知识产权政策研究的范围和边界提供了理论指导,对于大数据内涵和构成的整理更是对之后三个章节具体分析提供了支撑。第三章讨论了知识产权政策研究中的数据来源问题,大数据对于知识产权政策研究的影响首先表现为对其数据来源的变革。主要探讨了传统知识产权政策研究的数据来源以及在大数据技术的影响下,研究者可以拓展的新兴知识产权政策数据来源。第四章探讨了大数据对具体知识产权政策过程的影响,依据公共政策实践中的政策过程,对于大数据方法的具体应用展开了细节性的讨论。主要依据安德森的政策过程五阶段划分方法,将知识产权政策的研究过程划分为政策议程、政策制定、政策选择、政策实施、政策评估五个阶段,并针对每一个具体政策过程中大数据技术的具体应用进行了展开,并在最后总结了大数据技术在知识产权政策具体过程应用中的作用。然而大数据除了会对传统公共政策过程实践产生影响以外,还会在更基本的层次对公共政策理念产生影响。因此,本文在第五章探讨了大数据工具对知识产权政策研究产生的变革性影响,包括政策规则算法化和政策调整动态化。第五章所探讨的两种变革具有一定的超前性,在现阶段还缺乏实施基础,但是未来政策研究发展的一个潜在方向。第六章是对大数据在知识产权政策应用中的评价以及全文的总结和展望。大数据虽然会对公共政策以及知识产权政策的研究产生影响,但是大数据在政策研究中也有其优势、劣势以及需要面对的挑战,这些问题也是研究者需要面对的难题。通过第三章、第四章、第五章、第六章的研究,初步形成了知识产权政策大数据研究的方法论体系,包括大数据对政策研究数据来源的影响,大数据对具体政策过程的影响,大数据对于政策理念基础的影响,以及对于大数据在政策研究中的应用的评价。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016107334.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中国科学技术大学',
 'keywords': '知识产权、政策、大数据、方法论、研究方法、方法应用',
 'refer': '下载次数（1550）| 被引次数（2）',
 'source': '博士论文',
 'time': '2016年',
 'title': '知识产权政策研究中的大数据方法应用研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:19 [scrapy.core.scraper] ERROR: Error processing {'abstract': '互联网时代数据信息正以惊人的速度膨胀,同时呈现出多元化和碎片化的趋势。如何合理利用这些错综复杂的信息,并将其有效运用到工作中,充分发挥大数据的价值显得迫在眉睫。基于以上背景,笔者认为在大数据时代,结合大数据的基本知识,对产业经济信息的分析进行系统研究,将有助于产业大数据的应用实践。未来,充分利用大数据的价值将推动产经部门工作发生革命性变化。本文以此为切入点,结合工作实际,系统分析大数据背景下产经信息的分析方法及其在宏观决策中的作用,并以钢铁行业和企业为例进行实证分析。本文以大数据基本理论和产业经济信息模型入手,结合产业经济信息分析方法,系统分析了大数据对宏观经济的服务价值。钢铁行业信息是产经信息的一个重要组成部分,本文重点分析了钢铁行业大数据应用,搭建了钢铁行业数据信息框架,运用大数据支撑技术,分析钢铁行业质量控制系统、成本管理系统、生产计划编制和电商平台建设等方面的应用。充分利用大数据分析,将数据获取、分析、提炼运用到钢铁行业的各个环节,极大地提高了钢铁行业获取、分析和运用数据信息的能力,推动钢铁行业的转型升级。最后以某钢企大数据的实施与应用为例进行实证分析,钢铁企业依托大数据技术,从数据采集、存储、分析和应用等环节构建大数据链条,并充分运用到生产、营销和管理中,实现数据集成和管理模式的融合,打造智能、高效的管理模式,培养在同行业中的核心竞争力。通过以上分析,本文得出以下结论:第一,运用大数据进行产业经济信息分析,提升信息分析效率是大势所趋。产业经济信息分析将会完全融入到从相关从业者到国家权威管理部门的服务中,但产经信息的分析仍需深层次挖掘大数据的价值。第二,产业经济信息分析虽需要借助大数据技术平台,而分析的关键在于不同行业、部门和机构的数据信息能够实现共享,并加以有效整合。第三,在大数据时代,将大数据技术充分运用到钢铁行业等传统行业中,有助于提高钢铁企业的生产效率和管理能力,提高行业和企业决策的科学性,有效改善钢铁行业产能过剩的状况,推动行业转型升级。钢铁行业须紧抓大数据时代的契机,打造钢铁行业大数据支持平台,构建大数据中心,并运用到钢铁行业全产业链中,从源头到终端进行科学管理,为进入工业4.0时代扫清障碍。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016184042.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中国地质大学(北京)',
 'keywords': '大数据、产业经济信息、宏观决策、钢铁行业',
 'refer': '下载次数（2502）| 被引次数（7）',
 'source': '博士论文',
 'time': '2016年',
 'title': '大数据时代产业经济信息分析及在宏观决策中的应用——以钢铁行业为例'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:21 [scrapy.core.scraper] ERROR: Error processing {'abstract': '本文通过对大数据的内涵、特征、前沿技术以及发展脉络的梳理,并结合利用微博大数据进行战略预见的案例研究,提出了基于大数据的战略预见,详细论述了该新型战略预见方法所带来的思维、方法论以及价值取向的变化。本文认为大数据有希望带来一个平行于自然世界和精神世界的数据世界。从战略预见的角度来看,基于大数据的预见是一种数据驱动的经验模型,它是一种不同于传统的逻辑加经验的预见模式。这种新的战略预见方法无疑将大大拓展人类认识和可预见的范围,并加强战略预见的工具理性,促进战略逻辑中价值理性和工具理性的统一。另外,本文对数据权、数据伦理以及大数据推进战略文明转型等问题进行了比较深入的哲学反思。下面将简述论文的行文结构。第一章将解析大数据的基本概念,发展历史及潜在风险。本章将介绍大数据的定义、特征、分类、主体以及前沿技术。其次,通过回顾大数据的发展历史,介绍科学研究的“第四范式”,即数据密集型科学。最后对大数据引发的一系列伦理问题进行考察。第二章首先讨论了战略预见的逻辑与意涵,并分析预见在战略思维、战略环境以及应对危机中的重要作用。其次,通过梳理三种经典的战略预见方法,展示了在大数据时代多种战略预见方法互补应用的重要性,以及基于大数据的战略预见的可能性。第三章首先分析了大数据作为战略预见的必要性。通过细述微博大数据进行战略预见的具体方法,展示了对“十八届五中全会”的网民态度以及对商业保险和社会保险替代关系这两组具体预见的案例。依托案例,本章总结了大数据作为战略预见的六项方法特征,分别是整体性、相关性、不确定性、网络化、众包化与人工智能化。第四章将对基于大数据的战略预见进行哲学反思。本章针对大数据作为战略预见的方法论和价值论进行思考。从方法论的角度来说,大数据作为战略预见不同于经典预见方法的逻辑加经验的模式,而是倡导一种数据驱动的经验模型,同时,大数据有希望带来平行于自然世界和精神世界的数据世界,将大为拓展人类认识和可预见的范围。在利用大数据进行战略预测的过程中,也要谨防数据拜物教的负面影响。从价值论的角度来说,本章讨论了大数据的技术价值与社会价值,以及新的战略制权——数据权的产生,还有大数据对人的自由全面发展的推动作用。论文完成之后,期望在战略运用方面对数据人才培养、新型智库建设、国家数据安全战略等问题提供有益的参考。最后,论文进行了总结与展望。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016210100.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中共中央党校',
 'keywords': '大数据、方法论、战略预见、战略、大战略',
 'refer': '下载次数（2409）| 被引次数（2）',
 'source': '博士论文',
 'time': '2016年',
 'title': '基于大数据的战略预见研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:22 [scrapy.core.scraper] ERROR: Error processing {'abstract': '在大数据时代,中国出版产业面临着新的业态转型和产业链重构的艰巨任务。如果说互联网通过重塑人类交往方式而改变了传统的出版生产体系和市场体系,那么,大数据则通过改变人类社会的信息和数据处理方式进而改变着传统的出版生产体系和市场体系。出版业兼具信息产业、文化创意产业和新闻传播业等多重属性,是以内容和服务创新为特征的知识型产业类别。大数据时代的大数据技术、大数据科学、大数据思维和大数据平台都特别适用于出版业进行知识创新和信息传播。当前,在中国进行以知识创新推动产业升级,着力建设“创新型国家”的大背景下,大数据是中国出版产业进行业态创新和产业链重构的必然选择。研究大数据条件下中国出版产业链的重构问题涉及传播学、出版学、产业链理论以及大数据理论等多学科理论。在大数据条件下,“按需出版”、“按需印刷”、“自主出版”、“众筹出版”等新出版模式不断出现,揭开了大众传播与分众传播关系的新篇章,大众传播与分众传播并存是大数据时代传播学融合的创新基础,分众传播体系和大众传播体系不是取代关系,而是并存关系,只是这种并存关系随着环境的变化在不断此消彼长。在大数据时代,“媒介即人”的传播学理念有了进一步的诠释,“数字的本质是人,数据挖掘就是在分析人类族群自身”,因此,基于大数据的“定制出版”,“分众出版”、“碎片化出版”等新出版方式的出现揭示着从聚众时代的人类族群到分众时代的人类族群关系的变化。大数据时代出版产业链的重构有三个维度：出版价值链维度、出版供需链维度和出版空间链维度。出版价值链是出版产业链价值关系的维度表达,出版供需链是出版产业链供需关系的维度表达,出版空间链是出版产业链空间关系的维度表达。任何产业活动都存在价值关系、供需关系和空间关系,出版产业也不例外,也存在着价值关系传递、供需关系关联和空间关系变迁。基于大数据进行出版价值链重构,其所运用的大数据原理包括：一是基于大数据的“相关性”理论推动出版价值链重构；二是基于大数据的“全数据原理”推动出版价值链重构；三是基于大数据的“第四范式”推动出版价值链重构。发挥大数据价值功能重构出版价值链的基本任务：一是基于大数据关系理解功能创新出版产品形态组合：二是基于大数据的用户挖掘功能创新市场用户组合;三是基于大数据的信息挖掘、用户挖掘和关系理解综合功能再造出版价值链结构。重构的立体、多元、网状的价值链可以尝试用2+++模型来概括,即2种介质(纸介质+光电介质)2种资源(内容资源+数据资源)、2种服务(产品服务+体验服务)。基于大数据对出版供需链进行重构的逻辑是：一是作为稿源的出版资源生长逻辑的转换；二是作为供需链驱动力的产业发展逻辑的转变；三是作为供需终端的市场成长逻辑的转换。基于大数据建构的出版供需链模型是立体、多维、柔性的网状结构,这种出版供需链可以尝试用2+++模型来概括,即2种作者稿源(专业作者+业余作者)、2种出版生产方式(标准出版+按需出版)、2种市场划分(大众市场+分众市场)。基于大数据进行出版空间链的重构,其基本任务：一是在出版产业层面实现出版地域空间和出版网络空间新组合以及凭藉“三业融合”扩大出版产业运行空间范围；二是在出版业务层面实现有限空间向无限空间以及单业务空间向多业务空间的拓展。基于大数据建构出版空间链有两个新的构造,一是存在空间+选择空间+活动空间的网络空间构造,二是纸质版+网络版+手机版的媒介空间构造。基于大数据实现出版产业链重构,存在着诸多不同层面的障碍和问题,但大数据时代中国出版产业链的重构是大势所趋,而基于大数据的出版产业链重构的产业形态应该是智能出版。智能化是大数据应用的高级境界,如果说大数据时代城市化的出路是“智慧城市”,商业化的出路是“智能商务”,那么,出版现代化的出路则是“智能出版”。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1015593301.nh&dbcode=CDFD&year=2015&dflag=cajdown',
 'institution': '华中科技大学',
 'keywords': '大数据、大数据时代、出版产业链、出版产业链重构',
 'refer': '下载次数（2165）| 被引次数（10）',
 'source': '博士论文',
 'time': '2015年',
 'title': '大数据时代中国出版产业链的重构'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:24 [scrapy.core.scraper] ERROR: Error processing {'abstract': '当前,随着人类社会数据规模和种类的飞速增长,大数据时代已经到来,大数据的特性与治理理论在"多元化、扁平化、协作化"等方面相互契合,并将革命性地推动政府治理向现代化方向发展。论文围绕大数据技术对政府治理现代化的影响,对基于大数据的政府治理现代化体系、评价模型以及建设路径等内容进行了系统研究,提出了应用大数据推进政府治理现代化的对策和建议,这将有助于客观的认识政府治理现代化问题,为政府利用大数据技术推动治理理念的创新和治理模式的变革提供了参考依据,具有重要的理论意义和现实意义。作者从系统科学视角对大数据重新进行定义,指出大数据是由海量的、分层次的、相互纠缠的全数据集组成的具有自组织性的、动态的、开放的大系统数据集,并提出了大数据"集量成智"的本质特性;通过理论研究和比较研究,提出了基于大数据技术的"DW神经系统型"政府治理机制;通过案例研究分析了大数据对政府治理现代化的积极影响,剖析了面临的风险和挑战;通过实地研究对河南省鹤壁市政府治理现代化有关情况进行了问卷调查,对行政工作效率等12项内容进行了满意度分析;运用PEMSTI特征指标分析模型从人口、经济、工业、服务、交通和信息化六个维度对鹤壁市政府治理现代化情况进行了评价;通过定性研究,提出了鹤壁市政府治理现代化的建设路径;最后采取宏观与微观相结合的方法,对应用大数据推进政府治理现代化的对策和建议进行了探讨。通过研究,作者得出如下结论:1.大数据时代,强烈的政治诉求、公民权利的现实压力,以及传统政府治理存在的种种弊端,共同形成了对政府治理走向现代化的迫切需求。2.海量数据的集聚和相互作用的过程,能够实现数据创造智慧的过程,即"集量成智"。基于大数据技术的"DW神经系统型"政府治理机制,将摆脱"随机抽样"和"因果逻辑"的研究范式,通过"全样本分析"和"相关性分析"等方法获得智慧,并被运用到政府治理领域,打破拉塞尔·阿克夫提出的"数据—信息—知识—智慧"(Data-Information-Knowledge-Wisdom)关系,形成一种"数据—智慧"(Data-Wisdom)的新型关系。3.大数据对政府治理的结构、机制、职能、工具、能力、评估等6个方面具有重要的积极影响:一是多元的治理结构,从垂直走向扁平,从单一走向多元;二是规范的治理机制,从人治走向法治,从封闭走向透明;三是人本的治理职能,从全能走向有限,从管制走向服务;四是现代的治理工具,从强制走向协作,从经验走向数据;五是高效的治理能力,从粗放走向精准,从被动走向主动;六是科学的治理评估,从定性走向定量,从定时走向实时。但是,目前存在的数据异化、信息失真、数据垄断、隐私泄露等风险也不容忽视。4.基于大数据的政府治理现代化具有6方面表现:在治理结构方面呈现治理主体多元化、组织结构扁平化;在治理机制方面呈现信息公开透明化、治理机制法治化;在治理职能方面呈现资源配置市场化、公共服务人本化;在治理工具方面呈现治理方式数据化、社会管理协作化;在治理能力方面呈现行政决策精准化、危机管理预知化;在治理评估方面呈现绩效管理科学化、纪检监察监控化。5.探讨了政府治理现代化的评价方法,通过对传统方法的对比和改进,确定了人口、经济、工业、服务、交通和通信六个维度为模型指标,提出了PEMSTI特征指标分析模型。6.以鹤壁市为例,进行满意度问卷分析得出,民众对政府治理现代化的总体满意度为81.2%,其中对"公众参与治理便利程度"的满意度最高,达到了92.9%;而对"弱势群体覆盖水平"的满意度较低,只有64.7%。通过PEMSTI特征指标模型分析得出,一是政府治理现代化水平受人口和经济总量影响较大,经济越发达,政府治理现代化水平越高。二是随着政府治理现代化工作的实施,鹤壁市各项指标增长迅速,特别是现代服务业、通讯电信业方面增速明显,均位于其他样本城市的前列。三是鹤壁市各项指标呈现单项指针形态,整体发展仍不均衡。在政府治理现代化的建设路径方面,鹤壁市应采取以政府投资建设为主导,以公私合营的模式为辅助,以创新驱动发展,重点做好城市管理业务、社会民生业务、科技文化业务、资源环境业务和产业经济业务方面的治理服务。7.关于应用大数据推动政府治理现代化建设的问题,作者提出了合理定位政府角色、创新行政工作机制、全面实施大数据战略、打造统一数据信息平台、加强人才储备力度、动员民众广泛参与、优化投资融资模式等主要对策建议。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017164593.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '中国农业大学',
 'keywords': '政府治理现代化、大数据、DW神经系统模型、PEMSTI特征指标分析模型、建设路径',
 'refer': '下载次数（3374）| 被引次数（3）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据对政府治理现代化的影响研究——以鹤壁市为例'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:25 [scrapy.core.scraper] ERROR: Error processing {'abstract': '我国网民居世界之最,随着大数据时代的到来,大学生作为网民中的一个重要群体,深受其影响。大数据时代,数据呈现爆炸性增长,数据分析能力快速进步,一切皆可量化,数据成为重要的生产要素,人类的思维理念面临革命性的变革。大学生群体作为当代青年的优秀群体,思想最为活跃,最善于接受新鲜事物,最能适应时代要求。没有了地域界限、传统束缚、师长权威,而主张崇尚自我、标新立异的网络空间,没有了信息滞后、信息不对称,而充满着海量信息的大数据时代,给大学生提供了与以往时代迥然不同的社会基础。大数据时代的到来,既给大学生道德教育带来了前所未有的挑战,也为创新大学生道德教育提供了新的机遇。本研究以马克思主义理论为指导,综合运用法学、哲学、教育学、心理学并结合信息学、传播学、管理学、计算机科学、数据科学的知识进行交叉学科研究,整体上遵循从实然到应然的研究思路,从分析大数据时代的内涵和特征及对大学生道德教育的影响入手,力求从大数据时代大学生道德教育的指导思想与基本原则、内容与方法、措施与机制等方面提出系统教育的建议对策。本研究由导论、正文和结论三个部分组成。导论,主要阐述了本研究的选题缘由和选题意义,通过对国内外研究现状进行综述,厘清了研究思路和研究方法。第一章,大数据时代与大学生道德教育的基本问题。概念的厘定是研究的逻辑起点,大数据时代是本研究的时代背景,大学生道德教育是本研究的核心内容,因此,本章详细论述了大数据和大数据时代的内涵与特征,大数据时代的产生背景和发展趋势,分析了不同学者对道德和道德教育概念的阐释,在此基础上提出了大数据时代大学生道德教育的概念,并详细分析了大数据时代给大学生道德教育带来的影响。第二章,大数据时代大学生道德教育的重要性。面对大数据时代的影响,全球化、信息化和市场化带来的全方位多层次的挑战,大学生道德教育面临前所未有的机遇与挑战。本章分析了开展大数据时代的大学生道德教育研究是顺应了大数据时代带来的机遇与挑战,能够促进大学生在大数据时代更加全面的发展,实现道德教育在大数据时代的信息化发展。第三章,大数据时代大学生道德教育的指导思想和基本原则。理论是行动的先导,思想是行动的指南,原则是行动的准则。本章分析了马克思、恩格斯、列宁和我国党和国家领导人关于道德教育的思想,分析了大数据时代大学生道德教育基本原则,这对于开展大数据时代大学生道德教育提供了理论支撑,对大学生道德教育实践起着重要的导向作用,能够推动大学生道德教育活动的顺利开展和实施,为教育者如何开展大学生道德教育工作指明方向。第四章,大数据时代大学生道德教育的内容与方法。大学生个体的道德发展包括知、情、意、行四个方面,这四个方面交互影响、动态发展。大数据时代,处于转型期的中国,社会各个方面都受到了深刻影响,教育的网络化、信息化、数据化改变着教育活动自身。本章针对大数据时代的特点,整合知、情、意、行的教育内容和教育方式,采用网络道德教育与现实道德教育相结合、数字技术与人文精神相结合、数据思维与传统经验相结合、情境认知与泛在教育相结合的教育方法,以期提高大学生道德教育的针对性和实效性。第五章,大数据时代大学生道德教育的措施与机制。随着我国社会主义市场经济的深入发展,社会结构的深刻变革与转型,同时受到西方思潮和后现代主义的影响,伴随着大数据时代的到来,当代大学生思想的独立性和差异性不断增强。这在客观上要求大数据时代的大学生道德教育需要有新的视角,并积极灵活地探索新的教育措施和教育机制。本章分析了大数据时代大学生道德教育的措施,包括制定大数据发展战略、构建大数据教育模式、培养大数据素养、完善大数据政策与法律法规等。分析了大数据时代大学生道德教育的机制,包括预测预警机制、数据化管理机制、开放性机制、评价机制与保障机制,使大数据在大学生道德教育中发挥出其独特的优势。结论,社会实践的不断发展和需要推动着理论的产生与更新,只要信息技术在不断发展,大学生道德教育研究就不应止步。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017803510.nh&dbcode=CDFD&year=2015&dflag=cajdown',
 'institution': '西南大学',
 'keywords': '大数据时代、大学生、道德教育',
 'refer': '下载次数（1885）| 被引次数（0）',
 'source': '博士论文',
 'time': '2015年',
 'title': '大数据时代大学生道德教育研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:25 [scrapy.core.scraper] ERROR: Error processing {'abstract': '随着计算机和信息技术的迅猛发展和普及应用,行业数据爆炸性增长,全球已经进入了“大数据”时代。大数据已引起全球业界、学术界和各国政府的高度关注。大数据已经渗透到各行各业,巨大的数据资源已成为国家和企业的战略资源。大数据给全球带来了重大的发展机遇与挑战。一方面,大规模数据资源蕴涵着巨大的商业价值和社会价值,有效地管理和利用这些数据、挖掘数据的深度价值,对国家治理、社会管理、企业决策和个人生活将带来巨大的影响。另一方面,大数据带来新的发展机遇的同时,也带来很多技术挑战。格式多样、形态复杂、规模庞大的行业大数据给传统的计算技术带来了巨大挑战,传统的信息处理与计算技术已难以有效地应对大数据的处理。因此,需要从计算技术的多个层面出发,采用新的技术方法,才能提供有效的大数据处理技术手段和方法。大规模数据的有效处理面临数据的存储、计算和分析等几个层面上的主要技术困难。首先,动辄达到数百TB级甚至PB级规模的行业大数据,远远超出了传统数据库系统的处理能力。因此,需要研究提供有效的分布式大数据存储管理技术方法与系统。同时,大规模数据处理是一个非常耗时的计算过程,使得传统的单机系统远远无法满足大数据对计算性能的要求。因此,需要研究提供高效的并行化大数据计算技术方法与系统。进一步,大数据的有效分析利用通常涉及到对大规模数据的分析挖掘,而巨大的数据量使得传统的单机机器学习和数据挖掘算法都难以在可接受时间内完成计算,导致算法失效。因此,需要研究提供有效的并行化大数据机器学习与分析挖掘算法和大数据机器学习系统。大数据处理不同于传统的计算与信息处理技术的另一个重要特点是,它是一项涉及计算与信息处理技术众多方面的综合性技术,具有显著的技术综合性和交叉性特征,以任何一个单一和隔离的技术层面和技术方法,都难以有效完成大数据的处理。因此,大数据的有效处理需要将存储、计算与分析层面的技术紧密结合、交叉综合,以形成一种完整的大数据处理技术栈,构成一体化的大数据处理系统平台。基于以上问题背景,本文对大数据处理的多个技术层面进行了深入研究,在分布式存储技术与系统、并行化计算技术与系统、以及大数据并行化机器学习与数据分析算法与系统方面,进行了一系列的研究。具体而言,本文工作包括以下主要技术内容和贡献：(1)大数据分布式存储管理技术与系统研究。主要开展了三方面的研究工作。1)为了提升大数据分布式存储系统的性能,研究实现了分层式大数据存储系统缓存调度策略与性能优化方法,可显著提高分布式存储系统数据访问的性能；2)研究实现了一种通用的分布式文件系统性能测试方法与系统工具,可以用于各种分布式文件系统的性能评估和研究优化,或者用于大数据应用系统设计时选择合适的存储系统和参数优化配置；3)研究设计了分布式层次化大规模RDF语义数据存储技术与管理系统,可有效地存储管理大规模RDF语义数据。(2)主流大数据并行计算系统性能优化研究。主要研究了两方面的工作。1)Hadoop '
             'MapReduce作业执行调度优化技术,研究实现了优化的MapReduce作业与任务调度处理方法以及高效的任务执行状态通信方法,实现了一个与标准Hadoop完全兼容的优化版本Hadoop; '
             '2) Spark RDD数据堆外(Off '
             'Heap)内存存储机制,针对Spark在处理大规模数据性能受到JVM垃圾回收严重影响的问题,研究实现了一种基于分布式堆外内存存储的Spark '
             'RDD数据存储机制。(3)大数据并行化机器学习与数据分析方法与算法研究。主要研究实现了多个应用领域的复杂大数据机器学习与数据分析并行化算法,包括：1)针对数据挖掘领域中大规模神经网络训练性能低下的问题,研究实现了一个定制式大规模神经网络训练并行化算法与计算平台cNeural;2)针对在搜索引擎和信息检索领域重要的排序学习(Learning '
             'To Rank)算法GBRT (Gradient Boosting Regression '
             'Tree)训练耗时较长的问题,研究提出了基于K-Means直方图近似算法优化的加速方法及其并行化算法；3)针对语义网推理领域中RDFS和OWL推理规则集在大规模语义数据上推理耗时过长的问题,研究实现了基于Spark并行计算平台的高效并行化推理方法与系统。(4)统一大数据机器学习与数据分析编程模型与系统平台研究。针对大数据分析处理时面临的系统平台可编程性和易用性问题、以及大数据分析处理时的计算性能问题,研究提出了一种基于矩阵模型的统一大数据机器学习与数据分析编程模型与框架,并进一步设计实现了一个跨平台统一大数据机器学习与数据分析系统平台Octopus(大章鱼),该系统底层可与Hadoop、Spark、MPI、Flink等主流大数据平台集成,实现底层平台对上层数据分析程序员的透明性,而上层可使用R/Python编程语言与编程开发环境,基于矩阵模型,方便高效地完成大数据分析算法和应用的编程和计算。通过对上述大数据分布式存储、并行化计算、以及大数据分析层面关键技术方法与系统的研究,本文取得了一系列研究工作成果,这些成果可作为重要支撑技术与系统,有效运用于构建一体化的大数据处理系统平台。本文部分成果已经被成功运用于工业界的开源或者商业化大数据处理系统或应用产品中。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017008183.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '南京大学',
 'keywords': '大数据处理、分布式存储管理、并行化计算、性能优化、机器学习并行化算法、大数据分析编程模型、大数据机器学习系统',
 'refer': '下载次数（6953）| 被引次数（11）',
 'source': '博士论文',
 'time': '2016年',
 'title': '大数据处理技术与系统研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:25 [scrapy.core.scraper] ERROR: Error processing {'abstract': '\xa0'
             '本发明提供了一种具备容N-3存储媒介失效的电力大数据云储存系统,该系统包括云存储控制管理单元,云存储控制管理单元分别与依次连接的电力大数据块的[32,16,8]Reed-Muller码编码处理单元、写入通信传输通道、a行32列的存储媒介阵列、读出通信传输通道和电力大数据块的[32,16,8]Reed-Muller码译码处理单元相连。该系统采用Reed-Muller码编译码技术、哈希函数摘要技术,允许同时发生任意≤3个存储媒介失效,具备N-3容失效性,解决电力大数据云储存系统存储容量、容故障能力和扩展性三者均衡优化问题,保护数据安全,且保障数据具有一定的私密性和完整性,以推进电力大数据云储存系统的建设和发展。',
 'download': 'http://dbpub.cnki.net/grid2008/dbpub/detail.aspx?filename=CN103957265A&dbname=SCPD2014',
 'institution': '国家电网公司;中国电力科学研究院',
 'keywords': '\xa0【主权项】\xa0'
             '一种具备容N?3存储媒介失效的电力大数据云储存系统,其特征在于：所述系统包括依次连接的电力大数据块的[32,16,8]Reed?Muller码编码处理单元、写入通信传输通道、a行32列的存储媒介阵列、读出通信传输通道和电力大数据块的[32,16,8]Reed?Muller码译码处理单元；?云存储控制管理单元分别与所述电力大数据块的[32,16,8]Reed?Muller码编码处理单元、写入通信传输通道、a行32列的存储媒介阵列、读出通信传输通道和电力大数据块的[32,16,8]Reed?Muller码译码处理单元连接。?',
 'refer': '下载次数（0）| 被引次数（0）',
 'source': '中国专利',
 'time': '2014年',
 'title': '一种具备容N-3存储媒介失效的电力大数据云储存系统'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:26 [scrapy.core.scraper] ERROR: Error processing {'abstract': '近年来,尽管我国的税收信用建设取得了一定成就,但是当前税收信用缺失现象依然十分严重,纳税人偷逃税款、征税人收过头税、用税人预算不透明、税务中介合谋等现象屡见不鲜,亟需建立一个完善的税收信用体系。大数据时代的来临为我国税收信用体系的建设提供了良好的契机,大数据在税收领域的应用将会对税收信用理论研究和实践应用产生深刻的影响,因此研究大数据在税收信用建设方面的作用和影响正当其时。国内外学者对税收信用的研究主要集中在纳税信用方面,很少对征税信用、用税信用和税务中介信用进行全面的研究,尤其是大数据时代下税收信用建设的研究更是少见。本文提出了包含纳税信用、征税信用、用税信用和、税务中介信用四个方面的比较全面的税收信用研究框架和内容,并全面分析和研究大数据对税收信用的影响,以期揭示大数据时代下税收信用建设的特征和规律,为大数据时代下的税收信用建设提供参考,具有较强的理论意义及现实意义。构建比较全面的税收信用体系,建立税收信用的完整框架,并研究大数据对税收信用的影响和规律,也是本文在研究框架以及内容上尝试的创新。通过对大数据以及税收信用相关理论概念进行梳理,第二章得出了本研究的理论基础以及研究方法。税收信用从某种角度上说是纳税人、征税人、用税人和税务中介等具有契约特性的博弈关系,大数据的应用会改变或消除税收博弈双方的信息不对称状态,改变博弈均衡结果,从而对税收信用产生影响。基于此种考虑,本文利用信息经济学及博弈论相关理论的分析方法和逻辑思维全面分析大数据时代下的税收信用建设。第四章对纳税人、征税人、用税人、税务中介的信息特点和优势进行了分析,进而总结分析了他们之间的信息不对称的具体表现,正是这种信息不对称严重制约着我国税收信用的发展。而税收大数据不仅涵盖了海量的涉税信息,大数据技术的应用能够充分挖掘和发挥海量涉税信息的价值,在一定程度上会减弱甚至消除纳税人、征税人、用税人、税务中介之间的税收信息不对称状态。至此,提出了大数据对税收信息不对称乃至税收信用影响的理论依据。为了深入分析大数据对税收信用的影响,本文第五章构建了一系列的模型,并尝试将大数据因素纳入模型中,模型包括:纳税信用博弈模型、征税信用委托-代理模型、用税信用声誉模型、税务中介信用博弈模型等。具体的分析过程如下:首先进行了理论分析以及假设,提出大数据对税收信用影响的理论依据以及提出大数据影响的待检验假设;其次,通过博弈论以及委托-代理理论的基本知识建立模型,并进行分析和求均衡解;最后结合模型的均衡解,得出大数据对税收信用建设的影响。通过一系列分析,本文主要得出以下基本结论:(一)纳税人是否选择诚信纳税与税务机关的稽查成本Ct、税务机关能否稽查出纳税人偷漏税的概率ε有关。大数据的利用会通过降低税务机关的稽查成本,提高税务机关稽查的技术,进而降低纳税人偷税漏税的概率,这将最终有利于提高纳税人的税收信用;(二)通过分析求解信息不对称和信息对称条件下的委托-代理模型,得出在信息对称条件下征税人(税务机关)作为代理人工作努力程度更高,政府部门的最优收益更大,因此大数据的运用有利于征税信用建设;(三)政府的税收效用与纳税人对政府信用的预期正相关,然而大数据对纳税人的预期、博弈均衡结果以及用税信用的影响是错综复杂的;(四)大数据的应用会降低税务机关的稽查成本,提高税务机关稽查成功的概率,加大税务中介合谋的损失等一系列效果,最终会有利于税务中介的信用建设。通过以上五章的分析,本文进一步明确了大数据对我国税收信用建设的促进作用,科学合理的运用大数据会给我国的税收信用建设带来重大发展机遇。因此,加快构建与大数据时代相适应的税收信用体系是当前税收信用建设工作的重中之重。最后,基于以上研究的结论,结合我国税收信用建设现状,本文提出大数据时代下我国的税收信用体系建设的政策性建议。主要包括两个部分:一是完善大数据下税收信用建设基本要件,以及实行一些具体措施;二是完善纳税人信用等级评定制度、加强征管环节的税收信用、重视税务中介的信用建设等建议。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1018031683.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '中共中央党校',
 'keywords': '税收信用、大数据、税收博弈、信息不对称',
 'refer': '下载次数（237）| 被引次数（）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据时代下的税收信用建设研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:51:28 [scrapy.core.scraper] ERROR: Error processing {'abstract': '在我国,中小企业大部分由创办人经营,由于缺乏资源,需要长期依赖企业家的创新精神来促进业务增长。尽管如此,中小企业在我国经济发展中起着非常重要的作用,不同的资源导致中小企业有着不同的表现,因此,有必要让中小企业通过识别和利用创新的机会,提出计划目标和组织长期的策略。同时,通过与外部环境相配合来实现战略竞争力,从而获得高于平均水平的回报。创新战略精神可以促使中小企业管理和识别可持续的竞争优势,从而推动中小企业发现新商机和加强管理与协调资源。在我国经济发展中,中小企业起主导作用,占99.5%以上,是国民经济和社会发展的重要基础。中小企业的迅速发展已成为我国市场经济的重要成员,带动社会生产力的发展。因此,越来越多的中小企业通过“瓶颈资产”来建立竞争优势,以创造、组合、转移、积累和保护无形资产。从核心竞争力中演化而来的资源基础理论强调企业的竞争优势在于宝贵的有形和无形资源,由于资源具有异质性,因此能够将短期的竞争优势转化为持续的竞争优势。大部分的中小企业家善于辨别机会,信息来源是他们决策的关键,而快速反应和分析能力能够给中小企业带来持续的竞争优势,因此也是值得关注的核心竞争力。这种核心能力被称为动态能力或动态竞争力。动态能力是一个很难确定企业特质的潜在因素,最初被定义为“企业发挥整合能力,创建和重构内部和外部资源,形成竞争力,以应对变化多端的环境。”企业通过改变资源和例程的能力来承认面临着的动态变化的市场环境,并对一些企业之所以能有更好的生存机会做出解释。动态能力强调学习,通过“信息”获取有关资料,并瞄准与之匹配的内部资源配置环境,诱发公司对资源进行调整配置,导致内部优势和短板通过识别来应对外部所带来的机会和挑战。“变化”是下一个合乎逻辑的过程步骤,包括创造潜在反应的刺激,从信息处理步骤产生的“评估”和“选择”替代方案。最后,“保留”已实现的资源配置。通过对动态能力和吸收能力相互作用,导致作战能力提升,从而提高企业的竞争优势,建成”基于知识的动态能力模型”。企业不仅要从市场环境中发现新知识,也要对内部反应做出反馈,利用应用结果和重新配置的重点来组织学习。吸收能力和动态能力之间的链接是相辅相成的,通过动态能力和学习,有助于更好地理解知识。动态能力的作用是把各种概念集合或汇总,而吸收能力则是通过与学习相结合,具体有:“采集”识别和获取外部知识,“同化”整合知识;“变换”外部新知识与已有的知识相结合,和“开发”外部知识来实现组织目标的应变能力。这四个维度是必然的探索、同化的过程,通过转化和利用式学习,有助于提高经营业绩,创建竞争优势,利用其创新性和战略灵活性,以适应变化和提升竞争力。成功的吸收能力是持续竞争优势的动态能力,实时分析则是信息管理中的重要工具,同时可以解决微弱信号理论中的信息不对称问题。实时(或低延时)大数据分析可以改变游戏规则,由于客户和市场是稍纵即逝的,因此在出现或消失之前,中小企业有机会通过微弱信号来识别和采取行动。基于服务位置大数据有着庞大的商业潜力,该数据的优点是可实时访问关键数据源,并找出业务指标。实时数据的匹配决定了创造性的思维和预测分析,使业务流程产生改变,实现对企业利益相关者进行预测和优化。这些新的理念,可以帮助中小企业设想整套方案,并推出具体的措施。因此,在不同的决策情况下,评估潜在于各项业务活动中。另外,企业高管特别重视大数据技术在中小企业制定竞争战略时所起到的重要作用,及其决策特异性的发挥。如今,大数据彻底改变了中小企业的业务模型,提出了新见解和客户互动方式,通过分析竞争对手的信息从而提高盈利能力,实现策略改变和实时交付。不同来源的数据,经过勘探,体现价值。新信息技术能够在几秒钟内访问和分析海量数据,并从中提取高价值的信息来推动业务变革。因此大数据的超高效益,确实会改变中小企业与大型企业之间的游戏规则。大数据的关键功能是数据挖掘,模型发现和评估,描述变量“相关性”,对其定义提出四个重点:第一是大小,和数据集体积有关;第二是复杂性,与结构、行为和排列有关;第三是技术,与工具和科技有关;第四是处理巨大和复杂的数据收集。大数据的特点是规模性、多样性、高速性和价值密度。动态竞争力和大数据系统之间的关系是信号理论中的微弱信号,主要描述市场行为,当双方(个人或组织)有机会获得不同信息时,在一般情况下,发送者一方必须知道如何沟通。对方接收到信息后,必须选择如何解释信号。因此,信号理论不断被向前推进,现在已经被广泛应用到企业组织学当中。学者通过信号传递理论,以新方式来开发、解决复杂的配方,以了解细致入微的变化。动态能力通过整合公司资源,构建和重新配置内部能力与外部竞争以应对迅速变化的环境。经过整合公司流程,将资源重新配置,获取和释放相匹配后,以适应市场变化。动态能力是导向能力,帮助中小企业重新部署和配置资源,以满足不断变化的客户需求和应对竞争对手的策略。动态能力是一个集体经验,通过系统组织生成并修改其操作,以追求高效益,经协调整合,重新配置,改造学习等方式,让公司创造出新的产品和工艺,达到修改或创建核心竞争力的效果。实证研究发现,动态能力对战略变革和企业绩效的影响不同。大数据是中小企业信息管理的关键组成部分,与中小型企业的动态能力具有外在共性。根据大数据维度(容量,品种,速度,真实性和价值),提出了动态能力维度符合竞争力的概念。所以,对大数据技术,中小企业,竞争力和动态能力之间的协同关系进行研究,是本文研究的选题目的。基于文献综述和对我国中小企业使用大数据的调查,提出五个动态能力:微弱信号;商业环境传感;业务调整;资源能力转化和资源编排(营销和技术能力/实时分析,学习能力/可视化,协调和整合能力,对环境竞争战略反应)。本文的研究方法使用混合研究方法。第一部分,对国内外二十家中小企业公司进行访问研究,了解他们在业务上对数据的要求,特别是对大数据的期望。这二十家中小企业分布在五个城市,日本东京、欧洲、巴西、香港和新加坡,采用深化非结构化面试的方式来进行访问。第二部分,通过群集分析进行定性内容分析,并对主题重点伸张。然后,制作调查问卷,通过电子调查方法,对约2000份样本进行抽样调查,最终收回电子调查表有600多份。第三部分,利用调查问卷的实证结果来建立中小企业的大数据动态竞争力模型。通过个案访谈,产生三个创新观点。第一是“通过动态能力促使中小企业快速转型和重新配置资源”;第二是“通过大数据手段来提炼微弱信号以强化动态竞争力”;第三是“通过实时大数据以提升中小企业的动态决策能力”。信息技术(大数据)压倒性地解决了原始数据的管理技术,能够把握关键和改造行业,提高了大数据的效益与企业绩效。通过对相关行业的辅助数据进行分析,定义了大数据的吸收能力,通过学习贯彻落实信息技术的相关能力。中小企业的吸收能力并不是简单地聚合公司和行业资源,而是含有其它附加能力,通过整合后最终才能产生效应。吸收能力把内部和外部的信息汇总后变成知识,从而提高适应能力(含动态能力)。本文通过实证研究,最终产生四个解决方案。第一个对策是“建立以中小企业为主导的大数据共享平台“;第二个对策是“建立以中小企为中心的大数据隐私系统”;第三个对策是“建立基于云技术的中小企业营运大数据系统”;第四个对策是“提升中小企业的大数据实时分析能力”。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017020193.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '江西财经大学',
 'keywords': '大数据、互联网+、洞察力、中小企业、动态竞争力',
 'refer': '下载次数（670）| 被引次数（1）',
 'source': '博士论文',
 'time': '2016年',
 'title': '基于大数据的中小企业动态竞争力提升研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 16:52:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 16:52:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'FEED_FORMAT': 'csv', 'FEED_URI': 'wdj1.csv', 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 16:52:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 16:52:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 16:52:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 16:52:03 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 16:52:03 [scrapy.core.engine] INFO: Spider opened
2018-08-01 16:52:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 16:52:45 [scrapy.core.scraper] ERROR: Error processing {'abstract': '当今世界,大数据正渗透到人类社会的方方面面,不仅改变人们的思维方式、工作方式和生活方式,改变社会的生产力与生产关系,而且成为未来的"新石油"、"新金矿"、"新资源"和创新的"新引擎"。自2012年以来,美国、英国、法国、日本、韩国等发达国家陆续将大数据上升为国家战略。经过多年的酝酿,我国2015年召开的党的十八届五中全会,明确提出"实施国家大数据战略"。政府必须和企业、高校及科研机构结盟,全民动员和广泛参与,才能应对"大数据"时代的挑战,高校必将是这次大数据浪潮的参与者和推动者。尽管我国教育大数据领域也存在"乔布斯之间"的困惑,但在研究高校大数据方面具有得天独厚的条件,教育管理大数据研究和应用的前景广阔。管理也是生产力。从某种程度上讲,管理比其它要素更重要。大数据教育管理,是高校教育管理发展的新阶段。一切过去皆为序曲,通过大数据预测规律,通过大数据发现价值,大数据使高校采用更加智慧的方式来激发和生产新的智慧。高校教育管理中的大数据与商业领域中的大数据运用有着根本的区别:高校大数据以相关关系为切入,最终寻找特殊的相关关系——因果关系,知其然并"知其所以然"。利用大数据、云计算和物联网等技术,优化办学要素的结构、提高管理水平,是高校提高办学效益、促进高等教育管理由增量发展向质量发展转变的重要工具和基础。目前,学术界在大数据与高校教育管理结合的系统研究成果不多,深度和广度不够,也缺乏具体的实证研究。本论文从科技哲学、管理学、教育学及社会学的视角,综合分析高校大数据教育管理的价值和潜在的风险,在调研我国高校大数据教育管理发展现状及存在问题的基础上,探寻促进我国高校大数据教育管理创新的对策。本研究的主要内容包括四个方面:一是对大数据进行系统深入研究以尽可能达到科学认识。分析大数据产生的科技背景、经济背景和文化背景,尤其深入分析了大数据与互联网、物联网、云计算等信息技术发展及运用的关系,厘清大数据、信息化与智慧化之间的区别与联系。深度剖析了大数据的本质特征。从大数据所引发的生产力与生产关系改革、政治改革、思维变革、商业变革、教育变革和管理变革等方面,揭示大数据对人类思维、科技、经济、文化、学科发展及社会发展的巨大价值,同时对大数据潜在的思维风险、安全风险、技术风险及伦理道德风险等进行系统研究。二是系统研究大数据对我国高校教育管理发展的积极影响和消极影响。在分析高校教育管理现代化本质特点的基础上,指出我国传统高校教育管理存在人文不足、形式单一、缺乏个性及反馈不足等弊端,这与现代化高校教育管理要求相悖。高校大数据教育管理具有个性化、及时性、科学性、差异性、互动性、整合性及权变性等特点,从而具备传统高校教育管理无法比拟的优势。大数据将对我国高校的数据采集、管理决策、治理模式、教育教学、科研服务、评估评价等方面变革带来机遇。同时,高校大数据教育管理面临着隐私与自由平衡问题、数据霸权问题、数据垃圾问题、数据标准问题以及数据安全等诸多挑战,并产生诸多消极影响。三是研究我国高校大数据教育管理发展现状及存在的问题。高校大数据教育管理是信息化发展的新阶段,运用专家访谈法及问卷调查法等研究方法进行调研发现:经过十多年的发展,我国高校教育管理信息化已经取得一定的成绩,如高校CIO制度已经初步建立,财政投入逐步加大,教育管理成效初显等。但是,我国高校大数据教育管理也存在着缺乏顶层设计、缺乏资金保障、数据人才缺乏、法律法规等支持体系不完善及共享机制缺失等问题。四是思考并提出促进我国高校大数据教育管理发展的对策。按照教育现代化的要求,围绕智慧化、人性化教育管理的目标,针对我国高校大数据教育管理存在的问题,在借鉴美国等发达国家高校大数据教育管理经验的基础上,提出促进我国高校大数据教育管理的对策。高校要树立大数据教育管理理念,坚持以人为本、扬长避短、疏堵结合的原则,通过加强顶层设计,加强制度规约,构建协同机制、分享机制和评价机制,打造数据师资等运维体系建设,从而实现"规避风险、发挥优势"的大数据发展目标。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017192249.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '武汉大学',
 'keywords': '高校、大数据、教育管理、影响、对策',
 'refer': '下载次数（6658）| 被引次数（17）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据对我国高校教育管理的影响及对策研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:47 [scrapy.core.scraper] ERROR: Error processing {'abstract': '近年来,大数据的思维和方法在社会经济生活领域引起了一场巨大变革,也为政府公共部门带来了新的机遇和挑战。在实践层面,各国政府都对大数据在公共管理中的决策支撑作用表示了肯定,但是对于大数据的使用是较为分散的,主要集中于医疗、交通、教育、舆情预测、消费预测等个别领域,且在这些领域中的应用主要以处理日常管理内容和应对突发紧急事件为主,而对于如何使用大数据支撑政府公共政策的制定尚没有通用的实践策略。在学术研究层面,众多学者也对大数据在促进政府信息公开、决策科学化、管理精细化等方面的作用提出了期望,认为其能够带来新一轮的公共管理变革。但是在公共管理和公共政策学术研究层面,对大数据方法的研究仍处于较为肤浅的介绍和讨论阶段,尚没有形成使用大数据工具辅助政策研究和政策分析的方法论。因此本文致力于研究大数据方法在公共政策研究中的应用问题,并选择了知识产权政策这一子政策体系作为研究的对象。大数据方法与其他所有类型的研究方法相同,都不是万能的而是有其适用边界的,并不是所用公共政策类型都适合使用大数据方法进行研究。知识产权政策领域在使用大数据方法方面具有天然的优势,知识产权政策相对于其他子政策类型,其研究资料的数据化程度较高,且具有数据化研究传统,表现为专利计量研究、专利情报研究等。因此,与其他政策领域相比,大数据方法在知识产权政策研究领域更加容易推进。也正是由于这个原因,本文选择知识产权政策体系作为大数据在公共政策研究中应用的具体对象。本文研究的是大数据方法在知识产权政策研究中的应用问题,属于多学科的交叉型研究,研究共由六章组成。第一章是绪论,主要探讨了研究大数据方法在知识产权政策研究中的应用问题的重要性。指出大数据方法是知识产权政策研究方法体系的重要组成部分,对于该问题的研究可以为知识产权政策研究增添新的研究工具。第二章是全文的理论基础,系统性地梳理了政策科学理论、科技政策理论、知识产权政策体系以及大数据的内涵和构成。政策科学理论中的政策过程理论为第四章的研究提供了基本框架,而对于科技政策、知识产权政策体系的梳理则对明确知识产权政策研究的范围和边界提供了理论指导,对于大数据内涵和构成的整理更是对之后三个章节具体分析提供了支撑。第三章讨论了知识产权政策研究中的数据来源问题,大数据对于知识产权政策研究的影响首先表现为对其数据来源的变革。主要探讨了传统知识产权政策研究的数据来源以及在大数据技术的影响下,研究者可以拓展的新兴知识产权政策数据来源。第四章探讨了大数据对具体知识产权政策过程的影响,依据公共政策实践中的政策过程,对于大数据方法的具体应用展开了细节性的讨论。主要依据安德森的政策过程五阶段划分方法,将知识产权政策的研究过程划分为政策议程、政策制定、政策选择、政策实施、政策评估五个阶段,并针对每一个具体政策过程中大数据技术的具体应用进行了展开,并在最后总结了大数据技术在知识产权政策具体过程应用中的作用。然而大数据除了会对传统公共政策过程实践产生影响以外,还会在更基本的层次对公共政策理念产生影响。因此,本文在第五章探讨了大数据工具对知识产权政策研究产生的变革性影响,包括政策规则算法化和政策调整动态化。第五章所探讨的两种变革具有一定的超前性,在现阶段还缺乏实施基础,但是未来政策研究发展的一个潜在方向。第六章是对大数据在知识产权政策应用中的评价以及全文的总结和展望。大数据虽然会对公共政策以及知识产权政策的研究产生影响,但是大数据在政策研究中也有其优势、劣势以及需要面对的挑战,这些问题也是研究者需要面对的难题。通过第三章、第四章、第五章、第六章的研究,初步形成了知识产权政策大数据研究的方法论体系,包括大数据对政策研究数据来源的影响,大数据对具体政策过程的影响,大数据对于政策理念基础的影响,以及对于大数据在政策研究中的应用的评价。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016107334.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中国科学技术大学',
 'keywords': '知识产权、政策、大数据、方法论、研究方法、方法应用',
 'refer': '下载次数（1550）| 被引次数（2）',
 'source': '博士论文',
 'time': '2016年',
 'title': '知识产权政策研究中的大数据方法应用研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:49 [scrapy.core.scraper] ERROR: Error processing {'abstract': '互联网时代数据信息正以惊人的速度膨胀,同时呈现出多元化和碎片化的趋势。如何合理利用这些错综复杂的信息,并将其有效运用到工作中,充分发挥大数据的价值显得迫在眉睫。基于以上背景,笔者认为在大数据时代,结合大数据的基本知识,对产业经济信息的分析进行系统研究,将有助于产业大数据的应用实践。未来,充分利用大数据的价值将推动产经部门工作发生革命性变化。本文以此为切入点,结合工作实际,系统分析大数据背景下产经信息的分析方法及其在宏观决策中的作用,并以钢铁行业和企业为例进行实证分析。本文以大数据基本理论和产业经济信息模型入手,结合产业经济信息分析方法,系统分析了大数据对宏观经济的服务价值。钢铁行业信息是产经信息的一个重要组成部分,本文重点分析了钢铁行业大数据应用,搭建了钢铁行业数据信息框架,运用大数据支撑技术,分析钢铁行业质量控制系统、成本管理系统、生产计划编制和电商平台建设等方面的应用。充分利用大数据分析,将数据获取、分析、提炼运用到钢铁行业的各个环节,极大地提高了钢铁行业获取、分析和运用数据信息的能力,推动钢铁行业的转型升级。最后以某钢企大数据的实施与应用为例进行实证分析,钢铁企业依托大数据技术,从数据采集、存储、分析和应用等环节构建大数据链条,并充分运用到生产、营销和管理中,实现数据集成和管理模式的融合,打造智能、高效的管理模式,培养在同行业中的核心竞争力。通过以上分析,本文得出以下结论:第一,运用大数据进行产业经济信息分析,提升信息分析效率是大势所趋。产业经济信息分析将会完全融入到从相关从业者到国家权威管理部门的服务中,但产经信息的分析仍需深层次挖掘大数据的价值。第二,产业经济信息分析虽需要借助大数据技术平台,而分析的关键在于不同行业、部门和机构的数据信息能够实现共享,并加以有效整合。第三,在大数据时代,将大数据技术充分运用到钢铁行业等传统行业中,有助于提高钢铁企业的生产效率和管理能力,提高行业和企业决策的科学性,有效改善钢铁行业产能过剩的状况,推动行业转型升级。钢铁行业须紧抓大数据时代的契机,打造钢铁行业大数据支持平台,构建大数据中心,并运用到钢铁行业全产业链中,从源头到终端进行科学管理,为进入工业4.0时代扫清障碍。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016184042.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中国地质大学(北京)',
 'keywords': '大数据、产业经济信息、宏观决策、钢铁行业',
 'refer': '下载次数（2502）| 被引次数（7）',
 'source': '博士论文',
 'time': '2016年',
 'title': '大数据时代产业经济信息分析及在宏观决策中的应用——以钢铁行业为例'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:50 [scrapy.core.scraper] ERROR: Error processing {'abstract': '本文通过对大数据的内涵、特征、前沿技术以及发展脉络的梳理,并结合利用微博大数据进行战略预见的案例研究,提出了基于大数据的战略预见,详细论述了该新型战略预见方法所带来的思维、方法论以及价值取向的变化。本文认为大数据有希望带来一个平行于自然世界和精神世界的数据世界。从战略预见的角度来看,基于大数据的预见是一种数据驱动的经验模型,它是一种不同于传统的逻辑加经验的预见模式。这种新的战略预见方法无疑将大大拓展人类认识和可预见的范围,并加强战略预见的工具理性,促进战略逻辑中价值理性和工具理性的统一。另外,本文对数据权、数据伦理以及大数据推进战略文明转型等问题进行了比较深入的哲学反思。下面将简述论文的行文结构。第一章将解析大数据的基本概念,发展历史及潜在风险。本章将介绍大数据的定义、特征、分类、主体以及前沿技术。其次,通过回顾大数据的发展历史,介绍科学研究的“第四范式”,即数据密集型科学。最后对大数据引发的一系列伦理问题进行考察。第二章首先讨论了战略预见的逻辑与意涵,并分析预见在战略思维、战略环境以及应对危机中的重要作用。其次,通过梳理三种经典的战略预见方法,展示了在大数据时代多种战略预见方法互补应用的重要性,以及基于大数据的战略预见的可能性。第三章首先分析了大数据作为战略预见的必要性。通过细述微博大数据进行战略预见的具体方法,展示了对“十八届五中全会”的网民态度以及对商业保险和社会保险替代关系这两组具体预见的案例。依托案例,本章总结了大数据作为战略预见的六项方法特征,分别是整体性、相关性、不确定性、网络化、众包化与人工智能化。第四章将对基于大数据的战略预见进行哲学反思。本章针对大数据作为战略预见的方法论和价值论进行思考。从方法论的角度来说,大数据作为战略预见不同于经典预见方法的逻辑加经验的模式,而是倡导一种数据驱动的经验模型,同时,大数据有希望带来平行于自然世界和精神世界的数据世界,将大为拓展人类认识和可预见的范围。在利用大数据进行战略预测的过程中,也要谨防数据拜物教的负面影响。从价值论的角度来说,本章讨论了大数据的技术价值与社会价值,以及新的战略制权——数据权的产生,还有大数据对人的自由全面发展的推动作用。论文完成之后,期望在战略运用方面对数据人才培养、新型智库建设、国家数据安全战略等问题提供有益的参考。最后,论文进行了总结与展望。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016210100.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '中共中央党校',
 'keywords': '大数据、方法论、战略预见、战略、大战略',
 'refer': '下载次数（2409）| 被引次数（2）',
 'source': '博士论文',
 'time': '2016年',
 'title': '基于大数据的战略预见研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:52 [scrapy.core.scraper] ERROR: Error processing {'abstract': '在大数据时代,中国出版产业面临着新的业态转型和产业链重构的艰巨任务。如果说互联网通过重塑人类交往方式而改变了传统的出版生产体系和市场体系,那么,大数据则通过改变人类社会的信息和数据处理方式进而改变着传统的出版生产体系和市场体系。出版业兼具信息产业、文化创意产业和新闻传播业等多重属性,是以内容和服务创新为特征的知识型产业类别。大数据时代的大数据技术、大数据科学、大数据思维和大数据平台都特别适用于出版业进行知识创新和信息传播。当前,在中国进行以知识创新推动产业升级,着力建设“创新型国家”的大背景下,大数据是中国出版产业进行业态创新和产业链重构的必然选择。研究大数据条件下中国出版产业链的重构问题涉及传播学、出版学、产业链理论以及大数据理论等多学科理论。在大数据条件下,“按需出版”、“按需印刷”、“自主出版”、“众筹出版”等新出版模式不断出现,揭开了大众传播与分众传播关系的新篇章,大众传播与分众传播并存是大数据时代传播学融合的创新基础,分众传播体系和大众传播体系不是取代关系,而是并存关系,只是这种并存关系随着环境的变化在不断此消彼长。在大数据时代,“媒介即人”的传播学理念有了进一步的诠释,“数字的本质是人,数据挖掘就是在分析人类族群自身”,因此,基于大数据的“定制出版”,“分众出版”、“碎片化出版”等新出版方式的出现揭示着从聚众时代的人类族群到分众时代的人类族群关系的变化。大数据时代出版产业链的重构有三个维度：出版价值链维度、出版供需链维度和出版空间链维度。出版价值链是出版产业链价值关系的维度表达,出版供需链是出版产业链供需关系的维度表达,出版空间链是出版产业链空间关系的维度表达。任何产业活动都存在价值关系、供需关系和空间关系,出版产业也不例外,也存在着价值关系传递、供需关系关联和空间关系变迁。基于大数据进行出版价值链重构,其所运用的大数据原理包括：一是基于大数据的“相关性”理论推动出版价值链重构；二是基于大数据的“全数据原理”推动出版价值链重构；三是基于大数据的“第四范式”推动出版价值链重构。发挥大数据价值功能重构出版价值链的基本任务：一是基于大数据关系理解功能创新出版产品形态组合：二是基于大数据的用户挖掘功能创新市场用户组合;三是基于大数据的信息挖掘、用户挖掘和关系理解综合功能再造出版价值链结构。重构的立体、多元、网状的价值链可以尝试用2+++模型来概括,即2种介质(纸介质+光电介质)2种资源(内容资源+数据资源)、2种服务(产品服务+体验服务)。基于大数据对出版供需链进行重构的逻辑是：一是作为稿源的出版资源生长逻辑的转换；二是作为供需链驱动力的产业发展逻辑的转变；三是作为供需终端的市场成长逻辑的转换。基于大数据建构的出版供需链模型是立体、多维、柔性的网状结构,这种出版供需链可以尝试用2+++模型来概括,即2种作者稿源(专业作者+业余作者)、2种出版生产方式(标准出版+按需出版)、2种市场划分(大众市场+分众市场)。基于大数据进行出版空间链的重构,其基本任务：一是在出版产业层面实现出版地域空间和出版网络空间新组合以及凭藉“三业融合”扩大出版产业运行空间范围；二是在出版业务层面实现有限空间向无限空间以及单业务空间向多业务空间的拓展。基于大数据建构出版空间链有两个新的构造,一是存在空间+选择空间+活动空间的网络空间构造,二是纸质版+网络版+手机版的媒介空间构造。基于大数据实现出版产业链重构,存在着诸多不同层面的障碍和问题,但大数据时代中国出版产业链的重构是大势所趋,而基于大数据的出版产业链重构的产业形态应该是智能出版。智能化是大数据应用的高级境界,如果说大数据时代城市化的出路是“智慧城市”,商业化的出路是“智能商务”,那么,出版现代化的出路则是“智能出版”。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1015593301.nh&dbcode=CDFD&year=2015&dflag=cajdown',
 'institution': '华中科技大学',
 'keywords': '大数据、大数据时代、出版产业链、出版产业链重构',
 'refer': '下载次数（2165）| 被引次数（10）',
 'source': '博士论文',
 'time': '2015年',
 'title': '大数据时代中国出版产业链的重构'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:53 [scrapy.core.scraper] ERROR: Error processing {'abstract': '当前,随着人类社会数据规模和种类的飞速增长,大数据时代已经到来,大数据的特性与治理理论在"多元化、扁平化、协作化"等方面相互契合,并将革命性地推动政府治理向现代化方向发展。论文围绕大数据技术对政府治理现代化的影响,对基于大数据的政府治理现代化体系、评价模型以及建设路径等内容进行了系统研究,提出了应用大数据推进政府治理现代化的对策和建议,这将有助于客观的认识政府治理现代化问题,为政府利用大数据技术推动治理理念的创新和治理模式的变革提供了参考依据,具有重要的理论意义和现实意义。作者从系统科学视角对大数据重新进行定义,指出大数据是由海量的、分层次的、相互纠缠的全数据集组成的具有自组织性的、动态的、开放的大系统数据集,并提出了大数据"集量成智"的本质特性;通过理论研究和比较研究,提出了基于大数据技术的"DW神经系统型"政府治理机制;通过案例研究分析了大数据对政府治理现代化的积极影响,剖析了面临的风险和挑战;通过实地研究对河南省鹤壁市政府治理现代化有关情况进行了问卷调查,对行政工作效率等12项内容进行了满意度分析;运用PEMSTI特征指标分析模型从人口、经济、工业、服务、交通和信息化六个维度对鹤壁市政府治理现代化情况进行了评价;通过定性研究,提出了鹤壁市政府治理现代化的建设路径;最后采取宏观与微观相结合的方法,对应用大数据推进政府治理现代化的对策和建议进行了探讨。通过研究,作者得出如下结论:1.大数据时代,强烈的政治诉求、公民权利的现实压力,以及传统政府治理存在的种种弊端,共同形成了对政府治理走向现代化的迫切需求。2.海量数据的集聚和相互作用的过程,能够实现数据创造智慧的过程,即"集量成智"。基于大数据技术的"DW神经系统型"政府治理机制,将摆脱"随机抽样"和"因果逻辑"的研究范式,通过"全样本分析"和"相关性分析"等方法获得智慧,并被运用到政府治理领域,打破拉塞尔·阿克夫提出的"数据—信息—知识—智慧"(Data-Information-Knowledge-Wisdom)关系,形成一种"数据—智慧"(Data-Wisdom)的新型关系。3.大数据对政府治理的结构、机制、职能、工具、能力、评估等6个方面具有重要的积极影响:一是多元的治理结构,从垂直走向扁平,从单一走向多元;二是规范的治理机制,从人治走向法治,从封闭走向透明;三是人本的治理职能,从全能走向有限,从管制走向服务;四是现代的治理工具,从强制走向协作,从经验走向数据;五是高效的治理能力,从粗放走向精准,从被动走向主动;六是科学的治理评估,从定性走向定量,从定时走向实时。但是,目前存在的数据异化、信息失真、数据垄断、隐私泄露等风险也不容忽视。4.基于大数据的政府治理现代化具有6方面表现:在治理结构方面呈现治理主体多元化、组织结构扁平化;在治理机制方面呈现信息公开透明化、治理机制法治化;在治理职能方面呈现资源配置市场化、公共服务人本化;在治理工具方面呈现治理方式数据化、社会管理协作化;在治理能力方面呈现行政决策精准化、危机管理预知化;在治理评估方面呈现绩效管理科学化、纪检监察监控化。5.探讨了政府治理现代化的评价方法,通过对传统方法的对比和改进,确定了人口、经济、工业、服务、交通和通信六个维度为模型指标,提出了PEMSTI特征指标分析模型。6.以鹤壁市为例,进行满意度问卷分析得出,民众对政府治理现代化的总体满意度为81.2%,其中对"公众参与治理便利程度"的满意度最高,达到了92.9%;而对"弱势群体覆盖水平"的满意度较低,只有64.7%。通过PEMSTI特征指标模型分析得出,一是政府治理现代化水平受人口和经济总量影响较大,经济越发达,政府治理现代化水平越高。二是随着政府治理现代化工作的实施,鹤壁市各项指标增长迅速,特别是现代服务业、通讯电信业方面增速明显,均位于其他样本城市的前列。三是鹤壁市各项指标呈现单项指针形态,整体发展仍不均衡。在政府治理现代化的建设路径方面,鹤壁市应采取以政府投资建设为主导,以公私合营的模式为辅助,以创新驱动发展,重点做好城市管理业务、社会民生业务、科技文化业务、资源环境业务和产业经济业务方面的治理服务。7.关于应用大数据推动政府治理现代化建设的问题,作者提出了合理定位政府角色、创新行政工作机制、全面实施大数据战略、打造统一数据信息平台、加强人才储备力度、动员民众广泛参与、优化投资融资模式等主要对策建议。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017164593.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '中国农业大学',
 'keywords': '政府治理现代化、大数据、DW神经系统模型、PEMSTI特征指标分析模型、建设路径',
 'refer': '下载次数（3374）| 被引次数（3）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据对政府治理现代化的影响研究——以鹤壁市为例'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:54 [scrapy.core.scraper] ERROR: Error processing {'abstract': '我国网民居世界之最,随着大数据时代的到来,大学生作为网民中的一个重要群体,深受其影响。大数据时代,数据呈现爆炸性增长,数据分析能力快速进步,一切皆可量化,数据成为重要的生产要素,人类的思维理念面临革命性的变革。大学生群体作为当代青年的优秀群体,思想最为活跃,最善于接受新鲜事物,最能适应时代要求。没有了地域界限、传统束缚、师长权威,而主张崇尚自我、标新立异的网络空间,没有了信息滞后、信息不对称,而充满着海量信息的大数据时代,给大学生提供了与以往时代迥然不同的社会基础。大数据时代的到来,既给大学生道德教育带来了前所未有的挑战,也为创新大学生道德教育提供了新的机遇。本研究以马克思主义理论为指导,综合运用法学、哲学、教育学、心理学并结合信息学、传播学、管理学、计算机科学、数据科学的知识进行交叉学科研究,整体上遵循从实然到应然的研究思路,从分析大数据时代的内涵和特征及对大学生道德教育的影响入手,力求从大数据时代大学生道德教育的指导思想与基本原则、内容与方法、措施与机制等方面提出系统教育的建议对策。本研究由导论、正文和结论三个部分组成。导论,主要阐述了本研究的选题缘由和选题意义,通过对国内外研究现状进行综述,厘清了研究思路和研究方法。第一章,大数据时代与大学生道德教育的基本问题。概念的厘定是研究的逻辑起点,大数据时代是本研究的时代背景,大学生道德教育是本研究的核心内容,因此,本章详细论述了大数据和大数据时代的内涵与特征,大数据时代的产生背景和发展趋势,分析了不同学者对道德和道德教育概念的阐释,在此基础上提出了大数据时代大学生道德教育的概念,并详细分析了大数据时代给大学生道德教育带来的影响。第二章,大数据时代大学生道德教育的重要性。面对大数据时代的影响,全球化、信息化和市场化带来的全方位多层次的挑战,大学生道德教育面临前所未有的机遇与挑战。本章分析了开展大数据时代的大学生道德教育研究是顺应了大数据时代带来的机遇与挑战,能够促进大学生在大数据时代更加全面的发展,实现道德教育在大数据时代的信息化发展。第三章,大数据时代大学生道德教育的指导思想和基本原则。理论是行动的先导,思想是行动的指南,原则是行动的准则。本章分析了马克思、恩格斯、列宁和我国党和国家领导人关于道德教育的思想,分析了大数据时代大学生道德教育基本原则,这对于开展大数据时代大学生道德教育提供了理论支撑,对大学生道德教育实践起着重要的导向作用,能够推动大学生道德教育活动的顺利开展和实施,为教育者如何开展大学生道德教育工作指明方向。第四章,大数据时代大学生道德教育的内容与方法。大学生个体的道德发展包括知、情、意、行四个方面,这四个方面交互影响、动态发展。大数据时代,处于转型期的中国,社会各个方面都受到了深刻影响,教育的网络化、信息化、数据化改变着教育活动自身。本章针对大数据时代的特点,整合知、情、意、行的教育内容和教育方式,采用网络道德教育与现实道德教育相结合、数字技术与人文精神相结合、数据思维与传统经验相结合、情境认知与泛在教育相结合的教育方法,以期提高大学生道德教育的针对性和实效性。第五章,大数据时代大学生道德教育的措施与机制。随着我国社会主义市场经济的深入发展,社会结构的深刻变革与转型,同时受到西方思潮和后现代主义的影响,伴随着大数据时代的到来,当代大学生思想的独立性和差异性不断增强。这在客观上要求大数据时代的大学生道德教育需要有新的视角,并积极灵活地探索新的教育措施和教育机制。本章分析了大数据时代大学生道德教育的措施,包括制定大数据发展战略、构建大数据教育模式、培养大数据素养、完善大数据政策与法律法规等。分析了大数据时代大学生道德教育的机制,包括预测预警机制、数据化管理机制、开放性机制、评价机制与保障机制,使大数据在大学生道德教育中发挥出其独特的优势。结论,社会实践的不断发展和需要推动着理论的产生与更新,只要信息技术在不断发展,大学生道德教育研究就不应止步。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017803510.nh&dbcode=CDFD&year=2015&dflag=cajdown',
 'institution': '西南大学',
 'keywords': '大数据时代、大学生、道德教育',
 'refer': '下载次数（1885）| 被引次数（0）',
 'source': '博士论文',
 'time': '2015年',
 'title': '大数据时代大学生道德教育研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:55 [scrapy.core.scraper] ERROR: Error processing {'abstract': '随着计算机和信息技术的迅猛发展和普及应用,行业数据爆炸性增长,全球已经进入了“大数据”时代。大数据已引起全球业界、学术界和各国政府的高度关注。大数据已经渗透到各行各业,巨大的数据资源已成为国家和企业的战略资源。大数据给全球带来了重大的发展机遇与挑战。一方面,大规模数据资源蕴涵着巨大的商业价值和社会价值,有效地管理和利用这些数据、挖掘数据的深度价值,对国家治理、社会管理、企业决策和个人生活将带来巨大的影响。另一方面,大数据带来新的发展机遇的同时,也带来很多技术挑战。格式多样、形态复杂、规模庞大的行业大数据给传统的计算技术带来了巨大挑战,传统的信息处理与计算技术已难以有效地应对大数据的处理。因此,需要从计算技术的多个层面出发,采用新的技术方法,才能提供有效的大数据处理技术手段和方法。大规模数据的有效处理面临数据的存储、计算和分析等几个层面上的主要技术困难。首先,动辄达到数百TB级甚至PB级规模的行业大数据,远远超出了传统数据库系统的处理能力。因此,需要研究提供有效的分布式大数据存储管理技术方法与系统。同时,大规模数据处理是一个非常耗时的计算过程,使得传统的单机系统远远无法满足大数据对计算性能的要求。因此,需要研究提供高效的并行化大数据计算技术方法与系统。进一步,大数据的有效分析利用通常涉及到对大规模数据的分析挖掘,而巨大的数据量使得传统的单机机器学习和数据挖掘算法都难以在可接受时间内完成计算,导致算法失效。因此,需要研究提供有效的并行化大数据机器学习与分析挖掘算法和大数据机器学习系统。大数据处理不同于传统的计算与信息处理技术的另一个重要特点是,它是一项涉及计算与信息处理技术众多方面的综合性技术,具有显著的技术综合性和交叉性特征,以任何一个单一和隔离的技术层面和技术方法,都难以有效完成大数据的处理。因此,大数据的有效处理需要将存储、计算与分析层面的技术紧密结合、交叉综合,以形成一种完整的大数据处理技术栈,构成一体化的大数据处理系统平台。基于以上问题背景,本文对大数据处理的多个技术层面进行了深入研究,在分布式存储技术与系统、并行化计算技术与系统、以及大数据并行化机器学习与数据分析算法与系统方面,进行了一系列的研究。具体而言,本文工作包括以下主要技术内容和贡献：(1)大数据分布式存储管理技术与系统研究。主要开展了三方面的研究工作。1)为了提升大数据分布式存储系统的性能,研究实现了分层式大数据存储系统缓存调度策略与性能优化方法,可显著提高分布式存储系统数据访问的性能；2)研究实现了一种通用的分布式文件系统性能测试方法与系统工具,可以用于各种分布式文件系统的性能评估和研究优化,或者用于大数据应用系统设计时选择合适的存储系统和参数优化配置；3)研究设计了分布式层次化大规模RDF语义数据存储技术与管理系统,可有效地存储管理大规模RDF语义数据。(2)主流大数据并行计算系统性能优化研究。主要研究了两方面的工作。1)Hadoop '
             'MapReduce作业执行调度优化技术,研究实现了优化的MapReduce作业与任务调度处理方法以及高效的任务执行状态通信方法,实现了一个与标准Hadoop完全兼容的优化版本Hadoop; '
             '2) Spark RDD数据堆外(Off '
             'Heap)内存存储机制,针对Spark在处理大规模数据性能受到JVM垃圾回收严重影响的问题,研究实现了一种基于分布式堆外内存存储的Spark '
             'RDD数据存储机制。(3)大数据并行化机器学习与数据分析方法与算法研究。主要研究实现了多个应用领域的复杂大数据机器学习与数据分析并行化算法,包括：1)针对数据挖掘领域中大规模神经网络训练性能低下的问题,研究实现了一个定制式大规模神经网络训练并行化算法与计算平台cNeural;2)针对在搜索引擎和信息检索领域重要的排序学习(Learning '
             'To Rank)算法GBRT (Gradient Boosting Regression '
             'Tree)训练耗时较长的问题,研究提出了基于K-Means直方图近似算法优化的加速方法及其并行化算法；3)针对语义网推理领域中RDFS和OWL推理规则集在大规模语义数据上推理耗时过长的问题,研究实现了基于Spark并行计算平台的高效并行化推理方法与系统。(4)统一大数据机器学习与数据分析编程模型与系统平台研究。针对大数据分析处理时面临的系统平台可编程性和易用性问题、以及大数据分析处理时的计算性能问题,研究提出了一种基于矩阵模型的统一大数据机器学习与数据分析编程模型与框架,并进一步设计实现了一个跨平台统一大数据机器学习与数据分析系统平台Octopus(大章鱼),该系统底层可与Hadoop、Spark、MPI、Flink等主流大数据平台集成,实现底层平台对上层数据分析程序员的透明性,而上层可使用R/Python编程语言与编程开发环境,基于矩阵模型,方便高效地完成大数据分析算法和应用的编程和计算。通过对上述大数据分布式存储、并行化计算、以及大数据分析层面关键技术方法与系统的研究,本文取得了一系列研究工作成果,这些成果可作为重要支撑技术与系统,有效运用于构建一体化的大数据处理系统平台。本文部分成果已经被成功运用于工业界的开源或者商业化大数据处理系统或应用产品中。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017008183.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '南京大学',
 'keywords': '大数据处理、分布式存储管理、并行化计算、性能优化、机器学习并行化算法、大数据分析编程模型、大数据机器学习系统',
 'refer': '下载次数（6953）| 被引次数（11）',
 'source': '博士论文',
 'time': '2016年',
 'title': '大数据处理技术与系统研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:57 [scrapy.core.scraper] ERROR: Error processing {'abstract': '近年来,尽管我国的税收信用建设取得了一定成就,但是当前税收信用缺失现象依然十分严重,纳税人偷逃税款、征税人收过头税、用税人预算不透明、税务中介合谋等现象屡见不鲜,亟需建立一个完善的税收信用体系。大数据时代的来临为我国税收信用体系的建设提供了良好的契机,大数据在税收领域的应用将会对税收信用理论研究和实践应用产生深刻的影响,因此研究大数据在税收信用建设方面的作用和影响正当其时。国内外学者对税收信用的研究主要集中在纳税信用方面,很少对征税信用、用税信用和税务中介信用进行全面的研究,尤其是大数据时代下税收信用建设的研究更是少见。本文提出了包含纳税信用、征税信用、用税信用和、税务中介信用四个方面的比较全面的税收信用研究框架和内容,并全面分析和研究大数据对税收信用的影响,以期揭示大数据时代下税收信用建设的特征和规律,为大数据时代下的税收信用建设提供参考,具有较强的理论意义及现实意义。构建比较全面的税收信用体系,建立税收信用的完整框架,并研究大数据对税收信用的影响和规律,也是本文在研究框架以及内容上尝试的创新。通过对大数据以及税收信用相关理论概念进行梳理,第二章得出了本研究的理论基础以及研究方法。税收信用从某种角度上说是纳税人、征税人、用税人和税务中介等具有契约特性的博弈关系,大数据的应用会改变或消除税收博弈双方的信息不对称状态,改变博弈均衡结果,从而对税收信用产生影响。基于此种考虑,本文利用信息经济学及博弈论相关理论的分析方法和逻辑思维全面分析大数据时代下的税收信用建设。第四章对纳税人、征税人、用税人、税务中介的信息特点和优势进行了分析,进而总结分析了他们之间的信息不对称的具体表现,正是这种信息不对称严重制约着我国税收信用的发展。而税收大数据不仅涵盖了海量的涉税信息,大数据技术的应用能够充分挖掘和发挥海量涉税信息的价值,在一定程度上会减弱甚至消除纳税人、征税人、用税人、税务中介之间的税收信息不对称状态。至此,提出了大数据对税收信息不对称乃至税收信用影响的理论依据。为了深入分析大数据对税收信用的影响,本文第五章构建了一系列的模型,并尝试将大数据因素纳入模型中,模型包括:纳税信用博弈模型、征税信用委托-代理模型、用税信用声誉模型、税务中介信用博弈模型等。具体的分析过程如下:首先进行了理论分析以及假设,提出大数据对税收信用影响的理论依据以及提出大数据影响的待检验假设;其次,通过博弈论以及委托-代理理论的基本知识建立模型,并进行分析和求均衡解;最后结合模型的均衡解,得出大数据对税收信用建设的影响。通过一系列分析,本文主要得出以下基本结论:(一)纳税人是否选择诚信纳税与税务机关的稽查成本Ct、税务机关能否稽查出纳税人偷漏税的概率ε有关。大数据的利用会通过降低税务机关的稽查成本,提高税务机关稽查的技术,进而降低纳税人偷税漏税的概率,这将最终有利于提高纳税人的税收信用;(二)通过分析求解信息不对称和信息对称条件下的委托-代理模型,得出在信息对称条件下征税人(税务机关)作为代理人工作努力程度更高,政府部门的最优收益更大,因此大数据的运用有利于征税信用建设;(三)政府的税收效用与纳税人对政府信用的预期正相关,然而大数据对纳税人的预期、博弈均衡结果以及用税信用的影响是错综复杂的;(四)大数据的应用会降低税务机关的稽查成本,提高税务机关稽查成功的概率,加大税务中介合谋的损失等一系列效果,最终会有利于税务中介的信用建设。通过以上五章的分析,本文进一步明确了大数据对我国税收信用建设的促进作用,科学合理的运用大数据会给我国的税收信用建设带来重大发展机遇。因此,加快构建与大数据时代相适应的税收信用体系是当前税收信用建设工作的重中之重。最后,基于以上研究的结论,结合我国税收信用建设现状,本文提出大数据时代下我国的税收信用体系建设的政策性建议。主要包括两个部分:一是完善大数据下税收信用建设基本要件,以及实行一些具体措施;二是完善纳税人信用等级评定制度、加强征管环节的税收信用、重视税务中介的信用建设等建议。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1018031683.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '中共中央党校',
 'keywords': '税收信用、大数据、税收博弈、信息不对称',
 'refer': '下载次数（237）| 被引次数（）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据时代下的税收信用建设研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:58 [scrapy.core.scraper] ERROR: Error processing {'abstract': '在我国,中小企业大部分由创办人经营,由于缺乏资源,需要长期依赖企业家的创新精神来促进业务增长。尽管如此,中小企业在我国经济发展中起着非常重要的作用,不同的资源导致中小企业有着不同的表现,因此,有必要让中小企业通过识别和利用创新的机会,提出计划目标和组织长期的策略。同时,通过与外部环境相配合来实现战略竞争力,从而获得高于平均水平的回报。创新战略精神可以促使中小企业管理和识别可持续的竞争优势,从而推动中小企业发现新商机和加强管理与协调资源。在我国经济发展中,中小企业起主导作用,占99.5%以上,是国民经济和社会发展的重要基础。中小企业的迅速发展已成为我国市场经济的重要成员,带动社会生产力的发展。因此,越来越多的中小企业通过“瓶颈资产”来建立竞争优势,以创造、组合、转移、积累和保护无形资产。从核心竞争力中演化而来的资源基础理论强调企业的竞争优势在于宝贵的有形和无形资源,由于资源具有异质性,因此能够将短期的竞争优势转化为持续的竞争优势。大部分的中小企业家善于辨别机会,信息来源是他们决策的关键,而快速反应和分析能力能够给中小企业带来持续的竞争优势,因此也是值得关注的核心竞争力。这种核心能力被称为动态能力或动态竞争力。动态能力是一个很难确定企业特质的潜在因素,最初被定义为“企业发挥整合能力,创建和重构内部和外部资源,形成竞争力,以应对变化多端的环境。”企业通过改变资源和例程的能力来承认面临着的动态变化的市场环境,并对一些企业之所以能有更好的生存机会做出解释。动态能力强调学习,通过“信息”获取有关资料,并瞄准与之匹配的内部资源配置环境,诱发公司对资源进行调整配置,导致内部优势和短板通过识别来应对外部所带来的机会和挑战。“变化”是下一个合乎逻辑的过程步骤,包括创造潜在反应的刺激,从信息处理步骤产生的“评估”和“选择”替代方案。最后,“保留”已实现的资源配置。通过对动态能力和吸收能力相互作用,导致作战能力提升,从而提高企业的竞争优势,建成”基于知识的动态能力模型”。企业不仅要从市场环境中发现新知识,也要对内部反应做出反馈,利用应用结果和重新配置的重点来组织学习。吸收能力和动态能力之间的链接是相辅相成的,通过动态能力和学习,有助于更好地理解知识。动态能力的作用是把各种概念集合或汇总,而吸收能力则是通过与学习相结合,具体有:“采集”识别和获取外部知识,“同化”整合知识;“变换”外部新知识与已有的知识相结合,和“开发”外部知识来实现组织目标的应变能力。这四个维度是必然的探索、同化的过程,通过转化和利用式学习,有助于提高经营业绩,创建竞争优势,利用其创新性和战略灵活性,以适应变化和提升竞争力。成功的吸收能力是持续竞争优势的动态能力,实时分析则是信息管理中的重要工具,同时可以解决微弱信号理论中的信息不对称问题。实时(或低延时)大数据分析可以改变游戏规则,由于客户和市场是稍纵即逝的,因此在出现或消失之前,中小企业有机会通过微弱信号来识别和采取行动。基于服务位置大数据有着庞大的商业潜力,该数据的优点是可实时访问关键数据源,并找出业务指标。实时数据的匹配决定了创造性的思维和预测分析,使业务流程产生改变,实现对企业利益相关者进行预测和优化。这些新的理念,可以帮助中小企业设想整套方案,并推出具体的措施。因此,在不同的决策情况下,评估潜在于各项业务活动中。另外,企业高管特别重视大数据技术在中小企业制定竞争战略时所起到的重要作用,及其决策特异性的发挥。如今,大数据彻底改变了中小企业的业务模型,提出了新见解和客户互动方式,通过分析竞争对手的信息从而提高盈利能力,实现策略改变和实时交付。不同来源的数据,经过勘探,体现价值。新信息技术能够在几秒钟内访问和分析海量数据,并从中提取高价值的信息来推动业务变革。因此大数据的超高效益,确实会改变中小企业与大型企业之间的游戏规则。大数据的关键功能是数据挖掘,模型发现和评估,描述变量“相关性”,对其定义提出四个重点:第一是大小,和数据集体积有关;第二是复杂性,与结构、行为和排列有关;第三是技术,与工具和科技有关;第四是处理巨大和复杂的数据收集。大数据的特点是规模性、多样性、高速性和价值密度。动态竞争力和大数据系统之间的关系是信号理论中的微弱信号,主要描述市场行为,当双方(个人或组织)有机会获得不同信息时,在一般情况下,发送者一方必须知道如何沟通。对方接收到信息后,必须选择如何解释信号。因此,信号理论不断被向前推进,现在已经被广泛应用到企业组织学当中。学者通过信号传递理论,以新方式来开发、解决复杂的配方,以了解细致入微的变化。动态能力通过整合公司资源,构建和重新配置内部能力与外部竞争以应对迅速变化的环境。经过整合公司流程,将资源重新配置,获取和释放相匹配后,以适应市场变化。动态能力是导向能力,帮助中小企业重新部署和配置资源,以满足不断变化的客户需求和应对竞争对手的策略。动态能力是一个集体经验,通过系统组织生成并修改其操作,以追求高效益,经协调整合,重新配置,改造学习等方式,让公司创造出新的产品和工艺,达到修改或创建核心竞争力的效果。实证研究发现,动态能力对战略变革和企业绩效的影响不同。大数据是中小企业信息管理的关键组成部分,与中小型企业的动态能力具有外在共性。根据大数据维度(容量,品种,速度,真实性和价值),提出了动态能力维度符合竞争力的概念。所以,对大数据技术,中小企业,竞争力和动态能力之间的协同关系进行研究,是本文研究的选题目的。基于文献综述和对我国中小企业使用大数据的调查,提出五个动态能力:微弱信号;商业环境传感;业务调整;资源能力转化和资源编排(营销和技术能力/实时分析,学习能力/可视化,协调和整合能力,对环境竞争战略反应)。本文的研究方法使用混合研究方法。第一部分,对国内外二十家中小企业公司进行访问研究,了解他们在业务上对数据的要求,特别是对大数据的期望。这二十家中小企业分布在五个城市,日本东京、欧洲、巴西、香港和新加坡,采用深化非结构化面试的方式来进行访问。第二部分,通过群集分析进行定性内容分析,并对主题重点伸张。然后,制作调查问卷,通过电子调查方法,对约2000份样本进行抽样调查,最终收回电子调查表有600多份。第三部分,利用调查问卷的实证结果来建立中小企业的大数据动态竞争力模型。通过个案访谈,产生三个创新观点。第一是“通过动态能力促使中小企业快速转型和重新配置资源”;第二是“通过大数据手段来提炼微弱信号以强化动态竞争力”;第三是“通过实时大数据以提升中小企业的动态决策能力”。信息技术(大数据)压倒性地解决了原始数据的管理技术,能够把握关键和改造行业,提高了大数据的效益与企业绩效。通过对相关行业的辅助数据进行分析,定义了大数据的吸收能力,通过学习贯彻落实信息技术的相关能力。中小企业的吸收能力并不是简单地聚合公司和行业资源,而是含有其它附加能力,通过整合后最终才能产生效应。吸收能力把内部和外部的信息汇总后变成知识,从而提高适应能力(含动态能力)。本文通过实证研究,最终产生四个解决方案。第一个对策是“建立以中小企业为主导的大数据共享平台“;第二个对策是“建立以中小企为中心的大数据隐私系统”;第三个对策是“建立基于云技术的中小企业营运大数据系统”;第四个对策是“提升中小企业的大数据实时分析能力”。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017020193.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '江西财经大学',
 'keywords': '大数据、互联网+、洞察力、中小企业、动态竞争力',
 'refer': '下载次数（670）| 被引次数（1）',
 'source': '博士论文',
 'time': '2016年',
 'title': '基于大数据的中小企业动态竞争力提升研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:52:59 [scrapy.core.scraper] ERROR: Error processing {'abstract': '数据是在社会发展和人类进步过程中不断演进的一种客观存在,伴随着社会现象和社会行为的产生而产生、发展而发展。大数据更是信息爆炸积累到了一个引发变革的程度的产物,是量变引起质变的结果。个体在互联网上既是数据的消费者又是数据的生产者,大规模生产、分享、应用数据的大数据时代已经来临。大数据数量大、类型多、速度快、价值密度低等重要特征使其成为宝贵的信息资源,彰显着巨大的科学价值和社会价值。在高校,包括大学生在内的每个人都是大数据的制造者、传播者、使用者和分析对象。在大数据蓬勃发展,多元文化相互影响的社会主义新时代,如何科学高效、合理合法地利用大数据,挖掘高校网络思想政治教育的深层次规律,有针对性地开展高校网络思想政治教育工作,提高高校思想政治教育质量,不仅关乎青年的成长成才,也关系到社会的发展与国家的前途。毫无疑问,大数据为高校网络思想政治教育提供了更加准确的数据背景和丰富可靠的教育方法及技术手段,提高了高校网络思想政治教育的针对性与科学性。与此同时,大数据所带来的网络环境、技术手段的快速发展和巨大变化也给高校网络思想政治教育施加了新的压力。因此,立足于大数据视阈,识别大数据给高校思想政治教育带来的种种机遇和挑战,利用大数据来科学发现高校网络思想政治教育的客观规律,构建大数据视阈下的高校网络思想政治教育创新系统,从而顺应大数据时代背景下高校网络思想政治教育发展的新形势、新规律和新要求,推动高校网络思想政治教育创新成为当前不得不深入研究并加以解决的重大问题。论文综合运用定性与定量分析,案例与实证分析,文献分析和大数据技术等方法,将大数据与高校网络思想政治教育二者紧密联系在一起,探讨在大数据视阈下如何利用大数据技术方法,发现和把握高校网络思想政治教育的规律,构建高校网络思想政治教育创新系统,进而推动高校网络思想政治教育创新。论文在对大数据视阈下高校网络思想政治教育创新的理论基础和现实状况进行全面分析的基础上,提出了大数据视阈下高校网络思想政治教育创新系统,并进一步采取结构化系统分析的方法对大数据视阈下高校网络思想政治教育创新系统进行了层层分解的深入研究。具体包括:首先,论文在对网络思想政治教育、大数据等基本范畴进行界定的基础上,对大数据视阈下高校网络思想政治教育创新的相关思想资源、理论基础进行了系统诠释和归纳总结。论文指出马克思主义为大数据运用于高校网络思想政治教育确立了价值导向、逻辑起点、功能导向和建设方向,大数据为高校网络思想政治教育提供了技术手段和实现途径,大数据丰富了马克思主义在高校网络思想政治教育中运用和传播的技术手段。其次,论文在对大数据视阈下高校网络思想政治教育创新的现实基础进行分析的基础上,提出了大数据视阈下高校网络思想政治教育创新的现实可能。论文指出,当前及未来社会,信息技术发展日新月异,网络环境变化翻天覆地,高校传统的网络思想政治教育已显现诸多的问题与不足,在面临大数据重大机遇和挑战的时代背景下,高校网络思想政治教育的理念有待创新、方法有待提升、技术有待进步。因此,在大数据视阈下创新高校网络思想政治教育既是来自时代的召唤,也是来自现实的要求。第三,论文在分析大数据视阈下高校网络思想政治教育创新系统构建的基本思路、任务、目标及原则的基础上,构建了大数据视阈下高校网络思想政治教育创新的系统构架。论文指出大数据视阈下高校网络思想政治教育创新系统由内及外由理念、机制、路径和载体等要素所构成,它们具有各自不同的特征及功能。大数据视阈下的高校网络思想政治教育创新应从这四个层面展开。第四,论文探讨了大数据视阈下高校网络思想政治教育的理念创新。论文指出大数据视阈下高校网络思想政治教育的理念创新是系统创新的核心,是引导其他几个层面创新的关键。大数据视阈下高校网络思想政治教育的理念创新应着力于树立全域育人理念、树立聚焦与再现的价值理念,以及树立定制化与定量化交融的理念。第五,论文探讨了大数据视阈下高校网络思想政治教育的路径创新。针对不同成因、动机以及复杂相关性所形成的高校网络思想政治教育的路径依赖,论文首先从思维突破、制度优化、自适应动态分析等角度进行了剖析,提出了在大数据视阈下高校传统网络思想政治教育“路径依赖”突破的最佳或最短路径的求解;其次,从教育内容层面的聚类筛选、识别界定,资源层面的动态配置,再到最后方法层面的协同联合,从理论到案例,从观念到实施,层层递进,利用大数据更新快、预测强、精准聚合、多维共享等特点,将高校网络思想政治教育以更生动、易接受、效果好的形式传递给学生,实现从“数据读心”到“留身入心”,再到“知心交心”,最后引导学生“修养有心”,将路径创新落实到高校网络思想政治教育的诸多阵地中。第六,论文探讨了大数据视阈下高校网络思想政治教育的载体创新。论文指出可以通过大数据平台架构、大数据技术突破与创新,以及大数据技术、互联网与新媒介的有机对接来推动高校网络思想政治教育的载体创新。最后,论文探讨了大数据视阈下高校网络思想政治教育的机制创新。论文通过对“兴趣簇”和“贡献值”的分析,提出了“激励相容”和“绩效促进”的激励机制;通过对教育评估、反馈模型的分析,提出了大数据视阈下高校网络思想政治教育创新的“动态评估反馈”机制;通过对技术安全、伦理道德、个人隐私等的分析,提出了大数据视阈下高校网络思想政治教育创新的安全保障机制。综上所述,论文在基于理论研究和现实分析的基础上,构建了大数据视阈下高校网络思想政治教育创新的系统构架,并依次对其理念创新、路径创新、载体创新和机制创新等系统层面进行层层剖开、详细论述,以期能为大数据视阈下高校网络思想政治教育创新提供有益的支撑和借鉴。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1018974845.nh&dbcode=CDFD&year=2018&dflag=cajdown',
 'institution': '电子科技大学',
 'keywords': '大数据、高校、网络、思想政治教育、创新',
 'refer': '下载次数（0）| 被引次数（0）',
 'source': '博士论文',
 'time': '2018年',
 'title': '大数据视阈下高校网络思想政治教育创新研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:53:00 [scrapy.core.scraper] ERROR: Error processing {'abstract': '根据时代发展的实际和要求,在教育观念、内容、手段和方法等方面与时俱进地改进创新,推进大学生思想政治教育个性化,是提升思想政治教育针对性和实效性的必然吁求。本文通过开展问卷调查和深度访谈,并引用相关问卷调查结果,论证指出当前大学生思想政治教育个性化仍存在受经验直觉化惯性思维束缚,无法满足需求,内容同质化,以及单向化、被动化等缺陷,根源在于受过分强调群体本位的传统文化及过分注重社会价值的思想政治教育价值观的影响和钳制,既有技术手段无法支撑,以及教育者个性缺乏和受教育者个性不完善等。作为信息时代的新标识,海量数据所蕴含的巨大的经济社会价值毋庸置疑,大数据开启的时代转型,以及引发变革的事实无法回避。大数据不仅是一种技术,也是一种价值观和方法论,它为大学生思想政治教育带来了方法论的变革,也为大学生思想政治教育提供了改进工作方式、方法和手段的一种可能。大数据时代大学生思想政治教育个性化的意义在于通过海量数据整合、挖掘和分析,科学研判学生个体的思想状态和行为特征,从而根据学生个人实际制定和采取有针对性的思想政治教育手段和方式。通过理论层面对大数据为大学生思想政治教育个性化带来的机遇和挑战的探讨,以及对现有大学生思想政治教育大数据应用案例的剖析,阐明借力大数据推进大学生思想政治个性化教育必要且可行。大数据时代大学生思想政治教育个性化的推进,既要有效利用大数据创造的有利条件,也要充分考虑可能引发的风险,应该坚持依托大数据与深入学生实际相统一、一般性分析与针对性教育有机结合、大数据采集与个人隐私保护相结合的原则,并通过大数据意识培育、大数据人才培养、大数据方法运用、智慧校园建构、大数据法律制定等途径,确保应用大数据推进大学生思想政治教育个性化的同时,保护好学生个人隐私,避免出现唯数据主义倾向。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1018085446.nh&dbcode=CDFD&year=2017&dflag=cajdown',
 'institution': '福建师范大学',
 'keywords': '大数据、大学生、思想政治教育、个性化',
 'refer': '下载次数（18）| 被引次数（）',
 'source': '博士论文',
 'time': '2017年',
 'title': '大数据时代大学生思想政治教育个性化研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:53:02 [scrapy.core.scraper] ERROR: Error processing {'abstract': '当前信息技术发展迅速,世界主要国家积极制定科技政策以推动大数据技术发展。大数据作为基础性战略资源,我国也积极将其纳入国家战略。我国大数据产业还处于发展初期,市场潜力巨大。当前我国大数据发展总体仍处于起步阶段,大数据技术发展的政策体系目前尚不完善,有待进一步优化。本文首先研究了大数据发展历程,并对大数据技术相关理论进行梳理,同时对大数据技术相关概念进行界定。然后阐述了大数据技术的产生条件以及大数据技术发展的动态因素。本文将世界主要国家的政策体系与我国的政策体系进行比较,分析了各自政策体系的亮点,同时发现我国大数据技术发展的技术路线图。当前我国大数据技术基础研究薄弱,大数据技术人才短缺,大数据产业应用模式较为单一。本文从宏观、中观、微观三个方面进行分析,比较政策需求和政策供给的具体方面,努力寻求政策体系方面的供需平衡,鼓励技术创新,并研究我国大数据技术发展政策体系的优化路径。最后,我国政府应加强大数据基础研究,鼓励大数据关键技术研发,鼓励技术创新,并积极制定产业扶持政策和人才培养计划,加大大数据技术研发等方面的资金投入。在制定政策方面,应立足系统论视角,把握好国家和地方政府的关系。本文将实证研究与规范研究相结合,利用文本分析法、对比研究法以及系统工程方法对大数据技术发展的政策体系进行研究,具有积极意义。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1017730228.nh&dbcode=CMFD&year=2017&dflag=cajdown',
 'institution': '云南师范大学',
 'keywords': '大数据技术、适配性、政策体系',
 'refer': '下载次数（458）| 被引次数（2）',
 'source': '硕士论文',
 'time': '2017年',
 'title': '我国大数据技术发展的政策体系研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:53:03 [scrapy.extensions.logstats] INFO: Crawled 28 pages (at 28 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 16:53:03 [scrapy.core.scraper] ERROR: Error processing {'abstract': '\xa0'
             '本发明提供了一种具备容N-3存储媒介失效的电力大数据云储存系统,该系统包括云存储控制管理单元,云存储控制管理单元分别与依次连接的电力大数据块的[32,16,8]Reed-Muller码编码处理单元、写入通信传输通道、a行32列的存储媒介阵列、读出通信传输通道和电力大数据块的[32,16,8]Reed-Muller码译码处理单元相连。该系统采用Reed-Muller码编译码技术、哈希函数摘要技术,允许同时发生任意≤3个存储媒介失效,具备N-3容失效性,解决电力大数据云储存系统存储容量、容故障能力和扩展性三者均衡优化问题,保护数据安全,且保障数据具有一定的私密性和完整性,以推进电力大数据云储存系统的建设和发展。',
 'download': 'http://dbpub.cnki.net/grid2008/dbpub/detail.aspx?filename=CN103957265A&dbname=SCPD2014',
 'institution': '国家电网公司;中国电力科学研究院',
 'keywords': '\xa0【主权项】\xa0'
             '一种具备容N?3存储媒介失效的电力大数据云储存系统,其特征在于：所述系统包括依次连接的电力大数据块的[32,16,8]Reed?Muller码编码处理单元、写入通信传输通道、a行32列的存储媒介阵列、读出通信传输通道和电力大数据块的[32,16,8]Reed?Muller码译码处理单元；?云存储控制管理单元分别与所述电力大数据块的[32,16,8]Reed?Muller码编码处理单元、写入通信传输通道、a行32列的存储媒介阵列、读出通信传输通道和电力大数据块的[32,16,8]Reed?Muller码译码处理单元连接。?',
 'refer': '下载次数（0）| 被引次数（0）',
 'source': '中国专利',
 'time': '2014年',
 'title': '一种具备容N-3存储媒介失效的电力大数据云储存系统'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:53:03 [scrapy.core.scraper] ERROR: Error processing {'abstract': '随着信息技术的飞速发展，人类社会进入数字信息时代。获取和掌握信息的能力己成为衡量一个国家实力强弱的标志。一切信息伴随需求不同决定其效益不同，而一切有益信息都是从大量数据中分析出来的。海量数据又随时间持续产生、不断流动、进而扩散形成大数据。大数据不仅用来描述数据的量非常巨大，还突出强调处理数据的速度。所以，大数据成为数据分析领域的前沿技术。数据成为当今每个行业和商业领域的重要因素。人们对于数据的海量挖掘和大量运用，不仅标志着产业生产率的增长和消费者的大量盈余，而且也明确地提示着大数据时代已经到来。数据正成为与物质资产和人力资本同样重要的基础生产要素，大数据的使用成为提高企业竞争力的关键要素。数据成为资产、产业垂直整合、泛互联网化是大数据时代的三大发展趋势。一个国家拥有的数据规模及运用的能力将成为综合国力的重要组成部分，对数据的占有权和控制权将成为陆权、海权、空权之外的国家核心权力。大数据与人类息息相关，越来越多的问题可以通过大数据解决。不仅在数据科学与技术层次，而且在商业模式、产业格局、生态价值与教育层面，大数据都能带来新理念和新思维，包括政府宏观部门、不同的产业界与学术界，甚至个人消费者。大数据与互联网一样，不仅是信息技术领域的革命，更加速企业创新，在全球范围引领社会变革并启动透明政府的发展。大数据正在引发一场思维革命，大数据正在改变人们考察世界的方式方法，以前所未有的速度引起社会、经济、学术、科研、国防、军事等领域的深刻变革。大数据除了将更好的解决商业问题，科技问题，还有各种社会问题，形成以人为本的大数据战略。大数据这一新概念不仅指数据规模庞大，也包括处理和应用数据，是数据对象、技术与应用三者的统一。大数据既可以是如政府部门或企业掌握的数据库这种有限数据集合，也可以是如微博、微信、社交网络上虚拟的无限数据集合。大数据技术包括数据采集、存储、管理、分析挖掘、可视化等技术及其集成。大数据应用是应用大数据技术对各种类型的大数据集合获得有价值信息的行为。充分实现大数据的价值惟有坚持对象、技术、应用三位一体同步发展。大数据是信息技术与各行业领域紧密融合的典型领域，有着旺盛需求和广阔前景。把握机遇需要不断跟踪研究大数据并不断提升对大数据的认知和理解，坚持技术创新与应用创新协同共进同时加快经济社会各领域的大数据开发与利用，推动国家、行业、企业对于数据的应用需求和发展水平进入新的阶段。在大数据时代数据作为一种独立存在的实体，其资产价值越来越突出，日益引起人们的重视。从具体的个人到形形色色的企业，从各国政府到各种组织都可以合法地去收集数据。不论个人还是企业，以及政府等都可以是数据的拥有者。今后个人隐私与数据归属权可能关系越来越少，欧洲民众要求政府公开信息的诉求极其强烈，民众有权向政府申请信息公开。除了涉及国家安全和个人隐私的公共信息外，大部分政府信息都可以公开。大数据主要有三个方面对人类经济社会发展影响巨大，归纳起来：一是能够推动实现巨大经济效益，二是能够推动增强社会管理水平，三是能够推动提高安全保障能力。大数据在政府和公共服务领域的应用可有效推动政务工作开展，提高政府部门的服务效率、决策水平和社会管理水平，产生巨大社会价值。总而言之，大数据将为人们提供强有力的新工具，使人们能更加容易地把握事物规律，更准确地认识世界、预测未来和改造世界。大数据问题涉及范围较广，本文在研究中注重概念分析与文献分析。具体来讲，研究中综合运用了科学技术哲学、社会学等学科的理论知识对大数据进行研究。同时做到问题导向、有的放矢，力求立足本专业理论知识，突出对涉及主题的深层次研究，注意多领域理论知识的综合和统一。本论文既从微观上探讨作为大数据源头与使用者的个体与企业面临的个人隐私风险与商业机密保护问题，又从宏观上分析整个产业乃至国家的大数据治理方针与发展策略，尽量找到实现国家、企业与个人协调发展与动态平衡的路径和方法。本论文通过历史发展的脉络来把握大数据的发展态势，运用科学技术哲学的视角探讨大数据的本质与内涵。以大数据的社会效应为理论和逻辑前提，在把握思维变化和产业发展转型的基础上，从技术、经济、社会等不同层面分析了大数据的动力机制和发展路径，总结了当前主要行业发展方式转型的经验，围绕科技与社会的互动关系梳理大数据与社会各相关产业的融合造成的广泛影响和巨大效益，突出分析了大数据金融产生的一系列重要影响，进而分析其背后蕴含的社会风险，探索相应的社会治理办法，最后就中国积极应对大数据时代、推动中国的大数据发展提出适合中国国情的国家战略设想。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1014336388.nh&dbcode=CDFD&year=2014&dflag=cajdown',
 'institution': '中共中央党校',
 'keywords': '大数据、发展动力、社会价值、大数据金融、风险、战略',
 'refer': '下载次数（35230）| 被引次数（204）',
 'source': '博士论文',
 'time': '2014年',
 'title': '大数据的社会价值与战略选择'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:53:04 [scrapy.core.scraper] ERROR: Error processing {'abstract': '伴随着信息通信技术的创新与发展,人类社会开始步入大数据时代。我们能够感知和记录更大规模和更多种类的数据,并且通过对这些数据的分析和处理,深度挖掘蕴含其中的内在信息及核心价值。作为“人类世界的下一个自然资源”,大数据正在成为促进组织创新、产业升级和经济发展的强大驱动力,在现代社会的诸多行业领域中有着旺盛的应用需求和广阔的应用前景。其中,教育领域被认为是一个大数据的重要应用领域,研究大数据应用与教育领域的深度融合,是我国教育发展的现实需求和未来趋势。本论文的主要研究内容是,基于大数据及其教育领域应用的理论探讨和实践解析,提出对我国发展大数据教育领域应用的建议。在理论探讨方面,从多视角出发诠释大数据的概念内涵,通过历史脉络梳理把握大数据教育领域应用的发展态势,对大数据应用在教育领域中的实践意义与途径进行了阐述；在实践解析方面,结合美国大数据教育领域应用实践中的现实案例阐释大数据应用驱动下的教育发展和变革,分析大数据教育领域应用在实际推进过程中面临的挑战和社会风险,最后在总结美国经验的基础上提出发展我国大数据教育领域应用的建议。在论文的第一章“绪论”中,主要涉及大数据教育领域应用的研究这一论题的引入,包括研究背景与研究意义的阐释、国内外研究成果的梳理以及研究思路与研究方法、研究创新与不足的说明等内容。第二、三、四、五、六章是论文的主体部分,主要围绕大数据的教育领域应用展开理论探讨和实践分析。第二章“大数据概览”对大数据的定义、理论基础、发展沿革、社会价值及潜在风险、关键技术和实践流程做出系统阐述；第三章“大数据教育领域应用的历史发展脉络、实践意义与途径”对大数据教育领域应用的历史发展阶段及其特征进行梳理,对大数据教育领域应用的实践意义与实践途径加以阐述；第四章“大数据在美国国家、区域和学校教育发展层面的应用”基于美国的应用实践,解析大数据在国家、区域和学校教育发展层面的应用场景和模式；第五章“大数据在美国教育重点领域中的应用”基于美国的应用实践,着重阐述大数据应用驱动下的教学、学习、评价、科研、管理和服务等教育重点领域的变革和发展；第六章“大数据教育领域应用面临的挑战”对可能影响大数据教育领域应用顺利开展的诸项因素进行剖析。第七章“发展我国大数据教育领域应用的建议”在分析和总结美国经验的基础上,分别从宏观和微观角度出发,提出促进我国大数据教育领域应用发展的实施建议。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1016126724.nh&dbcode=CDFD&year=2016&dflag=cajdown',
 'institution': '华东师范大学',
 'keywords': '大数据、大数据应用、教育数据挖掘、学习分析、个性化教育、自适应学习',
 'refer': '下载次数（7789）| 被引次数（30）',
 'source': '博士论文',
 'time': '2016年',
 'title': '大数据的教育领域应用之研究——基于美国的应用实践'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 16:53:07 [scrapy.core.scraper] ERROR: Error processing {'abstract': '近年来,大数据以其蕴含的丰富价值,得到了学术界和企业界的广泛关注。对大数据进行管理利用并构建大数据服务,是挖掘大数据价值的关键途径。云计算作为一种弹性高效的计算模式,则为构建大数据服务提供了强大的技术支撑。一方面,云计算的资源按需获取、按使用量计费及广域网互联的优势,节约了大数据处理所需的昂贵基础设施投入和维护成本；另一方面,基于云计算的大数据存储、管理与分析等技术,为快速构建大数据服务提供了技术支撑。尽管云计算技术在大数据服务领域取得了丰富的研究成果,但云环境下数据资源的分散性、动态网络中云服务QOS属性的不确定性和应用需求多元化等因素,为高效实现可靠的大数据服务带来了新的挑战：如1)目前的研究中,缺乏一个云环境下的大数据服务应用模式,为高效构建大数据服务提供技术参考；2)当构建大数据服务所依赖的数据资源分布在云环境中大规模分布式的节点中时,为可扩展的数据资源节点管理方法和数据资源查找方法带来了挑战；3)当大数据服务部署在多个互相协同的云服务之上时,因满足大数据服务功能性需求的云服务数目众多,需要选择QoS最优的云服务组合方案。传统的组合评估方法通常是使用云服务提供商发布的QoS值对组合方案进行评估,动态网络环境或服务提供商可能的商业炒作使得组合方案的可信度受到很大的影响。针对目前云环境下大数据服务在应用模式、数据资源查找、可信组合评估等方面面临的挑战,本文对云环境下的大数据服务及其关键技术开展了相关的研究工作；具体而言,本文的工作主要包括以下几项：1)为高效构建云环境下的大数据服务,提出了一个云环境下通用的大数据服务应用模式。该应用模式分为五个层次,自下而上分别为数据资源层、数据资源搜集层、任务规划层、可信组合评估层及大数据分析算法实现层。具体而言,数据资源层是以分布在云环境中的数据资源为基础,用服务对数据资源进行封装,供使用者通过匹配服务描述进行调用；数据资源搜集层则是根据大数据服务对数据资源的需求,实现可扩展的数据资源搜集：进而,任务规划层是指针对大数据的处理需求,将复杂的计算任务划分至多个功能独立的子任务；根据各个子任务对存储资源或计算资源的需求,可信组合评估层的功能便是为大数据处理任务选择QoS最优的云服务组合方案,从而为各个子任务提供存储资源或计算资源；最后,根据可信组合评估层的选择结果,设计并实现大数据分析算法,完成大数据服务的实现与部署；2)为满足云环境下可扩展的数据资源节点管理和数据资源查找需求,针对性地研究了P2P技术在大数据服务中的拓展应用。具体而言,采用非结构化P2P网络作为云环境下数据资源节点的拓扑组织结构,并以服务封装数据资源,使用者通过查找匹配服务描述信息以获得构建大数据服务所需的数据资源；进一步地,提出基于邻居节点间的数据资源信息主动复制协议,通过提高网络中数据资源的覆盖率以提高查找成功率。最后,基于邻居间主动复制的资源信息,提出了基于概率随机游走的数据资源查找方法,实现云环境下可扩展的数据资源查找；3) '
             '为提高支撑大数据服务的云服务组合方案的可信度,结合云服务的QoS历史记录大数据,提出了基于QoS历史记录的可信组合评估方法。为提高组合评估的计算效率,提出了HireSome-Ⅰ方法,HireSome-Ⅰ方法通过使用部分基于QoS历史记录的组合方案,对云服务组合方案进行评估,缩小了组合评估的计算规模,从而降低了组合评估执行的时间消耗。作为HireSome-Ⅰ方法的补充完善,简要介绍了Dou等人提出的HireSome-Ⅱ方法,即基于代表性QoS历史记录的可信组合评估方法。HireSome-Ⅱ方法通过使用代表性QoS历史记录执行可信组合评估,降低了可信组合评估的计算复杂度,进一步提高了可信组合评估的计算效率；4)为验证上述研究内容的可行性,从构建医疗大数据服务(疾病自诊断服务)的角度,讨论云环境下大数据服务及其关键技术在医疗领域的应用。首先,结合本文提出的大数据服务应用模式,分析并获得疾病自诊断服务的应用需求；针对该应用需求,使用可信组合评估方法,选择QoS最优的云服务组合方案,以响应疾病自诊断服务对计算资源和存储资源的需求；然后,结合电子病历大数据的处理分析需求,设计了一个疾病自诊断服务框架,以响应用户在线自诊断的请求;进一步地,提出了一个基于概念格的电子病历大数据分析方法,对电子病历大数据执行分析计算,获得疾病自诊断模型,来帮助用户进行疾病自诊断与分析。',
 'download': 'http://search.cnki.net/down/default.aspx?filename=1015321122.nh&dbcode=CDFD&year=2015&dflag=cajdown',
 'institution': '南京大学',
 'keywords': '云计算、大数据服务、可信组合评估、医疗大数据',
 'refer': '下载次数（5801）| 被引次数（18）',
 'source': '博士论文',
 'time': '2015年',
 'title': '云环境下大数据服务及其关键技术研究'}
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\pipelines.py", line 25, in process_item
    self.cu.execute(insert_sql)
sqlite3.OperationalError: no such table: cnki
2018-08-01 17:30:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:30:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:30:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:30:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:30:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:30:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:30:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:30:06 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:30:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:30:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 56, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 17:30:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:30:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6161,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 30, 6, 514000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 30, 6, 84000)}
2018-08-01 17:30:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:48:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:48:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:48:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:48:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:48:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:48:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:48:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:48:00 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:48:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:48:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:48:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:48:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6160,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 48, 0, 788000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 48, 0, 428000)}
2018-08-01 17:48:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:50:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:50:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:50:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:50:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:50:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:50:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:50:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:50:22 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:50:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:50:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:50:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:50:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6195,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 50, 22, 575000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 50, 22, 165000)}
2018-08-01 17:50:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:51:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:51:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:51:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:51:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:51:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:51:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:51:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:51:11 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:51:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:51:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:51:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:51:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6137,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 51, 12, 990000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 51, 11, 227000)}
2018-08-01 17:51:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:51:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:51:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:51:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:51:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:51:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:51:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:51:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:51:38 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:51:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:51:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:51:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:51:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6116,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 51, 40, 233000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 51, 38, 923000)}
2018-08-01 17:51:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:51:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:51:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:51:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:51:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:51:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:51:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:51:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:51:53 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:51:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:51:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:51:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:51:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6113,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 51, 53, 590000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 51, 53, 270000)}
2018-08-01 17:51:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:52:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:52:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:52:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:52:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:52:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:52:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:52:02 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:52:02 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:52:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:52:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:52:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:52:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6330,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 52, 3, 310000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 52, 2, 990000)}
2018-08-01 17:52:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:52:18 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:52:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:52:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:52:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:52:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:52:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:52:18 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:52:18 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:52:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:52:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:52:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:52:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6174,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 52, 18, 858000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 52, 18, 468000)}
2018-08-01 17:52:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:52:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:52:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:52:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:52:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:52:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:52:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:52:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:52:34 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:52:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:52:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:52:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:52:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6116,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 52, 50, 859000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 52, 34, 989000)}
2018-08-01 17:52:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:53:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:53:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:53:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:53:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:53:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:53:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:53:03 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:53:03 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:53:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:53:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = selector.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:53:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:53:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6267,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 53, 3, 508000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 53, 3, 68000)}
2018-08-01 17:53:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:53:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:53:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:53:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:53:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:53:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:53:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:53:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:53:40 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:53:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:53:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = response.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:53:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:53:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6202,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 53, 41, 166000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 53, 40, 826000)}
2018-08-01 17:53:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:53:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:53:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:53:58 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:54:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = response.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:54:24 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:54:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:54:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:54:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:54:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:54:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:54:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:54:24 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:54:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:54:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    Loads = response.xpath('/html/body/div[2]/div/ul"]')
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[2]/div/ul"]
2018-08-01 17:54:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:54:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:54:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:54:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:54:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:54:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:54:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:54:44 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:54:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:55:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:55:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:55:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:55:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:55:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:55:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:55:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:55:55 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:55:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:56:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:56:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:56:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:56:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:56:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:56:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:56:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:56:00 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:56:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:56:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 62, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 17:56:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:56:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:56:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:56:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:56:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:56:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:56:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:56:16 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:56:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:56:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 62, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 17:56:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:56:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6118,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 56, 17, 263000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 56, 16, 923000)}
2018-08-01 17:56:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:56:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:56:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:56:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:56:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:56:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:56:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:56:23 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:56:23 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:56:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:56:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 62, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 17:56:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:56:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6115,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 56, 23, 665000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 56, 23, 325000)}
2018-08-01 17:56:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:58:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:58:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:58:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:58:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:58:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:58:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:58:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:58:00 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:58:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:58:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 62, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 17:58:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:58:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6118,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 58, 0, 775000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 58, 0, 405000)}
2018-08-01 17:58:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 17:58:26 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 17:58:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 17:58:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 17:58:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 17:58:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 17:58:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 17:58:26 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 17:58:26 [scrapy.core.engine] INFO: Spider opened
2018-08-01 17:58:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 17:58:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 62, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 17:58:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 17:58:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6139,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 9, 58, 27, 21000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 9, 58, 26, 671000)}
2018-08-01 17:58:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 18:03:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 18:03:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 18:03:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 18:03:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 18:03:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 18:03:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 18:03:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 18:03:30 [scrapy.core.engine] INFO: Spider opened
2018-08-01 18:03:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 18:03:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 62, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 18:03:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 18:03:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6140,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 10, 3, 30, 722000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 10, 3, 30, 342000)}
2018-08-01 18:03:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 18:04:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 18:04:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 18:04:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 18:04:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 18:04:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 18:04:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 18:04:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 18:04:21 [scrapy.core.engine] INFO: Spider opened
2018-08-01 18:04:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 18:04:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 62, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 18:04:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 18:04:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6132,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 10, 4, 21, 475000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 10, 4, 21, 145000)}
2018-08-01 18:04:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-01 18:05:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-01 18:05:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-01 18:05:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-01 18:05:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-01 18:05:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-01 18:05:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-01 18:05:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-01 18:05:55 [scrapy.core.engine] INFO: Spider opened
2018-08-01 18:05:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-01 18:05:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 63, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-01 18:05:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-01 18:05:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 1, 10, 5, 55, 995000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 1, 10, 5, 55, 495000)}
2018-08-01 18:05:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:15:43 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:15:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:15:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:15:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:15:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:15:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:15:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:15:44 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:15:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:15:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 63, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:15:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:15:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6244,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 15, 45, 516600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 15, 44, 46600)}
2018-08-02 09:15:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:17:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:17:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:17:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:17:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:17:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:17:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:17:31 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:17:31 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:17:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:17:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 65, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:17:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:17:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6259,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 17, 31, 801600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 17, 31, 471600)}
2018-08-02 09:17:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:18:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:18:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:18:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:18:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:18:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:18:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:18:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:18:10 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:18:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:18:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/search.do?keyword=> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 65, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:18:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:18:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 317,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 6227,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 18, 10, 440600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 18, 10, 160600)}
2018-08-02 09:18:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:23:18 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:23:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:23:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:23:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:23:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:23:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:23:18 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:23:18 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:23:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:23:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 66, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:23:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:23:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11191,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 23, 18, 461600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 23, 18, 161600)}
2018-08-02 09:23:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:25:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:25:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:25:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:25:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:25:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:25:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:25:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:25:42 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:25:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:25:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 66, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:25:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:25:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 25, 43, 55600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 25, 42, 815600)}
2018-08-02 09:25:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:34:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:34:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:34:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:34:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:34:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:34:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:34:03 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:34:03 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:34:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:34:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 66, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:34:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:34:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 34, 3, 602600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 34, 3, 322600)}
2018-08-02 09:34:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:34:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:34:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:34:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:34:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:34:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:34:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:34:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:34:16 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:34:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:34:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 66, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:34:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:34:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 34, 16, 282600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 34, 16, 12600)}
2018-08-02 09:34:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:34:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:34:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:34:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:34:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:34:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:34:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:34:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:34:22 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:34:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:34:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 66, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:34:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:34:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11231,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 34, 22, 802600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 34, 22, 492600)}
2018-08-02 09:34:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:35:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:35:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:35:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:35:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:35:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:35:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:35:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:35:27 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:35:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:35:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 68, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:35:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:35:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 35, 27, 609600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 35, 27, 329600)}
2018-08-02 09:35:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:43:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:43:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:43:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:43:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:43:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:43:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:43:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:43:37 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:43:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:43:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 70, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:43:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:43:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 43, 37, 569600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 43, 37, 269600)}
2018-08-02 09:43:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:44:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:44:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:44:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:44:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:44:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:44:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:44:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:44:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:44:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:44:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 70, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:44:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:44:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 44, 7, 75600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 44, 6, 775600)}
2018-08-02 09:44:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:44:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:44:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:44:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:44:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:44:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:44:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:44:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:44:55 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:44:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:44:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    print(response.xpath("/html/body/div[4]/div/div[2]/ul/li[2]/div[2]/string-join(text())").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[4]/div/div[2]/ul/li[2]/div[2]/string-join(text())
2018-08-02 09:44:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:44:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11231,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 44, 55, 816600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 44, 55, 546600)}
2018-08-02 09:44:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:45:09 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:45:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:45:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:45:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:45:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:45:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:45:09 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:45:09 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:45:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:45:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    print(response.xpath("/html/body/div[4]/div/div[2]/ul/li[2]/div[2]/string-join(text())").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[4]/div/div[2]/ul/li[2]/div[2]/string-join(text())
2018-08-02 09:45:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:45:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 45, 9, 446600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 45, 9, 216600)}
2018-08-02 09:45:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:48:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:48:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:48:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:48:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:48:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:48:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:48:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:48:32 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:48:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:48:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 71, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:48:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:48:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11268,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 48, 32, 918600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 48, 32, 648600)}
2018-08-02 09:48:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:48:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:48:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:48:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:48:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:48:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:48:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:48:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:48:44 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:48:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:48:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 71, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:48:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:48:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 48, 45, 78600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 48, 44, 808600)}
2018-08-02 09:48:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:50:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:50:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:50:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:50:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:50:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:50:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:50:31 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:50:31 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:50:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:50:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 71, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:50:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:50:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11222,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 50, 31, 910600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 50, 31, 730600)}
2018-08-02 09:50:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:50:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:50:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:50:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:50:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:50:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:50:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:50:49 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:50:49 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:50:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:50:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 71, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:50:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:50:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 50, 50, 11600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 50, 49, 821600)}
2018-08-02 09:50:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:53:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:53:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:53:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:53:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:53:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:53:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:53:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:53:42 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:53:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:53:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:53:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:53:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 53, 42, 821600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 53, 42, 641600)}
2018-08-02 09:53:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:53:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:53:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:53:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:53:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:53:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:53:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:53:58 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:53:58 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:53:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:53:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:53:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:53:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11182,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 53, 58, 843600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 53, 58, 673600)}
2018-08-02 09:53:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:54:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:54:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:54:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:54:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:54:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:54:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:54:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:54:08 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:54:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:54:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:54:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:54:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 54, 8, 243600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 54, 8, 53600)}
2018-08-02 09:54:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:54:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:54:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:54:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:54:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:54:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:54:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:54:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:54:24 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:54:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:54:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:54:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:54:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 54, 24, 265600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 54, 24, 13600)}
2018-08-02 09:54:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:55:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:55:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:55:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:55:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:55:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:55:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:55:39 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:55:39 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:55:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:55:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:55:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:55:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 55, 39, 853600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 55, 39, 663600)}
2018-08-02 09:55:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:55:50 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:55:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:55:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:55:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:55:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:55:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:55:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:55:50 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:55:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:55:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:55:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:55:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 55, 50, 673600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 55, 50, 493600)}
2018-08-02 09:55:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:56:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:56:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:56:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:56:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:56:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:56:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:56:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:56:00 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:56:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:56:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    print(response.xpath("normalize-space(/html/body/div[4]/div/div[2]/ul/li[2]/div[2]/)"))
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in normalize-space(/html/body/div[4]/div/div[2]/ul/li[2]/div[2]/)
2018-08-02 09:56:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:56:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 56, 0, 513600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 56, 0, 313600)}
2018-08-02 09:56:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:56:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:56:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:56:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:56:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:56:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:56:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:56:13 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:56:13 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:56:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:56:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:56:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:56:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 56, 13, 609600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 56, 13, 429600)}
2018-08-02 09:56:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:57:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:57:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:57:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:57:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:57:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:57:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:57:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:57:54 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:57:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:57:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    print(response.xpath("/html/body/div[4]/div/div[2]/ul/li[2]/div[2]/normalize-space(//text())"))
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[4]/div/div[2]/ul/li[2]/div[2]/normalize-space(//text())
2018-08-02 09:57:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:57:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 57, 54, 657600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 57, 54, 487600)}
2018-08-02 09:57:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:58:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:58:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:58:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:58:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:58:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:58:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:58:05 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:58:05 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:58:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:58:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 28, in parse
    print(response.xpath("/html/body/div[4]/div/div[2]/ul/li[2]/div[2]/normalize-space(text())"))
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[4]/div/div[2]/ul/li[2]/div[2]/normalize-space(text())
2018-08-02 09:58:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:58:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 58, 5, 627600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 58, 5, 437600)}
2018-08-02 09:58:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:58:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:58:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:58:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:58:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:58:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:58:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:58:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:58:17 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:58:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:58:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:58:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 58, 17, 765600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 58, 17, 585600)}
2018-08-02 09:58:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:59:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:59:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:59:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:59:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:59:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:59:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:59:36 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:59:36 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:59:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:59:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:59:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:59:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11165,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 59, 37, 16600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 59, 36, 836600)}
2018-08-02 09:59:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 09:59:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 09:59:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 09:59:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 09:59:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 09:59:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 09:59:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 09:59:48 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 09:59:48 [scrapy.core.engine] INFO: Spider opened
2018-08-02 09:59:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 09:59:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 09:59:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 09:59:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 1, 59, 48, 256600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 1, 59, 48, 66600)}
2018-08-02 09:59:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:00:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:00:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:00:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:00:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:00:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:00:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:00:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:00:10 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:00:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:00:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:00:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:00:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11221,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 0, 11, 49600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 0, 10, 859600)}
2018-08-02 10:00:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:00:19 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:00:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:00:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:00:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:00:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:00:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:00:19 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:00:19 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:00:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:00:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:00:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:00:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 0, 19, 630600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 0, 19, 420600)}
2018-08-02 10:00:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:00:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:00:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:00:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:00:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:00:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:00:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:00:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:00:32 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:00:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:00:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:00:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:00:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 0, 32, 268600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 0, 32, 78600)}
2018-08-02 10:00:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:00:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:00:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:00:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:00:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:00:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:00:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:00:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:00:38 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:00:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:00:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 72, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:00:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:00:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 0, 38, 668600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 0, 38, 478600)}
2018-08-02 10:00:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:03:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:03:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:03:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:03:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:03:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:03:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:03:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:03:00 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:03:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:03:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 73, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:03:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:03:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11152,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 3, 0, 479600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 3, 0, 309600)}
2018-08-02 10:03:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:03:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:03:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:03:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:03:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:03:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:03:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:03:13 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:03:13 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:03:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:03:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 73, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:03:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:03:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11182,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 3, 13, 759600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 3, 13, 569600)}
2018-08-02 10:03:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:03:59 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:03:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:03:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:03:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:03:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:03:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:03:59 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:03:59 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:03:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:03:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 73, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:03:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:03:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11268,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 3, 59, 467600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 3, 59, 247600)}
2018-08-02 10:03:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:05:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:05:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:05:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:05:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:05:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:05:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:05:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:05:16 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:05:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:05:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 75, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:05:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:05:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 5, 16, 388600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 5, 16, 198600)}
2018-08-02 10:05:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:05:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:05:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:05:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:05:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:05:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:05:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:05:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:05:27 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:05:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:05:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 75, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:05:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:05:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 5, 27, 690600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 5, 27, 490600)}
2018-08-02 10:05:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:05:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:05:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:05:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:05:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:05:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:05:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:05:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:05:38 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:05:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:05:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 75, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:05:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:05:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 5, 38, 421600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 5, 38, 221600)}
2018-08-02 10:05:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:05:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:05:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:05:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:05:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:05:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:05:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:05:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:05:56 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:05:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:05:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 76, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:05:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:05:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11268,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 5, 56, 410600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 5, 56, 220600)}
2018-08-02 10:05:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:06:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:06:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:06:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:06:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:06:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:06:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:06:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:06:12 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:06:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:06:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 77, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:06:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:06:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11268,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 6, 12, 550600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 6, 12, 360600)}
2018-08-02 10:06:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:10:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:10:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:10:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:10:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:10:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:10:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:10:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:10:33 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:10:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:10:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 78, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:10:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:10:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11263,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 10, 42, 869600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 10, 33, 591600)}
2018-08-02 10:10:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:12:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:12:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:12:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:12:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:12:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:12:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:12:58 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:12:58 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:12:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:13:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 79, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:13:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:13:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 13, 8, 240600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 12, 58, 961600)}
2018-08-02 10:13:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:13:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:13:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:13:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:13:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:13:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:13:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:13:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:13:17 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:13:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:13:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 80, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:13:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:13:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11181,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 13, 27, 22600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 13, 17, 767600)}
2018-08-02 10:13:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:13:50 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:13:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:13:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:13:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:13:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:13:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:13:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:13:50 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:13:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:13:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 80, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:13:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:13:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 13, 59, 535600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 13, 50, 242600)}
2018-08-02 10:13:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:15:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:15:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:15:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:15:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:15:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:15:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:15:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:15:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:15:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:15:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 79, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:15:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:15:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 15, 16, 140600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 15, 6, 868600)}
2018-08-02 10:15:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:17:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:17:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:17:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:17:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:17:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:17:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:17:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:17:42 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:17:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:17:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 79, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:17:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:17:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 17, 42, 682600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 17, 42, 412600)}
2018-08-02 10:17:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:19:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:19:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:19:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:19:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:19:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:19:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:19:45 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:19:45 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:19:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:19:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 83, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:19:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:19:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11242,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 19, 45, 335600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 19, 45, 95600)}
2018-08-02 10:19:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:42:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:42:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:42:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:42:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:42:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:42:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:42:25 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:42:25 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:42:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:42:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 79, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:42:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:42:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11224,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 42, 25, 541600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 42, 25, 291600)}
2018-08-02 10:42:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:42:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:42:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:42:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:42:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:42:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:42:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:42:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:42:55 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:42:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:42:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 79, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:42:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:42:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11189,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 42, 56, 240600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 42, 55, 990600)}
2018-08-02 10:42:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:46:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:46:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:46:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:46:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:46:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:46:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:46:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:46:16 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:46:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:46:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 82, in parse
    v_nextPageUrl = "http://search.cnki.net/" + v_nextPageUrlist[0]  # 此处网址不全时可能会出现valueError
IndexError: list index out of range
2018-08-02 10:46:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:46:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11267,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 46, 17, 79600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 46, 16, 858600)}
2018-08-02 10:46:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 10:51:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:51:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:51:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:51:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:51:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:51:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:51:33 [twisted] CRITICAL: Unhandled error in Deferred:
2018-08-02 10:51:33 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'CnkiSpider1_0.pipelines' has no attribute 'JsonWithEncodingCnblogsPipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'CnkiSpider1_0.pipelines' doesn't define any object named 'JsonWithEncodingCnblogsPipeline'
2018-08-02 10:51:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:51:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:51:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:51:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:51:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:51:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:51:38 [twisted] CRITICAL: Unhandled error in Deferred:
2018-08-02 10:51:38 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'CnkiSpider1_0.pipelines' has no attribute 'JsonWithEncodingCnblogsPipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'CnkiSpider1_0.pipelines' doesn't define any object named 'JsonWithEncodingCnblogsPipeline'
2018-08-02 10:52:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:52:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:52:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:52:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:52:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:52:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:52:21 [twisted] CRITICAL: Unhandled error in Deferred:
2018-08-02 10:52:21 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'CnkiSpider1_0.pipelines' has no attribute 'JsonWithEncodingCnblogsPipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'CnkiSpider1_0.pipelines' doesn't define any object named 'JsonWithEncodingCnblogsPipeline'
2018-08-02 10:56:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:56:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:56:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:56:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:56:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:56:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:56:21 [twisted] CRITICAL: Unhandled error in Deferred:
2018-08-02 10:56:21 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'CnkiSpider1_0.pipelines' has no attribute 'JsonWithEncodingCnblogsPipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'CnkiSpider1_0.pipelines' doesn't define any object named 'JsonWithEncodingCnblogsPipeline'
2018-08-02 10:58:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:58:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:58:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:58:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:58:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:58:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:58:47 [twisted] CRITICAL: Unhandled error in Deferred:
2018-08-02 10:58:47 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'CnkiSpider1_0.pipelines' has no attribute 'JsonWithEncodingCnblogsPipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "D:\software\Anaconda\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "D:\software\Anaconda\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'CnkiSpider1_0.pipelines' doesn't define any object named 'JsonWithEncodingCnblogsPipeline'
2018-08-02 10:59:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 10:59:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 10:59:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 10:59:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 10:59:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 10:59:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 10:59:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.Cnkispider10Pipeline']
2018-08-02 10:59:40 [scrapy.core.engine] INFO: Spider opened
2018-08-02 10:59:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 10:59:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 10:59:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11698,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 2, 59, 41, 331600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 2, 59, 40, 951600)}
2018-08-02 10:59:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:00:50 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:00:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:00:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:00:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:00:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:00:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:00:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:00:50 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:00:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:00:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:00:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11262,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 0, 50, 826600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 0, 50, 576600)}
2018-08-02 11:00:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:01:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:01:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:01:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:01:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:01:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:01:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:01:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:01:42 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:01:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:01:42 [scrapy.core.scraper] ERROR: Spider must return Request, BaseItem, dict or None, got 'list' in <GET https://www.csai.cn/kouzi/317.html>
2018-08-02 11:01:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:01:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11189,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 1, 42, 486600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 1, 42, 256600)}
2018-08-02 11:01:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:01:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:01:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:01:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:01:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:01:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:01:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:01:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:01:54 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:01:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:01:54 [scrapy.core.scraper] ERROR: Spider must return Request, BaseItem, dict or None, got 'list' in <GET https://www.csai.cn/kouzi/317.html>
2018-08-02 11:01:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:01:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11263,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 1, 54, 996600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 1, 54, 746600)}
2018-08-02 11:01:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:02:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:02:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:02:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:02:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:02:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:02:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:02:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:02:41 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:02:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:02:42 [scrapy.core.scraper] ERROR: Spider must return Request, BaseItem, dict or None, got 'list' in <GET https://www.csai.cn/kouzi/317.html>
2018-08-02 11:02:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:02:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11223,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 2, 42, 42600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 2, 41, 781600)}
2018-08-02 11:02:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:03:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:03:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:03:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:03:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:03:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:03:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:03:39 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:03:39 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:03:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:03:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 38, in parse
    print(items.count())
TypeError: count() takes exactly one argument (0 given)
2018-08-02 11:03:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:03:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11263,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 3, 39, 305600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 3, 39, 85600)}
2018-08-02 11:03:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:04:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:04:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:04:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:04:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:04:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:04:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:04:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:04:10 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:04:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:04:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:04:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11160,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 4, 10, 567600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 4, 10, 327600)}
2018-08-02 11:04:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:06:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:06:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:06:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:06:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:06:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:06:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:06:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:06:20 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:06:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:06:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:06:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11223,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 6, 21, 48600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 6, 20, 278600)}
2018-08-02 11:06:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:08:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:08:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:08:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:08:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:08:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:08:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:08:48 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:08:48 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:08:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:08:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:08:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11233,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 8, 48, 303600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 8, 48, 83600)}
2018-08-02 11:08:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:09:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:09:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:09:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:09:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:09:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:09:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:09:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:09:22 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:09:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:09:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:09:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11223,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 9, 22, 739600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 9, 22, 479600)}
2018-08-02 11:09:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:18:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:18:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:18:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:18:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:18:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:18:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:18:39 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:18:39 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:18:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:18:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:18:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11224,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 18, 40, 244600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 18, 39, 974600)}
2018-08-02 11:18:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:20:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:20:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:20:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:20:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:20:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:20:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:20:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:20:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:20:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:20:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 49, in parse
    yield d
NameError: name 'd' is not defined
2018-08-02 11:20:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:20:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11167,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 20, 6, 271600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 20, 6, 21600)}
2018-08-02 11:20:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:20:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:20:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:20:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:20:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:20:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:20:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:20:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:20:16 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:20:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:20:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:20:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11229,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 20, 17, 148600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 20, 16, 888600)}
2018-08-02 11:20:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:20:29 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:20:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:20:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:20:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:20:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:20:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:20:29 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:20:29 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:20:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:20:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:20:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11243,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 20, 29, 578600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 20, 29, 308600)}
2018-08-02 11:20:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:27:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:27:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:27:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:27:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:27:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:27:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:27:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:27:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:27:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:27:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:27:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11268,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 27, 7, 64600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 27, 6, 814600)}
2018-08-02 11:27:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:30:43 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:30:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:30:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:30:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:30:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:30:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:30:43 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:30:43 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:30:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:30:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:30:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11243,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 30, 43, 536600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 30, 43, 296600)}
2018-08-02 11:30:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:33:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:33:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:33:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:33:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:33:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:33:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:33:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:33:14 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:33:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:33:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:33:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11243,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 33, 14, 536600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 33, 14, 296600)}
2018-08-02 11:33:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:34:46 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:34:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:34:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:34:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:34:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:34:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:34:46 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:34:46 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:34:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:34:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 46, in parse
    dict.pop(name,vale)
TypeError: descriptor 'pop' requires a 'dict' object but received a 'str'
2018-08-02 11:34:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:34:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11230,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 34, 46, 727600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 34, 46, 457600)}
2018-08-02 11:34:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:36:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:36:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:36:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:36:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:36:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:36:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:36:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:36:57 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:36:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:36:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 46, in parse
    dict.setdefault(name,vale)
TypeError: descriptor 'setdefault' requires a 'dict' object but received a 'str'
2018-08-02 11:36:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:36:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11198,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 36, 57, 337600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 36, 57, 47600)}
2018-08-02 11:36:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:37:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:37:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:37:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:37:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:37:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:37:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:37:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:37:38 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:37:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:37:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 46, in parse
    dict[name]=vale
TypeError: 'type' object does not support item assignment
2018-08-02 11:37:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:37:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11268,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 37, 38, 852600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 37, 38, 572600)}
2018-08-02 11:37:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:37:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:37:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:37:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:37:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:37:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:37:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:37:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:37:51 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:37:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:37:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 46, in parse
    dict[name]=vale
TypeError: 'type' object does not support item assignment
2018-08-02 11:37:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:37:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11167,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 37, 51, 692600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 37, 51, 422600)}
2018-08-02 11:37:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:38:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:38:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:38:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:38:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:38:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:38:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:38:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:38:14 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:38:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:38:15 [scrapy.core.scraper] ERROR: Spider must return Request, BaseItem, dict or None, got 'type' in <GET https://www.csai.cn/kouzi/317.html>
2018-08-02 11:38:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:38:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11229,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 38, 15, 38600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 38, 14, 738600)}
2018-08-02 11:38:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:38:29 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:38:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:38:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:38:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:38:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:38:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:38:29 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:38:29 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:38:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:38:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 43, in parse
    for name,vale in names,vales:
ValueError: too many values to unpack (expected 2)
2018-08-02 11:38:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:38:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11243,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 38, 29, 689600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 38, 29, 439600)}
2018-08-02 11:38:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:38:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:38:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:38:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:38:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:38:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:38:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:38:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:38:42 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:38:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:38:42 [scrapy.core.scraper] ERROR: Spider must return Request, BaseItem, dict or None, got 'type' in <GET https://www.csai.cn/kouzi/317.html>
2018-08-02 11:38:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:38:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11229,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 38, 42, 601600),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 38, 42, 61600)}
2018-08-02 11:38:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:40:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:40:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:40:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:40:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:40:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:40:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:40:39 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:40:39 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:40:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:40:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:40:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11243,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 40, 39, 884600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 40, 39, 624600)}
2018-08-02 11:40:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:41:24 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:41:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:41:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:41:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:41:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:41:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:41:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:41:24 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:41:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:41:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:41:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11244,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 41, 24, 948600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 41, 24, 738600)}
2018-08-02 11:41:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:41:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:41:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:41:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:41:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:41:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:41:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:41:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:41:55 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:41:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:41:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:41:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11234,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 41, 55, 905600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 41, 55, 635600)}
2018-08-02 11:41:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:43:48 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:43:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:43:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:43:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:43:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:43:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:43:48 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:43:48 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:43:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:43:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:43:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11229,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 43, 49, 17600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 43, 48, 755600)}
2018-08-02 11:43:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 11:47:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 11:47:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 11:47:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 11:47:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 11:47:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 11:47:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 11:47:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 11:47:27 [scrapy.core.engine] INFO: Spider opened
2018-08-02 11:47:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 11:47:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 11:47:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11307,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 3, 47, 28, 290600),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 3, 47, 27, 990600)}
2018-08-02 11:47:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:02:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:02:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:02:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:02:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:02:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:02:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:02:15 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:02:15 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:02:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:02:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:02:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11714,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 2, 16, 6000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 2, 15, 626000)}
2018-08-02 14:02:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:04:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:04:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:04:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:04:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:04:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:04:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:04:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:04:54 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:04:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:04:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:04:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11520,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 4, 54, 750000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 4, 54, 322000)}
2018-08-02 14:04:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:09:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:09:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:09:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:09:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:09:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:09:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:09:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:09:32 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:09:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:09:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/316.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 52, in parse
    dic.setdefault(key, value)
NameError: name 'dic' is not defined
2018-08-02 14:09:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:09:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11445,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 9, 32, 915000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 9, 32, 528000)}
2018-08-02 14:09:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:10:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:10:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:10:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:10:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:10:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:10:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:10:35 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:10:35 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:10:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:10:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:10:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11009,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 10, 35, 835000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 10, 35, 596000)}
2018-08-02 14:10:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:10:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:10:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:10:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:10:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:10:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:10:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:10:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:10:56 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:10:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:10:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:10:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 10978,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 10, 57, 92000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 10, 56, 870000)}
2018-08-02 14:10:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:13:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:13:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:13:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:13:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:13:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:13:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:13:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:13:21 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:13:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:13:21 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.csai.cn/kouzi/i.html>: HTTP status code is not handled or not allowed
2018-08-02 14:13:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:13:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 305,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 2948,
 'downloader/response_count': 1,
 'downloader/response_status_count/404': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 13, 21, 677000),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 13, 21, 392000)}
2018-08-02 14:13:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:14:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:14:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:14:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:14:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:14:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:14:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:14:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:14:33 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:14:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:14:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:14:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11241,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 14, 34, 213000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 14, 33, 959000)}
2018-08-02 14:14:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:18:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:18:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:18:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:18:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:18:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:18:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:18:05 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:18:05 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:18:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:18:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:18:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11232,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 18, 5, 541000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 18, 5, 323000)}
2018-08-02 14:18:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:23:45 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:23:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:23:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:23:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:23:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:23:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:23:45 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:23:45 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:23:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:23:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:23:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11224,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 23, 45, 732000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 23, 45, 500000)}
2018-08-02 14:23:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:25:24 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:25:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:25:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:25:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:25:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:25:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:25:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:25:24 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:25:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:25:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:25:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 555,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22692,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 25, 26, 73000),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 2, 6, 25, 24, 316000)}
2018-08-02 14:25:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:29:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:29:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:29:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:29:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:29:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:29:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:29:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:29:22 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:29:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:29:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 60, in parse
    for x in 50:
TypeError: 'int' object is not iterable
2018-08-02 14:29:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:29:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11246,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 29, 22, 565000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 29, 22, 349000)}
2018-08-02 14:29:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:29:46 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:29:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:29:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:29:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:29:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:29:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:29:46 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:29:46 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:29:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:29:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 60, in parse
    for x in 50:
TypeError: 'int' object is not iterable
2018-08-02 14:29:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:29:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11223,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 29, 47, 86000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 29, 46, 917000)}
2018-08-02 14:29:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:30:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:30:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:30:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:30:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:30:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:30:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:30:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:30:11 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:30:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:30:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 61, in parse
    url = 'https://www.csai.cn/kouzi/'+x+'.html'
TypeError: must be str, not int
2018-08-02 14:30:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:30:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11223,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 30, 11, 615000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 30, 11, 368000)}
2018-08-02 14:30:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:30:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:30:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:30:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:30:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:30:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:30:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:30:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:30:38 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:30:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:30:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 61, in parse
    url = 'https://www.csai.cn/kouzi/'+x+'.html'
TypeError: must be str, not int
2018-08-02 14:30:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:30:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 30, 39, 218000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 30, 39, 1000)}
2018-08-02 14:30:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:31:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:31:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:31:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:31:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:31:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:31:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:31:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:31:11 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:31:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:31:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:31:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 555,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22851,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 31, 13, 614000),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 2, 6, 31, 11, 795000)}
2018-08-02 14:31:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:32:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:32:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:32:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:32:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:32:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:32:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:32:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:32:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:32:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:32:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 61, in parse
    url = 'https://www.csai.cn/kouzi/'+i+'.html'
TypeError: must be str, not int
2018-08-02 14:32:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:32:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11233,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 32, 6, 332000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 32, 6, 137000)}
2018-08-02 14:32:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:32:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:32:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:32:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:32:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:32:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:32:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:32:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:32:20 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:32:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:32:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:32:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 555,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22414,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 32, 21, 745000),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 2, 6, 32, 20, 785000)}
2018-08-02 14:32:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:32:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:32:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:32:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:32:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:32:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:32:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:32:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:32:57 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:32:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:32:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 60, in parse
    for i in 50:
TypeError: 'int' object is not iterable
2018-08-02 14:32:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:32:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11194,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 32, 58, 77000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 32, 57, 897000)}
2018-08-02 14:32:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:33:19 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:33:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:33:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:33:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:33:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:33:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:33:19 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:33:19 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:33:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:33:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 60, in parse
    for i in 50:
TypeError: 'int' object is not iterable
2018-08-02 14:33:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:33:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 33, 19, 627000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 33, 19, 453000)}
2018-08-02 14:33:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:33:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:33:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:33:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:33:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:33:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:33:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:33:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:33:27 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:33:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:33:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 60, in parse
    for i in 50:
TypeError: 'int' object is not iterable
2018-08-02 14:33:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:33:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11233,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 33, 27, 745000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 33, 27, 562000)}
2018-08-02 14:33:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:33:50 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:33:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:33:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:33:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:33:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:33:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:33:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:33:50 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:33:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:33:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 61, in parse
    for i in 50:
TypeError: 'int' object is not iterable
2018-08-02 14:33:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:33:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11261,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 33, 51, 853000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 33, 50, 989000)}
2018-08-02 14:33:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:34:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:34:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:34:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:34:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:34:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:34:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:34:09 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:34:09 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:34:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:34:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 61, in parse
    for i in 50:
TypeError: 'int' object is not iterable
2018-08-02 14:34:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:34:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11233,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 34, 9, 306000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 34, 9, 120000)}
2018-08-02 14:34:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:38:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:38:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:38:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:38:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:38:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:38:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:38:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:38:37 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:38:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:38:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:38:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 555,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22488,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 38, 39, 79000),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 2, 6, 38, 37, 818000)}
2018-08-02 14:38:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:39:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:39:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:39:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:39:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:39:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:39:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:39:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:39:00 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:39:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:39:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:39:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 555,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22493,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 39, 2, 416000),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 2, 6, 39, 0, 974000)}
2018-08-02 14:39:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:40:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:40:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:40:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:40:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:40:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:40:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:40:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:40:30 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:40:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:40:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:40:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 555,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 23696,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 2,
 'dupefilter/filtered': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 40, 32, 315000),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 2,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 2, 6, 40, 30, 697000)}
2018-08-02 14:40:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:40:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:40:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:40:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:40:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:40:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:40:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:40:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:40:51 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:40:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:41:15 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.csai.cn/kouzi/198.html>: HTTP status code is not handled or not allowed
2018-08-02 14:41:51 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 50 pages/min), scraped 49 items (at 49 items/min)
2018-08-02 14:41:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:41:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:41:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:41:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:41:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:41:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:41:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:41:55 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:41:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:42:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:42:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1547,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 74383,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'dupefilter/filtered': 25,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 42, 1, 487000),
 'item_scraped_count': 6,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2018, 8, 2, 6, 41, 55, 499000)}
2018-08-02 14:42:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:42:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:42:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:42:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:42:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:42:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:42:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:42:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:42:30 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:42:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:42:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:42:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1547,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 71908,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'dupefilter/filtered': 25,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 42, 37, 619000),
 'item_scraped_count': 6,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2018, 8, 2, 6, 42, 30, 960000)}
2018-08-02 14:42:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:43:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:43:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:43:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:43:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:43:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:43:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:43:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:43:11 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:43:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:43:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\kouzi_spider.py", line 58, in parse
    print("内容等于："+response.xpath("/html/body/div[4]/div/div[2]/ul/li[2]/div[2]/div/em/text()").extract())
TypeError: must be str, not list
2018-08-02 14:43:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:43:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 307,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 11269,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 43, 11, 541000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 6, 43, 11, 258000)}
2018-08-02 14:43:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:43:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:43:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:43:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:43:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:43:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:43:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:43:35 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:43:35 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:43:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:43:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:43:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1547,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 71887,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'dupefilter/filtered': 25,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 43, 41, 465000),
 'item_scraped_count': 6,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2018, 8, 2, 6, 43, 35, 40000)}
2018-08-02 14:43:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 14:45:59 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 14:45:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 14:45:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 14:45:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 14:45:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 14:45:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 14:45:59 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 14:45:59 [scrapy.core.engine] INFO: Spider opened
2018-08-02 14:45:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 14:46:59 [scrapy.extensions.logstats] INFO: Crawled 50 pages (at 50 pages/min), scraped 50 items (at 50 items/min)
2018-08-02 14:47:59 [scrapy.extensions.logstats] INFO: Crawled 100 pages (at 50 pages/min), scraped 100 items (at 50 items/min)
2018-08-02 14:48:46 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.csai.cn/kouzi/198.html>: HTTP status code is not handled or not allowed
2018-08-02 14:48:59 [scrapy.extensions.logstats] INFO: Crawled 149 pages (at 49 pages/min), scraped 148 items (at 48 items/min)
2018-08-02 14:49:59 [scrapy.extensions.logstats] INFO: Crawled 197 pages (at 48 pages/min), scraped 196 items (at 48 items/min)
2018-08-02 14:50:59 [scrapy.extensions.logstats] INFO: Crawled 246 pages (at 49 pages/min), scraped 245 items (at 49 items/min)
2018-08-02 14:51:59 [scrapy.extensions.logstats] INFO: Crawled 294 pages (at 48 pages/min), scraped 293 items (at 48 items/min)
2018-08-02 14:52:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 14:52:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 91799,
 'downloader/request_count': 313,
 'downloader/request_method_count/GET': 313,
 'downloader/response_bytes': 3734637,
 'downloader/response_count': 313,
 'downloader/response_status_count/200': 312,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 97032,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 6, 52, 24, 168000),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 312,
 'log_count/INFO': 14,
 'request_depth_max': 2,
 'response_received_count': 313,
 'scheduler/dequeued': 313,
 'scheduler/dequeued/memory': 313,
 'scheduler/enqueued': 313,
 'scheduler/enqueued/memory': 313,
 'start_time': datetime.datetime(2018, 8, 2, 6, 45, 59, 583000)}
2018-08-02 14:52:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:14:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:14:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:14:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:14:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:14:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:14:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:14:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:14:08 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:14:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:15:08 [scrapy.extensions.logstats] INFO: Crawled 53 pages (at 53 pages/min), scraped 52 items (at 52 items/min)
2018-08-02 15:16:08 [scrapy.extensions.logstats] INFO: Crawled 101 pages (at 48 pages/min), scraped 101 items (at 49 items/min)
2018-08-02 15:16:53 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <404 https://www.csai.cn/kouzi/198.html>: HTTP status code is not handled or not allowed
2018-08-02 15:17:08 [scrapy.extensions.logstats] INFO: Crawled 152 pages (at 51 pages/min), scraped 151 items (at 50 items/min)
2018-08-02 15:18:08 [scrapy.extensions.logstats] INFO: Crawled 200 pages (at 48 pages/min), scraped 199 items (at 48 items/min)
2018-08-02 15:19:08 [scrapy.extensions.logstats] INFO: Crawled 249 pages (at 49 pages/min), scraped 248 items (at 49 items/min)
2018-08-02 15:20:08 [scrapy.extensions.logstats] INFO: Crawled 297 pages (at 48 pages/min), scraped 296 items (at 48 items/min)
2018-08-02 15:20:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:20:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 91511,
 'downloader/request_count': 313,
 'downloader/request_method_count/GET': 313,
 'downloader/response_bytes': 3676243,
 'downloader/response_count': 313,
 'downloader/response_status_count/200': 312,
 'downloader/response_status_count/404': 1,
 'dupefilter/filtered': 97032,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 20, 26, 999000),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/404': 1,
 'item_scraped_count': 312,
 'log_count/INFO': 14,
 'request_depth_max': 2,
 'response_received_count': 313,
 'scheduler/dequeued': 313,
 'scheduler/dequeued/memory': 313,
 'scheduler/enqueued': 313,
 'scheduler/enqueued/memory': 313,
 'start_time': datetime.datetime(2018, 8, 2, 7, 14, 8, 412000)}
2018-08-02 15:20:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:49:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:49:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:49:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:49:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:49:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:49:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:49:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:49:16 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:49:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:49:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 22, in parse
    appName = response.xpath("/html/body/div[3]/div[1]/div[1]/div/div[1]/h1/text()").extract()[0]
IndexError: list index out of range
2018-08-02 15:49:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:49:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 49, 16, 685000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 49, 16, 274000)}
2018-08-02 15:49:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:49:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:49:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:49:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:49:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:49:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:49:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:49:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:49:30 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:49:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:49:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    appName = response.xpath("/html/body/div[3]/div[1]/div[1]/div/div[1]/h1/text()").extract()[0]
IndexError: list index out of range
2018-08-02 15:49:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:49:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97164,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 49, 30, 733000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 49, 30, 417000)}
2018-08-02 15:49:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:50:24 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:50:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:50:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:50:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:50:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:50:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:50:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:50:24 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:50:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:50:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:50:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 50, 25, 139000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 50, 24, 792000)}
2018-08-02 15:50:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:50:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:50:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:50:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:50:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:50:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:50:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:50:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:50:38 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:50:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:50:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:50:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 50, 39, 354000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 50, 38, 978000)}
2018-08-02 15:50:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:51:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:51:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:51:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:51:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:51:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:51:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:51:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:51:33 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:51:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:51:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:51:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 51, 34, 130000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 51, 33, 803000)}
2018-08-02 15:51:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:53:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:53:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:53:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:53:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:53:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:53:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:53:31 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:53:31 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:53:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:53:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:53:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 53, 31, 406000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 53, 31, 26000)}
2018-08-02 15:53:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:53:45 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:53:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:53:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:53:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:53:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:53:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:53:45 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:53:45 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:53:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:53:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:53:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 53, 46, 128000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 53, 45, 845000)}
2018-08-02 15:53:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:54:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:54:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:54:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:54:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:54:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:54:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:54:04 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:54:04 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:54:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:54:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 54, 5, 330000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 54, 4, 957000)}
2018-08-02 15:54:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:55:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:55:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:55:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:55:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:55:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:55:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:55:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:55:27 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:55:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:55:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:55:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 55, 27, 580000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 55, 27, 186000)}
2018-08-02 15:55:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:55:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:55:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:55:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:55:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:55:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:55:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:55:47 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:55:47 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:55:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:55:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:55:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 55, 48, 34000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 55, 47, 768000)}
2018-08-02 15:55:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:56:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:56:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:56:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:56:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:56:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:56:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:56:13 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:56:13 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:56:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:56:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:56:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 56, 13, 475000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 56, 13, 157000)}
2018-08-02 15:56:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:56:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:56:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:56:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:56:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:56:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:56:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:56:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:56:27 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:56:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:56:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("normalize-space(//div[5]/div[3]/div[1]/div/ul/li[2]/)"))
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in normalize-space(//div[5]/div[3]/div[1]/div/ul/li[2]/)
2018-08-02 15:56:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:56:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 56, 27, 619000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 56, 27, 278000)}
2018-08-02 15:56:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:56:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:56:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:56:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:56:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:56:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:56:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:56:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:56:52 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:56:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:56:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:56:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97163,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 56, 52, 847000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 56, 52, 585000)}
2018-08-02 15:56:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:57:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:57:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:57:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:57:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:57:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:57:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:57:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:57:34 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:57:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:57:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:57:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97170,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 57, 34, 833000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 57, 34, 510000)}
2018-08-02 15:57:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 15:57:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 15:57:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 15:57:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 15:57:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 15:57:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 15:57:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 15:57:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 15:57:41 [scrapy.core.engine] INFO: Spider opened
2018-08-02 15:57:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 15:57:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 15:57:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97170,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 7, 57, 42, 219000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 7, 57, 41, 871000)}
2018-08-02 15:57:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:00:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:00:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:00:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:00:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:00:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:00:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:00:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:00:11 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:00:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:00:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]//text()"%2).extract())
TypeError: not all arguments converted during string formatting
2018-08-02 16:00:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:00:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 0, 12, 158000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 0, 11, 776000)}
2018-08-02 16:00:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:00:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:00:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:00:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:00:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:00:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:00:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:00:23 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:00:23 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:00:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:00:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:00:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 0, 23, 840000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 0, 23, 336000)}
2018-08-02 16:00:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:01:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:01:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:01:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:01:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:01:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:01:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:01:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:01:57 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:01:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:01:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]//string()").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]//string()
2018-08-02 16:01:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:01:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 1, 57, 485000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 1, 57, 103000)}
2018-08-02 16:01:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:02:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:02:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:02:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:02:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:02:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:02:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:02:05 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:02:05 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:02:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:02:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]//string(.)").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]//string(.)
2018-08-02 16:02:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:02:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 2, 6, 285000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 2, 5, 840000)}
2018-08-02 16:02:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:02:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:02:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:02:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:02:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:02:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:02:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:02:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:02:17 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:02:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:02:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]/string(.)").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]/string(.)
2018-08-02 16:02:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:02:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 2, 17, 525000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 2, 17, 199000)}
2018-08-02 16:02:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:02:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:02:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:02:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:02:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:02:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:02:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:02:23 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:02:23 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:02:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:02:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]/string()").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]/string()
2018-08-02 16:02:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:02:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 2, 23, 954000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 2, 23, 668000)}
2018-08-02 16:02:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:03:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:03:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:03:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:03:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:03:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:03:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:03:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:03:24 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:03:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:03:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]/string()").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]/string()
2018-08-02 16:03:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:03:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 3, 24, 437000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 3, 24, 108000)}
2018-08-02 16:03:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:03:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:03:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:03:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:03:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:03:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:03:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:03:35 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:03:35 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:03:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:03:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]/data()").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]/data()
2018-08-02 16:03:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:03:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 3, 35, 462000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 3, 35, 193000)}
2018-08-02 16:03:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:03:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:03:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:03:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:03:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:03:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:03:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:03:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:03:41 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:03:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:03:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]//data()").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]//data()
2018-08-02 16:03:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:03:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 3, 42, 218000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 3, 41, 894000)}
2018-08-02 16:03:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:04:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:04:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:04:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:04:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:04:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:04:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:04:07 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:04:07 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:04:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:04:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]//string()").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]//string()
2018-08-02 16:04:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:04:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 4, 7, 443000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 4, 7, 110000)}
2018-08-02 16:04:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:04:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:04:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:04:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:04:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:04:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:04:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:04:13 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:04:13 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:04:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:04:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[1]/string()").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[1]/string()
2018-08-02 16:04:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:04:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 4, 13, 555000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 4, 13, 77000)}
2018-08-02 16:04:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:04:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:04:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:04:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:04:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:04:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:04:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:04:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:04:24 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:04:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:04:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath("/html/body/div[5]/div[3]/div[1]/div/ul/li[2]/string()").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[3]/div[1]/div/ul/li[2]/string()
2018-08-02 16:04:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:04:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 4, 24, 519000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 4, 24, 133000)}
2018-08-02 16:04:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:04:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:04:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:04:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:04:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:04:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:04:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:04:36 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:04:36 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:04:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:04:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:04:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 4, 36, 324000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 4, 36, 50000)}
2018-08-02 16:04:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:04:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:04:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:04:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:04:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:04:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:04:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:04:49 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:04:49 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:04:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:04:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:04:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97171,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 4, 49, 530000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 4, 49, 179000)}
2018-08-02 16:04:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:07:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:07:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:07:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:07:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:07:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:07:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:07:03 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:07:03 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:07:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:07:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:07:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97160,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 7, 4, 83000),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 7, 3, 501000)}
2018-08-02 16:07:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:07:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:07:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:07:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:07:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:07:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:07:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:07:35 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:07:35 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:07:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:07:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 23, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:07:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:07:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97160,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 7, 35, 632000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 7, 35, 392000)}
2018-08-02 16:07:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:08:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:08:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:08:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:08:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:08:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:08:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:08:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:08:41 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:08:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:08:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 24, in parse
    print(data.xpath('string(.)'))
AttributeError: 'list' object has no attribute 'xpath'
2018-08-02 16:08:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:08:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97160,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 8, 41, 391000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 8, 41, 169000)}
2018-08-02 16:08:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:08:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:08:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:08:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:08:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:08:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:08:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:08:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:08:52 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:08:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:08:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:08:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:08:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97160,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 8, 52, 553000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 8, 52, 317000)}
2018-08-02 16:08:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:09:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:09:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:09:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:09:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:09:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:09:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:09:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:09:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:09:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:09:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/list-2960-10000-12-0-0-0-0-1.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:09:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:09:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 97160,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 9, 6, 255000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 9, 6, 41000)}
2018-08-02 16:09:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:19:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:19:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:19:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:19:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:19:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:19:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:19:05 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:19:05 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:19:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:19:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:19:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 19, 6, 141000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 19, 5, 816000)}
2018-08-02 16:19:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:19:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:19:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:19:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:19:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:19:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:19:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:19:39 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:19:39 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:19:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:19:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:19:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:19:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 19, 39, 764000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 19, 39, 506000)}
2018-08-02 16:19:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:20:18 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:20:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:20:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:20:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:20:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:20:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:20:19 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:20:19 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:20:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:20:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 27, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:20:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:20:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 20, 19, 341000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 20, 19, 29000)}
2018-08-02 16:20:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:21:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:21:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:21:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:21:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:21:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:21:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:21:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:21:54 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:21:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:21:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:21:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:21:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 21, 54, 399000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 21, 54, 127000)}
2018-08-02 16:21:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:22:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:22:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:22:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:22:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:22:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:22:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:22:07 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:22:07 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:22:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:22:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:22:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:22:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 22, 8, 31000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 22, 7, 761000)}
2018-08-02 16:22:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:22:26 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:22:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:22:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:22:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:22:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:22:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:22:26 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:22:26 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:22:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:22:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:22:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:22:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 22, 26, 794000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 22, 26, 460000)}
2018-08-02 16:22:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:22:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:22:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:22:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:22:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:22:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:22:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:22:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:22:50 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:22:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:22:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:22:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:22:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 22, 50, 348000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 22, 50, 26000)}
2018-08-02 16:22:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:23:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:23:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:23:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:23:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:23:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:23:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:23:02 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:23:02 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:23:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:23:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:23:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:23:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 23, 2, 394000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 23, 2, 13000)}
2018-08-02 16:23:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:23:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:23:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:23:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:23:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:23:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:23:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:23:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:23:16 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:23:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:23:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:23:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:23:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 23, 16, 337000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 23, 16, 66000)}
2018-08-02 16:23:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:25:09 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:25:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:25:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:25:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:25:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:25:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:25:09 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:25:09 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:25:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:25:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:25:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:25:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 25, 10, 87000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 25, 9, 708000)}
2018-08-02 16:25:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:25:19 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:25:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:25:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:25:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:25:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:25:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:25:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:25:20 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:25:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:25:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:25:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:25:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 25, 20, 345000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 25, 20, 18000)}
2018-08-02 16:25:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:25:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:25:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:25:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:25:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:25:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:25:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:25:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:25:27 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:25:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:25:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 25, in parse
    print(response.xpath("/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/span[@class='col999']/").extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/span[@class='col999']/
2018-08-02 16:25:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:25:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 25, 27, 608000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 25, 27, 280000)}
2018-08-02 16:25:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:25:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:25:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:25:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:25:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:25:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:25:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:25:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:25:54 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:25:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:25:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:25:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:25:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 25, 54, 419000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 25, 54, 45000)}
2018-08-02 16:25:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:26:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:26:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:26:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:26:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:26:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:26:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:26:31 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:26:31 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:26:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:26:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:26:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:26:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 26, 31, 419000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 26, 31, 139000)}
2018-08-02 16:26:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:27:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:27:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:27:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:27:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:27:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:27:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:27:02 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:27:02 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:27:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:27:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:27:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:27:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 27, 2, 926000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 27, 2, 605000)}
2018-08-02 16:27:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:27:43 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:27:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:27:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:27:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:27:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:27:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:27:43 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:27:43 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:27:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:27:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:27:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:27:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 27, 43, 844000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 27, 43, 480000)}
2018-08-02 16:27:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:27:50 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:27:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:27:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:27:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:27:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:27:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:27:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:27:50 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:27:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:27:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:27:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:27:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 27, 50, 883000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 27, 50, 584000)}
2018-08-02 16:27:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:28:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:28:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:28:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:28:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:28:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:28:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:28:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:28:33 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:28:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:28:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:28:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:28:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 28, 34, 26000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 28, 33, 693000)}
2018-08-02 16:28:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:29:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:29:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:29:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:29:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:29:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:29:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:29:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:29:53 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:29:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:29:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 30, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:29:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:29:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 29, 54, 236000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 29, 53, 743000)}
2018-08-02 16:29:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:31:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:31:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:31:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:31:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:31:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:31:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:31:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:31:01 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:31:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:31:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    print(response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/p//text()').extract().splitlines())
AttributeError: 'list' object has no attribute 'splitlines'
2018-08-02 16:31:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:31:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 31, 1, 334000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 31, 1, 7000)}
2018-08-02 16:31:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:31:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:31:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:31:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:31:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:31:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:31:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:31:13 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:31:13 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:31:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:31:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    print(response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/p//text()').splitlines())
AttributeError: 'SelectorList' object has no attribute 'splitlines'
2018-08-02 16:31:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:31:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 31, 14, 227000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 31, 13, 893000)}
2018-08-02 16:31:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:32:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:32:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:32:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:32:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:32:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:32:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:32:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:32:11 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:32:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:32:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    print(response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/p//text()').extract().strip() )
AttributeError: 'list' object has no attribute 'strip'
2018-08-02 16:32:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:32:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80485,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 32, 11, 400000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 32, 11, 118000)}
2018-08-02 16:32:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:33:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:33:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:33:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:33:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:33:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:33:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:33:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:33:20 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:33:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:33:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 32, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:33:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:33:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 33, 21, 94000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 33, 20, 754000)}
2018-08-02 16:33:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:33:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:33:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:33:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:33:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:33:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:33:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:33:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:33:42 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:33:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:33:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 32, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:33:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:33:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 33, 43, 310000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 33, 42, 984000)}
2018-08-02 16:33:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:37:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:37:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:37:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:37:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:37:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:37:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:37:35 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:37:35 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:37:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:37:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    nn=response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/p/span/text()').extract()[2]
IndexError: list index out of range
2018-08-02 16:37:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:37:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 37, 35, 618000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 37, 35, 293000)}
2018-08-02 16:37:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:37:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:37:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:37:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:37:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:37:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:37:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:37:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:37:57 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:37:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:37:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 26, in parse
    nn=response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/p/span/text()').extract()[2]
IndexError: list index out of range
2018-08-02 16:37:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:37:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 37, 58, 300000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 37, 58, 1000)}
2018-08-02 16:37:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:38:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:38:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:38:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:38:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:38:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:38:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:38:15 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:38:15 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:38:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:38:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 32, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:38:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:38:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 38, 16, 330000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 38, 15, 944000)}
2018-08-02 16:38:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:38:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:38:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:38:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:38:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:38:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:38:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:38:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:38:40 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:38:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:38:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 32, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:38:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:38:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 38, 40, 654000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 38, 40, 270000)}
2018-08-02 16:38:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:38:59 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:38:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:38:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:38:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:38:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:38:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:38:59 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:38:59 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:38:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:39:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:39:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:39:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 39, 0, 101000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 38, 59, 729000)}
2018-08-02 16:39:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:39:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:39:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:39:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:39:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:39:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:39:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:39:29 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:39:29 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:39:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 27, in parse
    print(response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd/p/string()').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[2]/div[1]/div[1]/dl/dd/p/string()
2018-08-02 16:39:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:39:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 39, 29, 395000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 39, 29, 48000)}
2018-08-02 16:39:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:39:48 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:39:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:39:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:39:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:39:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:39:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:39:48 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:39:48 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:39:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:39:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 27, in parse
    print(response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/p/data()').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[5]/div[2]/div[1]/div[1]/dl/dd[1]/p/data()
2018-08-02 16:39:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:39:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 39, 48, 878000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 39, 48, 515000)}
2018-08-02 16:39:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:39:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:39:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:39:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:39:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:39:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:39:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:39:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:39:57 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:39:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:39:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:39:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:39:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 39, 58, 205000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 39, 57, 878000)}
2018-08-02 16:39:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:41:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:41:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:41:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:41:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:41:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:41:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:41:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:41:28 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:41:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:41:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:41:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:41:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 41, 29, 317000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 41, 28, 847000)}
2018-08-02 16:41:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:42:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:42:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:42:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:42:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:42:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:42:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:42:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:42:34 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:42:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:42:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:42:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:42:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 42, 34, 812000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 42, 34, 413000)}
2018-08-02 16:42:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:43:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:43:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:43:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:43:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:43:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:43:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:43:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:43:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:43:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:43:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:43:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:43:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 43, 7, 203000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 43, 6, 822000)}
2018-08-02 16:43:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:43:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:43:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:43:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:43:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:43:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:43:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:43:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:43:11 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:43:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:43:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:43:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:43:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 43, 11, 953000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 43, 11, 608000)}
2018-08-02 16:43:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:43:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:43:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:43:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:43:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:43:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:43:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:43:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:43:20 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:43:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:43:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:43:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:43:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 43, 20, 735000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 43, 20, 382000)}
2018-08-02 16:43:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:43:29 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:43:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:43:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:43:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:43:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:43:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:43:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:43:30 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:43:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:43:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:43:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:43:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 43, 30, 464000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 43, 30, 74000)}
2018-08-02 16:43:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:43:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:43:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:43:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:43:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:43:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:43:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:43:45 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:43:45 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:43:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:43:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:43:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:43:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 43, 45, 470000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 43, 45, 148000)}
2018-08-02 16:43:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:43:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:43:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:43:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:43:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:43:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:43:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:43:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:43:53 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:43:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:43:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:43:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:43:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 43, 54, 79000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 43, 53, 787000)}
2018-08-02 16:43:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:44:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:44:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:44:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:44:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:44:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:44:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:44:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:44:00 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:44:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:44:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:44:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:44:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 44, 1, 85000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 44, 0, 550000)}
2018-08-02 16:44:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:44:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:44:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:44:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:44:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:44:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:44:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:44:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:44:08 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:44:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:44:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:44:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:44:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 44, 9, 40000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 44, 8, 714000)}
2018-08-02 16:44:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:44:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:44:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:44:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:44:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:44:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:44:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:44:15 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:44:15 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:44:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:44:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:44:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:44:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 44, 15, 760000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 44, 15, 205000)}
2018-08-02 16:44:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:44:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:44:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:44:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:44:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:44:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:44:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:44:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:44:21 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:44:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:44:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:44:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:44:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 44, 21, 596000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 44, 21, 266000)}
2018-08-02 16:44:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:44:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:44:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:44:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:44:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:44:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:44:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:44:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:44:28 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:44:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:44:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 33, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:44:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:44:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 44, 28, 659000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 44, 28, 332000)}
2018-08-02 16:44:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:44:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:44:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:44:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:44:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:44:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:44:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:44:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:44:52 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:44:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:44:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 34, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:44:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:44:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 44, 52, 627000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 44, 52, 262000)}
2018-08-02 16:44:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:45:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:45:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:45:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:45:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:45:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:45:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:45:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:45:52 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:45:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:45:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 35, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:45:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:45:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 45, 52, 531000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 45, 52, 255000)}
2018-08-02 16:45:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:46:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:46:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:46:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:46:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:46:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:46:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:46:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:46:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:46:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:46:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 35, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:46:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:46:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 46, 6, 648000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 46, 6, 333000)}
2018-08-02 16:46:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:46:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:46:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:46:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:46:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:46:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:46:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:46:25 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:46:25 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:46:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:46:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 35, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:46:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:46:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 46, 25, 446000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 46, 25, 174000)}
2018-08-02 16:46:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:46:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:46:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:46:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:46:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:46:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:46:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:46:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:46:40 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:46:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:46:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 36, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:46:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:46:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 46, 41, 748000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 46, 40, 705000)}
2018-08-02 16:46:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:48:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:48:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:48:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:48:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:48:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:48:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:48:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:48:34 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:48:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:48:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 36, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:48:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:48:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 48, 35, 118000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 48, 34, 843000)}
2018-08-02 16:48:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:48:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:48:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:48:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:48:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:48:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:48:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:48:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:48:51 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:48:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:48:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 36, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:48:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:48:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 48, 52, 9000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 48, 51, 561000)}
2018-08-02 16:48:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:49:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:49:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:49:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:49:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:49:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:49:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:49:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:49:06 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:49:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:49:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 36, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:49:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:49:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 49, 6, 630000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 49, 6, 255000)}
2018-08-02 16:49:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:49:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:49:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:49:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:49:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:49:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:49:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:49:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:49:17 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:49:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:49:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 36, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:49:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:49:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 49, 17, 909000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 49, 17, 625000)}
2018-08-02 16:49:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:50:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:50:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:50:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:50:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:50:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:50:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:50:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:50:22 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:50:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:50:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 36, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:50:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:50:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 50, 23, 137000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 50, 22, 598000)}
2018-08-02 16:50:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:50:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:50:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:50:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:50:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:50:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:50:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:50:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:50:55 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:50:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:50:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 27, in parse
    print(response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd/p//text()').extract().replace("\r","").replace("\n","").replace("\n",""))
AttributeError: 'list' object has no attribute 'replace'
2018-08-02 16:50:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:50:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 50, 56, 62000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 50, 55, 507000)}
2018-08-02 16:50:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:51:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:51:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:51:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:51:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:51:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:51:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:51:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:51:21 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:51:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:51:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 27, in parse
    print(response.xpath('/html/body/div[5]/div[2]/div[1]/div[1]/dl/dd/p//text()').extract().replace("\r","").replace("\n","").replace("\n",""))
AttributeError: 'list' object has no attribute 'replace'
2018-08-02 16:51:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:51:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 51, 21, 725000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 51, 21, 352000)}
2018-08-02 16:51:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:51:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:51:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:51:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:51:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:51:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:51:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:51:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:51:32 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:51:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:51:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 36, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:51:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:51:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 51, 32, 561000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 51, 32, 234000)}
2018-08-02 16:51:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:53:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:53:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:53:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:53:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:53:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:53:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:53:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:53:28 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:53:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:53:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:53:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:53:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 53, 29, 117000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 53, 28, 732000)}
2018-08-02 16:53:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:53:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:53:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:53:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:53:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:53:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:53:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:53:39 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:53:39 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:53:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:53:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:53:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:53:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 53, 39, 535000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 53, 39, 198000)}
2018-08-02 16:53:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:53:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:53:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:53:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:53:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:53:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:53:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:53:49 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:53:49 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:53:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:53:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:53:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:53:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 53, 49, 872000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 53, 49, 521000)}
2018-08-02 16:53:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:55:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:55:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:55:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:55:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:55:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:55:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:55:18 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:55:18 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:55:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:55:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 44, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:55:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:55:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 55, 18, 416000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 55, 18, 32000)}
2018-08-02 16:55:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 16:56:48 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 16:56:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 16:56:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 16:56:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 16:56:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 16:56:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 16:56:48 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 16:56:48 [scrapy.core.engine] INFO: Spider opened
2018-08-02 16:56:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 16:56:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 46, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 16:56:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 16:56:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 8, 56, 49, 255000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 8, 56, 48, 754000)}
2018-08-02 16:56:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:00:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:00:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:00:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:00:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:00:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:00:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:00:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:00:56 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:00:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:00:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 50, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:00:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:00:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 0, 56, 834000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 0, 56, 456000)}
2018-08-02 17:00:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:02:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:02:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:02:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:02:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:02:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:02:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:02:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:02:10 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:02:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:02:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 43, in parse
    print(n.replace("\r","").replace("\n","").replace("\n",""))
NameError: name 'n' is not defined
2018-08-02 17:02:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:02:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 2, 10, 957000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 2, 10, 586000)}
2018-08-02 17:02:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:02:43 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:02:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:02:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:02:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:02:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:02:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:02:43 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:02:43 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:02:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:02:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 43, in parse
    print(n.replace("\r","").replace("\n","").replace("\n",""))
NameError: name 'n' is not defined
2018-08-02 17:02:44 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:02:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 2, 44, 24000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 2, 43, 676000)}
2018-08-02 17:02:44 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:03:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:03:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:03:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:03:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:03:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:03:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:03:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:03:08 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:03:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:03:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 51, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:03:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:03:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 3, 9, 77000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 3, 8, 723000)}
2018-08-02 17:03:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:03:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:03:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:03:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:03:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:03:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:03:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:03:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:03:53 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:03:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:03:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 51, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:03:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:03:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 3, 54, 72000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 3, 53, 687000)}
2018-08-02 17:03:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:04:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:04:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:04:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:04:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:04:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:04:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:04:49 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:04:49 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:04:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:04:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:04:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:04:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 4, 49, 807000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 4, 49, 476000)}
2018-08-02 17:04:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:05:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:05:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:05:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:05:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:05:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:05:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:05:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:05:22 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:05:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:05:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:05:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:05:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 5, 22, 584000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 5, 22, 86000)}
2018-08-02 17:05:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:05:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:05:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:05:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:05:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:05:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:05:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:05:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:05:44 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:05:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:05:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:05:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:05:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 5, 45, 105000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 5, 44, 770000)}
2018-08-02 17:05:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:06:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:06:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:06:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:06:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:06:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:06:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:06:03 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:06:03 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:06:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:06:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:06:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:06:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 6, 3, 961000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 6, 3, 633000)}
2018-08-02 17:06:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:06:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:06:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:06:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:06:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:06:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:06:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:06:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:06:28 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:06:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:06:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:06:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:06:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 6, 29, 309000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 6, 28, 907000)}
2018-08-02 17:06:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:07:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:07:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:07:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:07:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:07:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:07:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:07:49 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:07:49 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:07:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:07:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:07:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:07:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 7, 50, 832000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 7, 49, 480000)}
2018-08-02 17:07:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:08:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:08:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:08:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:08:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:08:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:08:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:08:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:08:10 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:08:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:08:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:08:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:08:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 8, 10, 829000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 8, 10, 500000)}
2018-08-02 17:08:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:11:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:11:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:11:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:11:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:11:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:11:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:11:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:11:11 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:11:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:11:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:11:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:11:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 11, 12, 144000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 11, 11, 758000)}
2018-08-02 17:11:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:11:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:11:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:11:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:11:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:11:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:11:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:11:25 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:11:25 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:11:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:11:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:11:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:11:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 11, 25, 725000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 11, 25, 350000)}
2018-08-02 17:11:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:12:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:12:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:12:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:12:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:12:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:12:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:12:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:12:52 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:12:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:12:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:12:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:12:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 12, 53, 350000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 12, 52, 971000)}
2018-08-02 17:12:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:13:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:13:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:13:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:13:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:13:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:13:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:13:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:13:21 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:13:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:13:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 53, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:13:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:13:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 13, 21, 816000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 13, 21, 480000)}
2018-08-02 17:13:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:28:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:28:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:28:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:28:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:28:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:28:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:28:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:28:01 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:28:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:28:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 65, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:28:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:28:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80489,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 28, 2, 257000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 28, 1, 923000)}
2018-08-02 17:28:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:28:24 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:28:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:28:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:28:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:28:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:28:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:28:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:28:24 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:28:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:28:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 65, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:28:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:28:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80493,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 28, 25, 316000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 28, 24, 930000)}
2018-08-02 17:28:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:29:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:29:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:29:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:29:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:29:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:29:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:29:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:29:52 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:29:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:29:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 65, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:29:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:29:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 29, 52, 552000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 29, 52, 156000)}
2018-08-02 17:29:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:30:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:30:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:30:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:30:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:30:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:30:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:30:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:30:00 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:30:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:30:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 65, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:30:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:30:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 30, 1, 469000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 30, 0, 930000)}
2018-08-02 17:30:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:31:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:31:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:31:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:31:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:31:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:31:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:31:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:31:32 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:31:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:31:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 66, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:31:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:31:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 31, 32, 873000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 31, 32, 492000)}
2018-08-02 17:31:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:37:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:37:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:37:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:37:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:37:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:37:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:37:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:37:41 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:37:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:37:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 76, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:37:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:37:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 37, 41, 826000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 37, 41, 499000)}
2018-08-02 17:37:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:37:59 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:37:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:37:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:37:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:37:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:37:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:37:59 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:37:59 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:37:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:37:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 76, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:37:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:37:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 37, 59, 951000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 37, 59, 647000)}
2018-08-02 17:37:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:38:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:38:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:38:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:38:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:38:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:38:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:38:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:38:10 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:38:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:38:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 76, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:38:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:38:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 38, 10, 935000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 38, 10, 615000)}
2018-08-02 17:38:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:38:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:38:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:38:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:38:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:38:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:38:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:38:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:38:54 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:38:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:38:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 76, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:38:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:38:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 38, 54, 677000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 38, 54, 334000)}
2018-08-02 17:38:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:40:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:40:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:40:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:40:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:40:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:40:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:40:04 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:40:04 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:40:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:40:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/product-11370.html> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 76, in parse
    print(response.xpath('//div[5]/string(.)').extract())
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in //div[5]/string(.)
2018-08-02 17:40:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:40:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 80492,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 40, 5, 196000),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 40, 4, 916000)}
2018-08-02 17:40:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:47:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:47:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:47:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:47:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:47:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:47:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:47:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:47:44 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:47:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:47:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:47:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2750,
 'downloader/request_count': 10,
 'downloader/request_method_count/GET': 10,
 'downloader/response_bytes': 749967,
 'downloader/response_count': 10,
 'downloader/response_status_count/200': 10,
 'dupefilter/filtered': 81,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 47, 55, 994000),
 'item_scraped_count': 10,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 10,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2018, 8, 2, 9, 47, 44, 696000)}
2018-08-02 17:47:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:50:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:50:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:50:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:50:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:50:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:50:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:50:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:50:51 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:50:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:50:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/error/500.do> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    贷款金额 = dataArray[2]
IndexError: list index out of range
2018-08-02 17:50:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 17:50:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 948,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 2888,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 9, 50, 54, 963000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 50, 51, 959000)}
2018-08-02 17:50:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 17:51:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:51:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:51:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:51:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:51:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:51:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:51:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:51:11 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:51:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:52:11 [scrapy.extensions.logstats] INFO: Crawled 22 pages (at 22 pages/min), scraped 22 items (at 22 items/min)
2018-08-02 17:52:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/error/500.do> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    贷款金额 = dataArray[2]
IndexError: list index out of range
2018-08-02 17:53:11 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 11 pages/min), scraped 32 items (at 10 items/min)
2018-08-02 17:54:11 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 5 pages/min), scraped 37 items (at 5 items/min)
2018-08-02 17:55:11 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 0 pages/min), scraped 37 items (at 0 items/min)
2018-08-02 17:56:11 [scrapy.extensions.logstats] INFO: Crawled 38 pages (at 0 pages/min), scraped 37 items (at 0 items/min)
2018-08-02 17:57:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:57:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:57:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:57:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:57:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:57:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:57:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:57:28 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:57:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:58:28 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 24 pages/min), scraped 24 items (at 24 items/min)
2018-08-02 17:58:59 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 17:58:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 17:58:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 17:58:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 17:58:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 17:58:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 17:58:59 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 17:58:59 [scrapy.core.engine] INFO: Spider opened
2018-08-02 17:58:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 17:59:59 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 51 pages/min), scraped 51 items (at 51 items/min)
2018-08-02 18:00:59 [scrapy.extensions.logstats] INFO: Crawled 99 pages (at 48 pages/min), scraped 99 items (at 48 items/min)
2018-08-02 18:02:00 [scrapy.extensions.logstats] INFO: Crawled 147 pages (at 48 pages/min), scraped 147 items (at 48 items/min)
2018-08-02 18:02:59 [scrapy.extensions.logstats] INFO: Crawled 196 pages (at 49 pages/min), scraped 196 items (at 49 items/min)
2018-08-02 18:03:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/error/500.do> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    贷款金额 = dataArray[2]
IndexError: list index out of range
2018-08-02 18:03:59 [scrapy.extensions.logstats] INFO: Crawled 244 pages (at 48 pages/min), scraped 242 items (at 46 items/min)
2018-08-02 18:04:59 [scrapy.extensions.logstats] INFO: Crawled 294 pages (at 50 pages/min), scraped 293 items (at 51 items/min)
2018-08-02 18:05:59 [scrapy.extensions.logstats] INFO: Crawled 341 pages (at 47 pages/min), scraped 339 items (at 46 items/min)
2018-08-02 18:06:59 [scrapy.extensions.logstats] INFO: Crawled 390 pages (at 49 pages/min), scraped 389 items (at 50 items/min)
2018-08-02 18:07:59 [scrapy.extensions.logstats] INFO: Crawled 437 pages (at 47 pages/min), scraped 436 items (at 47 items/min)
2018-08-02 18:08:59 [scrapy.extensions.logstats] INFO: Crawled 487 pages (at 50 pages/min), scraped 486 items (at 50 items/min)
2018-08-02 18:09:59 [scrapy.extensions.logstats] INFO: Crawled 536 pages (at 49 pages/min), scraped 535 items (at 49 items/min)
2018-08-02 18:10:59 [scrapy.extensions.logstats] INFO: Crawled 585 pages (at 49 pages/min), scraped 584 items (at 49 items/min)
2018-08-02 18:11:59 [scrapy.extensions.logstats] INFO: Crawled 634 pages (at 49 pages/min), scraped 632 items (at 48 items/min)
2018-08-02 18:12:59 [scrapy.extensions.logstats] INFO: Crawled 683 pages (at 49 pages/min), scraped 682 items (at 50 items/min)
2018-08-02 18:13:59 [scrapy.extensions.logstats] INFO: Crawled 732 pages (at 49 pages/min), scraped 731 items (at 49 items/min)
2018-08-02 18:14:59 [scrapy.extensions.logstats] INFO: Crawled 781 pages (at 49 pages/min), scraped 780 items (at 49 items/min)
2018-08-02 18:15:59 [scrapy.extensions.logstats] INFO: Crawled 829 pages (at 48 pages/min), scraped 828 items (at 48 items/min)
2018-08-02 18:16:59 [scrapy.extensions.logstats] INFO: Crawled 876 pages (at 47 pages/min), scraped 875 items (at 47 items/min)
2018-08-02 18:17:59 [scrapy.extensions.logstats] INFO: Crawled 925 pages (at 49 pages/min), scraped 924 items (at 49 items/min)
2018-08-02 18:18:59 [scrapy.extensions.logstats] INFO: Crawled 976 pages (at 51 pages/min), scraped 975 items (at 51 items/min)
2018-08-02 18:19:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 18:19:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 335232,
 'downloader/request_count': 1001,
 'downloader/request_method_count/GET': 1001,
 'downloader/response_bytes': 73959193,
 'downloader/response_count': 1001,
 'downloader/response_status_count/200': 996,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/302': 4,
 'dupefilter/filtered': 992015,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 10, 19, 25, 861000),
 'item_scraped_count': 995,
 'log_count/ERROR': 1,
 'log_count/INFO': 27,
 'request_depth_max': 2,
 'response_received_count': 996,
 'scheduler/dequeued': 1001,
 'scheduler/dequeued/memory': 1001,
 'scheduler/enqueued': 1001,
 'scheduler/enqueued/memory': 1001,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 9, 58, 59, 989000)}
2018-08-02 18:19:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 18:34:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 18:34:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 18:34:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 18:34:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 18:34:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 18:34:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 18:34:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 18:34:28 [scrapy.core.engine] INFO: Spider opened
2018-08-02 18:34:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 18:35:28 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 49 pages/min), scraped 49 items (at 49 items/min)
2018-08-02 18:36:28 [scrapy.extensions.logstats] INFO: Crawled 100 pages (at 51 pages/min), scraped 100 items (at 51 items/min)
2018-08-02 18:37:28 [scrapy.extensions.logstats] INFO: Crawled 149 pages (at 49 pages/min), scraped 149 items (at 49 items/min)
2018-08-02 18:38:28 [scrapy.extensions.logstats] INFO: Crawled 200 pages (at 51 pages/min), scraped 200 items (at 51 items/min)
2018-08-02 18:39:28 [scrapy.extensions.logstats] INFO: Crawled 249 pages (at 49 pages/min), scraped 249 items (at 49 items/min)
2018-08-02 18:40:28 [scrapy.extensions.logstats] INFO: Crawled 297 pages (at 48 pages/min), scraped 297 items (at 48 items/min)
2018-08-02 18:41:28 [scrapy.extensions.logstats] INFO: Crawled 347 pages (at 50 pages/min), scraped 347 items (at 50 items/min)
2018-08-02 18:42:28 [scrapy.extensions.logstats] INFO: Crawled 397 pages (at 50 pages/min), scraped 397 items (at 50 items/min)
2018-08-02 18:43:28 [scrapy.extensions.logstats] INFO: Crawled 446 pages (at 49 pages/min), scraped 446 items (at 49 items/min)
2018-08-02 18:44:28 [scrapy.extensions.logstats] INFO: Crawled 494 pages (at 48 pages/min), scraped 494 items (at 48 items/min)
2018-08-02 18:45:28 [scrapy.extensions.logstats] INFO: Crawled 547 pages (at 53 pages/min), scraped 547 items (at 53 items/min)
2018-08-02 18:46:28 [scrapy.extensions.logstats] INFO: Crawled 595 pages (at 48 pages/min), scraped 595 items (at 48 items/min)
2018-08-02 18:47:28 [scrapy.extensions.logstats] INFO: Crawled 645 pages (at 50 pages/min), scraped 645 items (at 50 items/min)
2018-08-02 18:48:28 [scrapy.extensions.logstats] INFO: Crawled 695 pages (at 50 pages/min), scraped 695 items (at 50 items/min)
2018-08-02 18:49:28 [scrapy.extensions.logstats] INFO: Crawled 744 pages (at 49 pages/min), scraped 744 items (at 49 items/min)
2018-08-02 18:50:28 [scrapy.extensions.logstats] INFO: Crawled 794 pages (at 50 pages/min), scraped 794 items (at 50 items/min)
2018-08-02 18:51:28 [scrapy.extensions.logstats] INFO: Crawled 844 pages (at 50 pages/min), scraped 844 items (at 50 items/min)
2018-08-02 18:52:28 [scrapy.extensions.logstats] INFO: Crawled 896 pages (at 52 pages/min), scraped 896 items (at 52 items/min)
2018-08-02 18:53:28 [scrapy.extensions.logstats] INFO: Crawled 946 pages (at 50 pages/min), scraped 946 items (at 50 items/min)
2018-08-02 18:54:28 [scrapy.extensions.logstats] INFO: Crawled 995 pages (at 49 pages/min), scraped 995 items (at 49 items/min)
2018-08-02 18:55:28 [scrapy.extensions.logstats] INFO: Crawled 1045 pages (at 50 pages/min), scraped 1044 items (at 49 items/min)
2018-08-02 18:56:28 [scrapy.extensions.logstats] INFO: Crawled 1094 pages (at 49 pages/min), scraped 1094 items (at 50 items/min)
2018-08-02 18:57:28 [scrapy.extensions.logstats] INFO: Crawled 1144 pages (at 50 pages/min), scraped 1144 items (at 50 items/min)
2018-08-02 18:58:28 [scrapy.extensions.logstats] INFO: Crawled 1194 pages (at 50 pages/min), scraped 1193 items (at 49 items/min)
2018-08-02 18:59:28 [scrapy.extensions.logstats] INFO: Crawled 1242 pages (at 48 pages/min), scraped 1242 items (at 49 items/min)
2018-08-02 19:00:28 [scrapy.extensions.logstats] INFO: Crawled 1292 pages (at 50 pages/min), scraped 1292 items (at 50 items/min)
2018-08-02 19:01:28 [scrapy.extensions.logstats] INFO: Crawled 1341 pages (at 49 pages/min), scraped 1341 items (at 49 items/min)
2018-08-02 19:02:28 [scrapy.extensions.logstats] INFO: Crawled 1390 pages (at 49 pages/min), scraped 1390 items (at 49 items/min)
2018-08-02 19:03:28 [scrapy.extensions.logstats] INFO: Crawled 1436 pages (at 46 pages/min), scraped 1436 items (at 46 items/min)
2018-08-02 19:04:28 [scrapy.extensions.logstats] INFO: Crawled 1484 pages (at 48 pages/min), scraped 1484 items (at 48 items/min)
2018-08-02 19:05:28 [scrapy.extensions.logstats] INFO: Crawled 1534 pages (at 50 pages/min), scraped 1534 items (at 50 items/min)
2018-08-02 19:06:17 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://daikuan.csaimall.com/product-2440.html>: HTTP status code is not handled or not allowed
2018-08-02 19:06:28 [scrapy.extensions.logstats] INFO: Crawled 1585 pages (at 51 pages/min), scraped 1584 items (at 50 items/min)
2018-08-02 19:06:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/error/500.do> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    贷款金额 = dataArray[2]
IndexError: list index out of range
2018-08-02 19:07:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 19:07:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 19:07:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 19:07:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 19:07:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 19:07:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 19:07:15 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 19:07:15 [scrapy.core.engine] INFO: Spider opened
2018-08-02 19:07:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 19:07:28 [scrapy.extensions.logstats] INFO: Crawled 1629 pages (at 44 pages/min), scraped 1626 items (at 42 items/min)
2018-08-02 19:07:35 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://daikuan.csaimall.com/product-2379.html>: HTTP status code is not handled or not allowed
2018-08-02 19:08:15 [scrapy.extensions.logstats] INFO: Crawled 48 pages (at 48 pages/min), scraped 48 items (at 48 items/min)
2018-08-02 19:08:28 [scrapy.extensions.logstats] INFO: Crawled 1677 pages (at 48 pages/min), scraped 1674 items (at 48 items/min)
2018-08-02 19:09:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 19:09:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 19:09:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 19:09:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 19:09:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 19:09:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 19:09:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 19:09:14 [scrapy.core.engine] INFO: Spider opened
2018-08-02 19:09:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 19:09:15 [scrapy.extensions.logstats] INFO: Crawled 98 pages (at 50 pages/min), scraped 98 items (at 50 items/min)
2018-08-02 19:09:28 [scrapy.extensions.logstats] INFO: Crawled 1725 pages (at 48 pages/min), scraped 1722 items (at 48 items/min)
2018-08-02 19:10:14 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 49 pages/min), scraped 49 items (at 49 items/min)
2018-08-02 19:10:15 [scrapy.extensions.logstats] INFO: Crawled 149 pages (at 51 pages/min), scraped 149 items (at 51 items/min)
2018-08-02 19:10:28 [scrapy.extensions.logstats] INFO: Crawled 1776 pages (at 51 pages/min), scraped 1773 items (at 51 items/min)
2018-08-02 19:10:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 19:10:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 19:10:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 19:10:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 19:10:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 19:10:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 19:10:36 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 19:10:36 [scrapy.core.engine] INFO: Spider opened
2018-08-02 19:10:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 19:11:14 [scrapy.extensions.logstats] INFO: Crawled 101 pages (at 52 pages/min), scraped 101 items (at 52 items/min)
2018-08-02 19:11:15 [scrapy.extensions.logstats] INFO: Crawled 200 pages (at 51 pages/min), scraped 200 items (at 51 items/min)
2018-08-02 19:11:28 [scrapy.extensions.logstats] INFO: Crawled 1827 pages (at 51 pages/min), scraped 1824 items (at 51 items/min)
2018-08-02 19:11:36 [scrapy.extensions.logstats] INFO: Crawled 51 pages (at 51 pages/min), scraped 51 items (at 51 items/min)
2018-08-02 19:12:14 [scrapy.extensions.logstats] INFO: Crawled 151 pages (at 50 pages/min), scraped 151 items (at 50 items/min)
2018-08-02 19:12:15 [scrapy.extensions.logstats] INFO: Crawled 250 pages (at 50 pages/min), scraped 250 items (at 50 items/min)
2018-08-02 19:12:28 [scrapy.extensions.logstats] INFO: Crawled 1876 pages (at 49 pages/min), scraped 1873 items (at 49 items/min)
2018-08-02 19:12:36 [scrapy.extensions.logstats] INFO: Crawled 101 pages (at 50 pages/min), scraped 101 items (at 50 items/min)
2018-08-02 19:13:14 [scrapy.extensions.logstats] INFO: Crawled 200 pages (at 49 pages/min), scraped 200 items (at 49 items/min)
2018-08-02 19:13:15 [scrapy.extensions.logstats] INFO: Crawled 300 pages (at 50 pages/min), scraped 300 items (at 50 items/min)
2018-08-02 19:13:28 [scrapy.extensions.logstats] INFO: Crawled 1923 pages (at 47 pages/min), scraped 1920 items (at 47 items/min)
2018-08-02 19:13:36 [scrapy.extensions.logstats] INFO: Crawled 153 pages (at 52 pages/min), scraped 153 items (at 52 items/min)
2018-08-02 19:14:14 [scrapy.extensions.logstats] INFO: Crawled 247 pages (at 47 pages/min), scraped 246 items (at 46 items/min)
2018-08-02 19:14:15 [scrapy.extensions.logstats] INFO: Crawled 348 pages (at 48 pages/min), scraped 348 items (at 48 items/min)
2018-08-02 19:14:28 [scrapy.extensions.logstats] INFO: Crawled 1972 pages (at 49 pages/min), scraped 1969 items (at 49 items/min)
2018-08-02 19:14:36 [scrapy.extensions.logstats] INFO: Crawled 204 pages (at 51 pages/min), scraped 204 items (at 51 items/min)
2018-08-02 19:15:14 [scrapy.extensions.logstats] INFO: Crawled 295 pages (at 48 pages/min), scraped 295 items (at 49 items/min)
2018-08-02 19:15:15 [scrapy.extensions.logstats] INFO: Crawled 399 pages (at 51 pages/min), scraped 399 items (at 51 items/min)
2018-08-02 19:15:28 [scrapy.extensions.logstats] INFO: Crawled 2020 pages (at 48 pages/min), scraped 2017 items (at 48 items/min)
2018-08-02 19:15:36 [scrapy.extensions.logstats] INFO: Crawled 253 pages (at 49 pages/min), scraped 253 items (at 49 items/min)
2018-08-02 19:16:14 [scrapy.extensions.logstats] INFO: Crawled 342 pages (at 47 pages/min), scraped 342 items (at 47 items/min)
2018-08-02 19:16:15 [scrapy.extensions.logstats] INFO: Crawled 447 pages (at 48 pages/min), scraped 447 items (at 48 items/min)
2018-08-02 19:16:28 [scrapy.extensions.logstats] INFO: Crawled 2069 pages (at 49 pages/min), scraped 2066 items (at 49 items/min)
2018-08-02 19:16:36 [scrapy.extensions.logstats] INFO: Crawled 303 pages (at 50 pages/min), scraped 303 items (at 50 items/min)
2018-08-02 19:17:14 [scrapy.extensions.logstats] INFO: Crawled 391 pages (at 49 pages/min), scraped 391 items (at 49 items/min)
2018-08-02 19:17:15 [scrapy.extensions.logstats] INFO: Crawled 496 pages (at 49 pages/min), scraped 496 items (at 49 items/min)
2018-08-02 19:17:28 [scrapy.extensions.logstats] INFO: Crawled 2119 pages (at 50 pages/min), scraped 2116 items (at 50 items/min)
2018-08-02 19:17:36 [scrapy.extensions.logstats] INFO: Crawled 353 pages (at 50 pages/min), scraped 353 items (at 50 items/min)
2018-08-02 19:18:14 [scrapy.extensions.logstats] INFO: Crawled 439 pages (at 48 pages/min), scraped 439 items (at 48 items/min)
2018-08-02 19:18:15 [scrapy.extensions.logstats] INFO: Crawled 545 pages (at 49 pages/min), scraped 545 items (at 49 items/min)
2018-08-02 19:18:28 [scrapy.extensions.logstats] INFO: Crawled 2168 pages (at 49 pages/min), scraped 2165 items (at 49 items/min)
2018-08-02 19:18:36 [scrapy.extensions.logstats] INFO: Crawled 392 pages (at 39 pages/min), scraped 392 items (at 39 items/min)
2018-08-02 19:18:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/error/500.do> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    贷款金额 = dataArray[2]
IndexError: list index out of range
2018-08-02 19:19:14 [scrapy.extensions.logstats] INFO: Crawled 490 pages (at 51 pages/min), scraped 490 items (at 51 items/min)
2018-08-02 19:19:15 [scrapy.extensions.logstats] INFO: Crawled 595 pages (at 50 pages/min), scraped 595 items (at 50 items/min)
2018-08-02 19:19:28 [scrapy.extensions.logstats] INFO: Crawled 2218 pages (at 50 pages/min), scraped 2215 items (at 50 items/min)
2018-08-02 19:19:36 [scrapy.extensions.logstats] INFO: Crawled 442 pages (at 50 pages/min), scraped 441 items (at 49 items/min)
2018-08-02 19:20:14 [scrapy.extensions.logstats] INFO: Crawled 540 pages (at 50 pages/min), scraped 539 items (at 49 items/min)
2018-08-02 19:20:15 [scrapy.extensions.logstats] INFO: Crawled 643 pages (at 48 pages/min), scraped 643 items (at 48 items/min)
2018-08-02 19:20:28 [scrapy.extensions.logstats] INFO: Crawled 2267 pages (at 49 pages/min), scraped 2264 items (at 49 items/min)
2018-08-02 19:20:36 [scrapy.extensions.logstats] INFO: Crawled 489 pages (at 47 pages/min), scraped 488 items (at 47 items/min)
2018-08-02 19:21:14 [scrapy.extensions.logstats] INFO: Crawled 589 pages (at 49 pages/min), scraped 589 items (at 50 items/min)
2018-08-02 19:21:15 [scrapy.extensions.logstats] INFO: Crawled 692 pages (at 49 pages/min), scraped 692 items (at 49 items/min)
2018-08-02 19:21:28 [scrapy.extensions.logstats] INFO: Crawled 2316 pages (at 49 pages/min), scraped 2313 items (at 49 items/min)
2018-08-02 19:21:36 [scrapy.extensions.logstats] INFO: Crawled 540 pages (at 51 pages/min), scraped 539 items (at 51 items/min)
2018-08-02 19:22:14 [scrapy.extensions.logstats] INFO: Crawled 637 pages (at 48 pages/min), scraped 637 items (at 48 items/min)
2018-08-02 19:22:15 [scrapy.extensions.logstats] INFO: Crawled 739 pages (at 47 pages/min), scraped 739 items (at 47 items/min)
2018-08-02 19:22:28 [scrapy.extensions.logstats] INFO: Crawled 2364 pages (at 48 pages/min), scraped 2361 items (at 48 items/min)
2018-08-02 19:22:36 [scrapy.extensions.logstats] INFO: Crawled 590 pages (at 50 pages/min), scraped 589 items (at 50 items/min)
2018-08-02 19:23:14 [scrapy.extensions.logstats] INFO: Crawled 685 pages (at 48 pages/min), scraped 685 items (at 48 items/min)
2018-08-02 19:23:15 [scrapy.extensions.logstats] INFO: Crawled 787 pages (at 48 pages/min), scraped 787 items (at 48 items/min)
2018-08-02 19:23:28 [scrapy.extensions.logstats] INFO: Crawled 2414 pages (at 50 pages/min), scraped 2411 items (at 50 items/min)
2018-08-02 19:23:36 [scrapy.extensions.logstats] INFO: Crawled 641 pages (at 51 pages/min), scraped 640 items (at 51 items/min)
2018-08-02 19:24:14 [scrapy.extensions.logstats] INFO: Crawled 734 pages (at 49 pages/min), scraped 734 items (at 49 items/min)
2018-08-02 19:24:15 [scrapy.extensions.logstats] INFO: Crawled 836 pages (at 49 pages/min), scraped 836 items (at 49 items/min)
2018-08-02 19:24:28 [scrapy.extensions.logstats] INFO: Crawled 2467 pages (at 53 pages/min), scraped 2464 items (at 53 items/min)
2018-08-02 19:24:36 [scrapy.extensions.logstats] INFO: Crawled 689 pages (at 48 pages/min), scraped 688 items (at 48 items/min)
2018-08-02 19:25:14 [scrapy.extensions.logstats] INFO: Crawled 782 pages (at 48 pages/min), scraped 782 items (at 48 items/min)
2018-08-02 19:25:15 [scrapy.extensions.logstats] INFO: Crawled 887 pages (at 51 pages/min), scraped 887 items (at 51 items/min)
2018-08-02 19:25:28 [scrapy.extensions.logstats] INFO: Crawled 2516 pages (at 49 pages/min), scraped 2512 items (at 48 items/min)
2018-08-02 19:25:36 [scrapy.extensions.logstats] INFO: Crawled 739 pages (at 50 pages/min), scraped 738 items (at 50 items/min)
2018-08-02 19:26:14 [scrapy.extensions.logstats] INFO: Crawled 832 pages (at 50 pages/min), scraped 832 items (at 50 items/min)
2018-08-02 19:26:15 [scrapy.extensions.logstats] INFO: Crawled 935 pages (at 48 pages/min), scraped 935 items (at 48 items/min)
2018-08-02 19:26:28 [scrapy.extensions.logstats] INFO: Crawled 2567 pages (at 51 pages/min), scraped 2564 items (at 52 items/min)
2018-08-02 19:26:36 [scrapy.extensions.logstats] INFO: Crawled 788 pages (at 49 pages/min), scraped 787 items (at 49 items/min)
2018-08-02 19:26:49 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://daikuan.csaimall.com/product-12209.html>: HTTP status code is not handled or not allowed
2018-08-02 19:27:14 [scrapy.extensions.logstats] INFO: Crawled 880 pages (at 48 pages/min), scraped 880 items (at 48 items/min)
2018-08-02 19:27:15 [scrapy.extensions.logstats] INFO: Crawled 985 pages (at 50 pages/min), scraped 985 items (at 50 items/min)
2018-08-02 19:27:28 [scrapy.extensions.logstats] INFO: Crawled 2614 pages (at 47 pages/min), scraped 2611 items (at 47 items/min)
2018-08-02 19:27:36 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://daikuan.csaimall.com/product-1385.html>: HTTP status code is not handled or not allowed
2018-08-02 19:27:36 [scrapy.extensions.logstats] INFO: Crawled 837 pages (at 49 pages/min), scraped 835 items (at 48 items/min)
2018-08-02 19:28:14 [scrapy.extensions.logstats] INFO: Crawled 929 pages (at 49 pages/min), scraped 929 items (at 49 items/min)
2018-08-02 19:28:15 [scrapy.extensions.logstats] INFO: Crawled 1032 pages (at 47 pages/min), scraped 1032 items (at 47 items/min)
2018-08-02 19:28:28 [scrapy.extensions.logstats] INFO: Crawled 2664 pages (at 50 pages/min), scraped 2660 items (at 49 items/min)
2018-08-02 19:28:36 [scrapy.extensions.logstats] INFO: Crawled 886 pages (at 49 pages/min), scraped 884 items (at 49 items/min)
2018-08-02 19:29:14 [scrapy.extensions.logstats] INFO: Crawled 976 pages (at 47 pages/min), scraped 976 items (at 47 items/min)
2018-08-02 19:29:15 [scrapy.extensions.logstats] INFO: Crawled 1082 pages (at 50 pages/min), scraped 1082 items (at 50 items/min)
2018-08-02 19:29:28 [scrapy.extensions.logstats] INFO: Crawled 2713 pages (at 49 pages/min), scraped 2709 items (at 49 items/min)
2018-08-02 19:29:36 [scrapy.extensions.logstats] INFO: Crawled 938 pages (at 52 pages/min), scraped 936 items (at 52 items/min)
2018-08-02 19:30:14 [scrapy.extensions.logstats] INFO: Crawled 1026 pages (at 50 pages/min), scraped 1026 items (at 50 items/min)
2018-08-02 19:30:15 [scrapy.extensions.logstats] INFO: Crawled 1128 pages (at 46 pages/min), scraped 1128 items (at 46 items/min)
2018-08-02 19:30:28 [scrapy.extensions.logstats] INFO: Crawled 2764 pages (at 51 pages/min), scraped 2760 items (at 51 items/min)
2018-08-02 19:30:36 [scrapy.extensions.logstats] INFO: Crawled 986 pages (at 48 pages/min), scraped 984 items (at 48 items/min)
2018-08-02 19:31:14 [scrapy.extensions.logstats] INFO: Crawled 1075 pages (at 49 pages/min), scraped 1075 items (at 49 items/min)
2018-08-02 19:31:15 [scrapy.extensions.logstats] INFO: Crawled 1179 pages (at 51 pages/min), scraped 1179 items (at 51 items/min)
2018-08-02 19:31:28 [scrapy.extensions.logstats] INFO: Crawled 2814 pages (at 50 pages/min), scraped 2810 items (at 50 items/min)
2018-08-02 19:31:36 [scrapy.extensions.logstats] INFO: Crawled 1035 pages (at 49 pages/min), scraped 1033 items (at 49 items/min)
2018-08-02 19:32:14 [scrapy.extensions.logstats] INFO: Crawled 1125 pages (at 50 pages/min), scraped 1125 items (at 50 items/min)
2018-08-02 19:32:15 [scrapy.extensions.logstats] INFO: Crawled 1227 pages (at 48 pages/min), scraped 1227 items (at 48 items/min)
2018-08-02 19:32:28 [scrapy.extensions.logstats] INFO: Crawled 2861 pages (at 47 pages/min), scraped 2857 items (at 47 items/min)
2018-08-02 19:32:36 [scrapy.extensions.logstats] INFO: Crawled 1085 pages (at 50 pages/min), scraped 1083 items (at 50 items/min)
2018-08-02 19:33:14 [scrapy.extensions.logstats] INFO: Crawled 1178 pages (at 53 pages/min), scraped 1177 items (at 52 items/min)
2018-08-02 19:33:15 [scrapy.extensions.logstats] INFO: Crawled 1277 pages (at 50 pages/min), scraped 1277 items (at 50 items/min)
2018-08-02 19:33:28 [scrapy.extensions.logstats] INFO: Crawled 2909 pages (at 48 pages/min), scraped 2905 items (at 48 items/min)
2018-08-02 19:33:36 [scrapy.extensions.logstats] INFO: Crawled 1136 pages (at 51 pages/min), scraped 1134 items (at 51 items/min)
2018-08-02 19:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/error/500.do> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    贷款金额 = dataArray[2]
IndexError: list index out of range
2018-08-02 19:34:14 [scrapy.extensions.logstats] INFO: Crawled 1223 pages (at 45 pages/min), scraped 1222 items (at 45 items/min)
2018-08-02 19:34:15 [scrapy.extensions.logstats] INFO: Crawled 1326 pages (at 49 pages/min), scraped 1326 items (at 49 items/min)
2018-08-02 19:34:28 [scrapy.extensions.logstats] INFO: Crawled 2957 pages (at 48 pages/min), scraped 2953 items (at 48 items/min)
2018-08-02 19:34:36 [scrapy.extensions.logstats] INFO: Crawled 1184 pages (at 48 pages/min), scraped 1182 items (at 48 items/min)
2018-08-02 19:35:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 19:35:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1023403,
 'downloader/request_count': 3001,
 'downloader/request_method_count/GET': 3001,
 'downloader/response_bytes': 222426058,
 'downloader/response_count': 3001,
 'downloader/response_status_count/200': 2985,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/302': 12,
 'downloader/response_status_count/400': 3,
 'dupefilter/filtered': 8943045,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 11, 35, 7, 27000),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/400': 3,
 'item_scraped_count': 2984,
 'log_count/ERROR': 1,
 'log_count/INFO': 70,
 'request_depth_max': 2,
 'response_received_count': 2988,
 'scheduler/dequeued': 3001,
 'scheduler/dequeued/memory': 3001,
 'scheduler/enqueued': 3001,
 'scheduler/enqueued/memory': 3001,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 10, 34, 28, 571000)}
2018-08-02 19:35:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 19:35:14 [scrapy.extensions.logstats] INFO: Crawled 1267 pages (at 44 pages/min), scraped 1266 items (at 44 items/min)
2018-08-02 19:35:15 [scrapy.extensions.logstats] INFO: Crawled 1376 pages (at 50 pages/min), scraped 1376 items (at 50 items/min)
2018-08-02 19:35:22 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://daikuan.csaimall.com/product-11788.html>: HTTP status code is not handled or not allowed
2018-08-02 19:35:36 [scrapy.extensions.logstats] INFO: Crawled 1233 pages (at 49 pages/min), scraped 1230 items (at 48 items/min)
2018-08-02 19:36:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-02 19:36:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-02 19:36:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-02 19:36:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-02 19:36:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-02 19:36:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-02 19:36:03 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-02 19:36:03 [scrapy.core.engine] INFO: Spider opened
2018-08-02 19:36:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-02 19:36:14 [scrapy.extensions.logstats] INFO: Crawled 1270 pages (at 3 pages/min), scraped 1269 items (at 3 items/min)
2018-08-02 19:36:15 [scrapy.extensions.logstats] INFO: Crawled 1424 pages (at 48 pages/min), scraped 1424 items (at 48 items/min)
2018-08-02 19:36:16 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://daikuan.csaimall.com/product-5592.html>: HTTP status code is not handled or not allowed
2018-08-02 19:36:36 [scrapy.extensions.logstats] INFO: Crawled 1281 pages (at 48 pages/min), scraped 1278 items (at 48 items/min)
2018-08-02 19:37:03 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 23 pages/min), scraped 23 items (at 23 items/min)
2018-08-02 19:37:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://daikuan.csaimall.com/error/500.do> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\csaimall_spider.py", line 40, in parse
    贷款金额 = dataArray[2]
IndexError: list index out of range
2018-08-02 19:37:14 [scrapy.extensions.logstats] INFO: Crawled 1303 pages (at 33 pages/min), scraped 1302 items (at 33 items/min)
2018-08-02 19:37:15 [scrapy.extensions.logstats] INFO: Crawled 1472 pages (at 48 pages/min), scraped 1471 items (at 47 items/min)
2018-08-02 19:37:36 [scrapy.extensions.logstats] INFO: Crawled 1331 pages (at 50 pages/min), scraped 1328 items (at 50 items/min)
2018-08-02 19:38:03 [scrapy.extensions.logstats] INFO: Crawled 33 pages (at 10 pages/min), scraped 32 items (at 9 items/min)
2018-08-02 19:38:14 [scrapy.extensions.logstats] INFO: Crawled 1353 pages (at 50 pages/min), scraped 1351 items (at 49 items/min)
2018-08-02 19:38:15 [scrapy.extensions.logstats] INFO: Crawled 1522 pages (at 50 pages/min), scraped 1521 items (at 50 items/min)
2018-08-02 19:38:36 [scrapy.extensions.logstats] INFO: Crawled 1380 pages (at 49 pages/min), scraped 1377 items (at 49 items/min)
2018-08-02 19:39:03 [scrapy.extensions.logstats] INFO: Crawled 35 pages (at 2 pages/min), scraped 34 items (at 2 items/min)
2018-08-02 19:39:14 [scrapy.extensions.logstats] INFO: Crawled 1403 pages (at 50 pages/min), scraped 1402 items (at 51 items/min)
2018-08-02 19:39:15 [scrapy.extensions.logstats] INFO: Crawled 1571 pages (at 49 pages/min), scraped 1570 items (at 49 items/min)
2018-08-02 19:39:36 [scrapy.extensions.logstats] INFO: Crawled 1429 pages (at 49 pages/min), scraped 1426 items (at 49 items/min)
2018-08-02 19:40:03 [scrapy.extensions.logstats] INFO: Crawled 35 pages (at 0 pages/min), scraped 34 items (at 0 items/min)
2018-08-02 19:40:14 [scrapy.extensions.logstats] INFO: Crawled 1411 pages (at 8 pages/min), scraped 1410 items (at 8 items/min)
2018-08-02 19:40:15 [scrapy.extensions.logstats] INFO: Crawled 1620 pages (at 49 pages/min), scraped 1619 items (at 49 items/min)
2018-08-02 19:40:36 [scrapy.extensions.logstats] INFO: Crawled 1479 pages (at 50 pages/min), scraped 1476 items (at 50 items/min)
2018-08-02 19:41:03 [scrapy.extensions.logstats] INFO: Crawled 35 pages (at 0 pages/min), scraped 34 items (at 0 items/min)
2018-08-02 19:41:14 [scrapy.extensions.logstats] INFO: Crawled 1412 pages (at 1 pages/min), scraped 1411 items (at 1 items/min)
2018-08-02 19:41:15 [scrapy.extensions.logstats] INFO: Crawled 1667 pages (at 47 pages/min), scraped 1666 items (at 47 items/min)
2018-08-02 19:41:36 [scrapy.extensions.logstats] INFO: Crawled 1529 pages (at 50 pages/min), scraped 1526 items (at 50 items/min)
2018-08-02 19:42:03 [scrapy.extensions.logstats] INFO: Crawled 35 pages (at 0 pages/min), scraped 34 items (at 0 items/min)
2018-08-02 19:42:14 [scrapy.extensions.logstats] INFO: Crawled 1424 pages (at 12 pages/min), scraped 1423 items (at 12 items/min)
2018-08-02 19:42:15 [scrapy.extensions.logstats] INFO: Crawled 1716 pages (at 49 pages/min), scraped 1714 items (at 48 items/min)
2018-08-02 19:42:36 [scrapy.extensions.logstats] INFO: Crawled 1578 pages (at 49 pages/min), scraped 1575 items (at 49 items/min)
2018-08-02 19:43:03 [scrapy.extensions.logstats] INFO: Crawled 44 pages (at 9 pages/min), scraped 43 items (at 9 items/min)
2018-08-02 19:43:14 [scrapy.extensions.logstats] INFO: Crawled 1451 pages (at 27 pages/min), scraped 1450 items (at 27 items/min)
2018-08-02 19:43:15 [scrapy.extensions.logstats] INFO: Crawled 1765 pages (at 49 pages/min), scraped 1764 items (at 50 items/min)
2018-08-02 19:43:36 [scrapy.extensions.logstats] INFO: Crawled 1629 pages (at 51 pages/min), scraped 1626 items (at 51 items/min)
2018-08-02 19:44:03 [scrapy.extensions.logstats] INFO: Crawled 92 pages (at 48 pages/min), scraped 91 items (at 48 items/min)
2018-08-02 19:44:14 [scrapy.extensions.logstats] INFO: Crawled 1501 pages (at 50 pages/min), scraped 1500 items (at 50 items/min)
2018-08-02 19:44:15 [scrapy.extensions.logstats] INFO: Crawled 1814 pages (at 49 pages/min), scraped 1813 items (at 49 items/min)
2018-08-02 19:44:36 [scrapy.extensions.logstats] INFO: Crawled 1677 pages (at 48 pages/min), scraped 1674 items (at 48 items/min)
2018-08-02 19:45:03 [scrapy.extensions.logstats] INFO: Crawled 142 pages (at 50 pages/min), scraped 141 items (at 50 items/min)
2018-08-02 19:45:14 [scrapy.extensions.logstats] INFO: Crawled 1551 pages (at 50 pages/min), scraped 1549 items (at 49 items/min)
2018-08-02 19:45:15 [scrapy.extensions.logstats] INFO: Crawled 1863 pages (at 49 pages/min), scraped 1862 items (at 49 items/min)
2018-08-02 19:45:36 [scrapy.extensions.logstats] INFO: Crawled 1727 pages (at 50 pages/min), scraped 1724 items (at 50 items/min)
2018-08-02 19:46:03 [scrapy.extensions.logstats] INFO: Crawled 191 pages (at 49 pages/min), scraped 190 items (at 49 items/min)
2018-08-02 19:46:14 [scrapy.extensions.logstats] INFO: Crawled 1601 pages (at 50 pages/min), scraped 1600 items (at 51 items/min)
2018-08-02 19:46:15 [scrapy.extensions.logstats] INFO: Crawled 1910 pages (at 47 pages/min), scraped 1909 items (at 47 items/min)
2018-08-02 19:46:36 [scrapy.extensions.logstats] INFO: Crawled 1775 pages (at 48 pages/min), scraped 1772 items (at 48 items/min)
2018-08-02 19:47:03 [scrapy.extensions.logstats] INFO: Crawled 242 pages (at 51 pages/min), scraped 240 items (at 50 items/min)
2018-08-02 19:47:14 [scrapy.extensions.logstats] INFO: Crawled 1653 pages (at 52 pages/min), scraped 1651 items (at 51 items/min)
2018-08-02 19:47:15 [scrapy.extensions.logstats] INFO: Crawled 1961 pages (at 51 pages/min), scraped 1960 items (at 51 items/min)
2018-08-02 19:47:36 [scrapy.extensions.logstats] INFO: Crawled 1808 pages (at 33 pages/min), scraped 1805 items (at 33 items/min)
2018-08-02 19:48:03 [scrapy.extensions.logstats] INFO: Crawled 285 pages (at 43 pages/min), scraped 284 items (at 44 items/min)
2018-08-02 19:48:14 [scrapy.extensions.logstats] INFO: Crawled 1701 pages (at 48 pages/min), scraped 1700 items (at 49 items/min)
2018-08-02 19:48:15 [scrapy.extensions.logstats] INFO: Crawled 2011 pages (at 50 pages/min), scraped 2010 items (at 50 items/min)
2018-08-02 19:48:36 [scrapy.extensions.logstats] INFO: Crawled 1857 pages (at 49 pages/min), scraped 1853 items (at 48 items/min)
2018-08-02 19:49:03 [scrapy.extensions.logstats] INFO: Crawled 335 pages (at 50 pages/min), scraped 334 items (at 50 items/min)
2018-08-02 19:49:14 [scrapy.extensions.logstats] INFO: Crawled 1753 pages (at 52 pages/min), scraped 1752 items (at 52 items/min)
2018-08-02 19:49:15 [scrapy.extensions.logstats] INFO: Crawled 2058 pages (at 47 pages/min), scraped 2057 items (at 47 items/min)
2018-08-02 19:49:36 [scrapy.extensions.logstats] INFO: Crawled 1909 pages (at 52 pages/min), scraped 1906 items (at 53 items/min)
2018-08-02 19:50:03 [scrapy.extensions.logstats] INFO: Crawled 382 pages (at 47 pages/min), scraped 381 items (at 47 items/min)
2018-08-02 19:50:14 [scrapy.extensions.logstats] INFO: Crawled 1804 pages (at 51 pages/min), scraped 1803 items (at 51 items/min)
2018-08-02 19:50:15 [scrapy.extensions.logstats] INFO: Crawled 2105 pages (at 47 pages/min), scraped 2104 items (at 47 items/min)
2018-08-02 19:50:36 [scrapy.extensions.logstats] INFO: Crawled 1958 pages (at 49 pages/min), scraped 1955 items (at 49 items/min)
2018-08-02 19:51:03 [scrapy.extensions.logstats] INFO: Crawled 426 pages (at 44 pages/min), scraped 425 items (at 44 items/min)
2018-08-02 19:51:14 [scrapy.extensions.logstats] INFO: Crawled 1852 pages (at 48 pages/min), scraped 1851 items (at 48 items/min)
2018-08-02 19:51:15 [scrapy.extensions.logstats] INFO: Crawled 2153 pages (at 48 pages/min), scraped 2151 items (at 47 items/min)
2018-08-02 19:51:36 [scrapy.extensions.logstats] INFO: Crawled 2007 pages (at 49 pages/min), scraped 2004 items (at 49 items/min)
2018-08-02 19:52:03 [scrapy.extensions.logstats] INFO: Crawled 474 pages (at 48 pages/min), scraped 473 items (at 48 items/min)
2018-08-02 19:52:14 [scrapy.extensions.logstats] INFO: Crawled 1900 pages (at 48 pages/min), scraped 1899 items (at 48 items/min)
2018-08-02 19:52:15 [scrapy.extensions.logstats] INFO: Crawled 2202 pages (at 49 pages/min), scraped 2201 items (at 50 items/min)
2018-08-02 19:52:36 [scrapy.extensions.logstats] INFO: Crawled 2058 pages (at 51 pages/min), scraped 2055 items (at 51 items/min)
2018-08-02 19:53:03 [scrapy.extensions.logstats] INFO: Crawled 525 pages (at 51 pages/min), scraped 524 items (at 51 items/min)
2018-08-02 19:53:14 [scrapy.extensions.logstats] INFO: Crawled 1949 pages (at 49 pages/min), scraped 1947 items (at 48 items/min)
2018-08-02 19:53:15 [scrapy.extensions.logstats] INFO: Crawled 2249 pages (at 47 pages/min), scraped 2248 items (at 47 items/min)
2018-08-02 19:53:36 [scrapy.extensions.logstats] INFO: Crawled 2109 pages (at 51 pages/min), scraped 2106 items (at 51 items/min)
2018-08-02 19:54:03 [scrapy.extensions.logstats] INFO: Crawled 575 pages (at 50 pages/min), scraped 574 items (at 50 items/min)
2018-08-02 19:54:14 [scrapy.extensions.logstats] INFO: Crawled 2001 pages (at 52 pages/min), scraped 2000 items (at 53 items/min)
2018-08-02 19:54:15 [scrapy.extensions.logstats] INFO: Crawled 2298 pages (at 49 pages/min), scraped 2296 items (at 48 items/min)
2018-08-02 19:54:36 [scrapy.extensions.logstats] INFO: Crawled 2157 pages (at 48 pages/min), scraped 2154 items (at 48 items/min)
2018-08-02 19:55:03 [scrapy.extensions.logstats] INFO: Crawled 625 pages (at 50 pages/min), scraped 624 items (at 50 items/min)
2018-08-02 19:55:14 [scrapy.extensions.logstats] INFO: Crawled 2050 pages (at 49 pages/min), scraped 2049 items (at 49 items/min)
2018-08-02 19:55:15 [scrapy.extensions.logstats] INFO: Crawled 2346 pages (at 48 pages/min), scraped 2345 items (at 49 items/min)
2018-08-02 19:55:36 [scrapy.extensions.logstats] INFO: Crawled 2208 pages (at 51 pages/min), scraped 2205 items (at 51 items/min)
2018-08-02 19:56:03 [scrapy.extensions.logstats] INFO: Crawled 672 pages (at 47 pages/min), scraped 671 items (at 47 items/min)
2018-08-02 19:56:14 [scrapy.extensions.logstats] INFO: Crawled 2101 pages (at 51 pages/min), scraped 2100 items (at 51 items/min)
2018-08-02 19:56:15 [scrapy.extensions.logstats] INFO: Crawled 2394 pages (at 48 pages/min), scraped 2393 items (at 48 items/min)
2018-08-02 19:56:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 19:56:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 343400,
 'downloader/request_count': 1001,
 'downloader/request_method_count/GET': 1001,
 'downloader/response_bytes': 53272501,
 'downloader/response_count': 1001,
 'downloader/response_status_count/200': 693,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/302': 307,
 'dupefilter/filtered': 689924,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 11, 56, 29, 301000),
 'item_scraped_count': 692,
 'log_count/ERROR': 1,
 'log_count/INFO': 27,
 'request_depth_max': 2,
 'response_received_count': 693,
 'scheduler/dequeued': 1001,
 'scheduler/dequeued/memory': 1001,
 'scheduler/enqueued': 1001,
 'scheduler/enqueued/memory': 1001,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 11, 36, 3, 662000)}
2018-08-02 19:56:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 19:56:36 [scrapy.extensions.logstats] INFO: Crawled 2256 pages (at 48 pages/min), scraped 2253 items (at 48 items/min)
2018-08-02 19:57:14 [scrapy.extensions.logstats] INFO: Crawled 2152 pages (at 51 pages/min), scraped 2151 items (at 51 items/min)
2018-08-02 19:57:15 [scrapy.extensions.logstats] INFO: Crawled 2443 pages (at 49 pages/min), scraped 2442 items (at 49 items/min)
2018-08-02 19:57:36 [scrapy.extensions.logstats] INFO: Crawled 2305 pages (at 49 pages/min), scraped 2302 items (at 49 items/min)
2018-08-02 19:58:14 [scrapy.extensions.logstats] INFO: Crawled 2200 pages (at 48 pages/min), scraped 2199 items (at 48 items/min)
2018-08-02 19:58:15 [scrapy.extensions.logstats] INFO: Crawled 2491 pages (at 48 pages/min), scraped 2490 items (at 48 items/min)
2018-08-02 19:58:36 [scrapy.extensions.logstats] INFO: Crawled 2305 pages (at 0 pages/min), scraped 2302 items (at 0 items/min)
2018-08-02 19:59:14 [scrapy.extensions.logstats] INFO: Crawled 2251 pages (at 51 pages/min), scraped 2250 items (at 51 items/min)
2018-08-02 19:59:15 [scrapy.extensions.logstats] INFO: Crawled 2540 pages (at 49 pages/min), scraped 2539 items (at 49 items/min)
2018-08-02 19:59:36 [scrapy.extensions.logstats] INFO: Crawled 2305 pages (at 0 pages/min), scraped 2302 items (at 0 items/min)
2018-08-02 20:00:14 [scrapy.extensions.logstats] INFO: Crawled 2302 pages (at 51 pages/min), scraped 2301 items (at 51 items/min)
2018-08-02 20:00:15 [scrapy.extensions.logstats] INFO: Crawled 2590 pages (at 50 pages/min), scraped 2589 items (at 50 items/min)
2018-08-02 20:00:36 [scrapy.extensions.logstats] INFO: Crawled 2346 pages (at 41 pages/min), scraped 2343 items (at 41 items/min)
2018-08-02 20:01:14 [scrapy.extensions.logstats] INFO: Crawled 2351 pages (at 49 pages/min), scraped 2350 items (at 49 items/min)
2018-08-02 20:01:15 [scrapy.extensions.logstats] INFO: Crawled 2637 pages (at 47 pages/min), scraped 2636 items (at 47 items/min)
2018-08-02 20:01:36 [scrapy.extensions.logstats] INFO: Crawled 2395 pages (at 49 pages/min), scraped 2392 items (at 49 items/min)
2018-08-02 20:02:14 [scrapy.extensions.logstats] INFO: Crawled 2399 pages (at 48 pages/min), scraped 2398 items (at 48 items/min)
2018-08-02 20:02:15 [scrapy.extensions.logstats] INFO: Crawled 2687 pages (at 50 pages/min), scraped 2686 items (at 50 items/min)
2018-08-02 20:02:36 [scrapy.extensions.logstats] INFO: Crawled 2444 pages (at 49 pages/min), scraped 2441 items (at 49 items/min)
2018-08-02 20:03:14 [scrapy.extensions.logstats] INFO: Crawled 2450 pages (at 51 pages/min), scraped 2448 items (at 50 items/min)
2018-08-02 20:03:15 [scrapy.extensions.logstats] INFO: Crawled 2737 pages (at 50 pages/min), scraped 2736 items (at 50 items/min)
2018-08-02 20:03:24 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <400 https://daikuan.csaimall.com/product-10392.html>: HTTP status code is not handled or not allowed
2018-08-02 20:03:36 [scrapy.extensions.logstats] INFO: Crawled 2492 pages (at 48 pages/min), scraped 2488 items (at 47 items/min)
2018-08-02 20:04:14 [scrapy.extensions.logstats] INFO: Crawled 2497 pages (at 47 pages/min), scraped 2496 items (at 48 items/min)
2018-08-02 20:04:15 [scrapy.extensions.logstats] INFO: Crawled 2785 pages (at 48 pages/min), scraped 2784 items (at 48 items/min)
2018-08-02 20:04:36 [scrapy.extensions.logstats] INFO: Crawled 2540 pages (at 48 pages/min), scraped 2536 items (at 48 items/min)
2018-08-02 20:05:14 [scrapy.extensions.logstats] INFO: Crawled 2544 pages (at 47 pages/min), scraped 2543 items (at 47 items/min)
2018-08-02 20:05:15 [scrapy.extensions.logstats] INFO: Crawled 2835 pages (at 50 pages/min), scraped 2834 items (at 50 items/min)
2018-08-02 20:05:36 [scrapy.extensions.logstats] INFO: Crawled 2589 pages (at 49 pages/min), scraped 2585 items (at 49 items/min)
2018-08-02 20:06:14 [scrapy.extensions.logstats] INFO: Crawled 2594 pages (at 50 pages/min), scraped 2593 items (at 50 items/min)
2018-08-02 20:06:15 [scrapy.extensions.logstats] INFO: Crawled 2885 pages (at 50 pages/min), scraped 2884 items (at 50 items/min)
2018-08-02 20:06:36 [scrapy.extensions.logstats] INFO: Crawled 2638 pages (at 49 pages/min), scraped 2634 items (at 49 items/min)
2018-08-02 20:07:14 [scrapy.extensions.logstats] INFO: Crawled 2643 pages (at 49 pages/min), scraped 2642 items (at 49 items/min)
2018-08-02 20:07:15 [scrapy.extensions.logstats] INFO: Crawled 2935 pages (at 50 pages/min), scraped 2934 items (at 50 items/min)
2018-08-02 20:07:36 [scrapy.extensions.logstats] INFO: Crawled 2687 pages (at 49 pages/min), scraped 2683 items (at 49 items/min)
2018-08-02 20:08:14 [scrapy.extensions.logstats] INFO: Crawled 2693 pages (at 50 pages/min), scraped 2691 items (at 49 items/min)
2018-08-02 20:08:15 [scrapy.extensions.logstats] INFO: Crawled 2986 pages (at 51 pages/min), scraped 2985 items (at 51 items/min)
2018-08-02 20:08:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 20:08:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1022637,
 'downloader/request_count': 2999,
 'downloader/request_method_count/GET': 2999,
 'downloader/response_bytes': 220593534,
 'downloader/response_count': 2999,
 'downloader/response_status_count/200': 2998,
 'downloader/response_status_count/400': 1,
 'dupefilter/filtered': 8985006,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 12, 8, 31, 610000),
 'httperror/response_ignored_count': 1,
 'httperror/response_ignored_status_count/400': 1,
 'item_scraped_count': 2998,
 'log_count/INFO': 69,
 'request_depth_max': 2,
 'response_received_count': 2999,
 'scheduler/dequeued': 2999,
 'scheduler/dequeued/memory': 2999,
 'scheduler/enqueued': 2999,
 'scheduler/enqueued/memory': 2999,
 'start_time': datetime.datetime(2018, 8, 2, 11, 7, 15, 892000)}
2018-08-02 20:08:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 20:08:36 [scrapy.extensions.logstats] INFO: Crawled 2735 pages (at 48 pages/min), scraped 2731 items (at 48 items/min)
2018-08-02 20:09:14 [scrapy.extensions.logstats] INFO: Crawled 2742 pages (at 49 pages/min), scraped 2740 items (at 49 items/min)
2018-08-02 20:09:36 [scrapy.extensions.logstats] INFO: Crawled 2783 pages (at 48 pages/min), scraped 2779 items (at 48 items/min)
2018-08-02 20:10:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 20:10:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1023403,
 'downloader/request_count': 3001,
 'downloader/request_method_count/GET': 3001,
 'downloader/response_bytes': 222654181,
 'downloader/response_count': 3001,
 'downloader/response_status_count/200': 2787,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/302': 213,
 'dupefilter/filtered': 8349642,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 12, 10, 10, 806000),
 'item_scraped_count': 2786,
 'log_count/ERROR': 1,
 'log_count/INFO': 67,
 'request_depth_max': 2,
 'response_received_count': 2787,
 'scheduler/dequeued': 3001,
 'scheduler/dequeued/memory': 3001,
 'scheduler/enqueued': 3001,
 'scheduler/enqueued/memory': 3001,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 11, 9, 14, 492000)}
2018-08-02 20:10:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-02 20:10:36 [scrapy.extensions.logstats] INFO: Crawled 2831 pages (at 48 pages/min), scraped 2827 items (at 48 items/min)
2018-08-02 20:11:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-02 20:11:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1029400,
 'downloader/request_count': 3001,
 'downloader/request_method_count/GET': 3001,
 'downloader/response_bytes': 220358129,
 'downloader/response_count': 3001,
 'downloader/response_status_count/200': 2852,
 'downloader/response_status_count/301': 1,
 'downloader/response_status_count/302': 145,
 'downloader/response_status_count/400': 3,
 'dupefilter/filtered': 8544444,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 2, 12, 11, 8, 3000),
 'httperror/response_ignored_count': 3,
 'httperror/response_ignored_status_count/400': 3,
 'item_scraped_count': 2851,
 'log_count/ERROR': 1,
 'log_count/INFO': 70,
 'request_depth_max': 2,
 'response_received_count': 2855,
 'scheduler/dequeued': 3001,
 'scheduler/dequeued/memory': 3001,
 'scheduler/enqueued': 3001,
 'scheduler/enqueued/memory': 3001,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 2, 11, 10, 36, 238000)}
2018-08-02 20:11:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 10:59:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 10:59:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 10:59:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 10:59:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 10:59:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 10:59:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 10:59:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 10:59:34 [scrapy.core.engine] INFO: Spider opened
2018-08-03 10:59:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 10:59:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 10:59:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398990,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 2, 59, 34, 894000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 2, 59, 34, 705000)}
2018-08-03 10:59:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:02:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:02:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:02:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:02:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:02:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:02:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:02:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:02:12 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:02:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:02:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:02:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398994,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 2, 12, 443000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 2, 12, 235000)}
2018-08-03 11:02:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:02:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:02:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:02:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:02:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:02:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:02:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:02:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:02:38 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:02:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:02:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:02:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398994,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 2, 38, 325000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 2, 38, 97000)}
2018-08-03 11:02:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:08:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:08:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:08:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:08:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:08:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:08:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:08:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:08:52 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:08:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:08:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:08:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398996,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 8, 52, 519000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 8, 52, 78000)}
2018-08-03 11:08:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:11:46 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:11:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:11:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:11:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:11:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:11:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:11:46 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:11:46 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:11:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:11:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:11:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398983,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 11, 46, 956000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 11, 46, 610000)}
2018-08-03 11:11:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:12:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:12:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:12:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:12:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:12:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:12:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:12:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:12:06 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:12:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:12:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:12:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398983,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 12, 6, 551000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 12, 6, 207000)}
2018-08-03 11:12:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:17:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:17:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:17:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:17:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:17:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:17:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:17:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:17:28 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:17:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:17:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:17:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398983,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 17, 28, 725000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 17, 28, 376000)}
2018-08-03 11:17:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:20:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:20:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:20:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:20:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:20:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:20:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:20:58 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:20:58 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:20:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:20:59 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    s2=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:20:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:20:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398983,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 20, 59, 272000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 20, 58, 834000)}
2018-08-03 11:20:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:21:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:21:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:21:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:21:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:21:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:21:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:21:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:21:16 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:21:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:21:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    s2=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:21:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:21:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398983,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 21, 17, 379000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 21, 16, 921000)}
2018-08-03 11:21:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:21:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:21:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:21:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:21:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:21:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:21:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:21:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:21:42 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:21:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:21:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:21:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398983,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 21, 43, 244000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 21, 42, 879000)}
2018-08-03 11:21:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:22:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:22:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:22:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:22:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:22:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:22:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:22:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:22:12 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:22:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:22:13 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    s2=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:22:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:22:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398983,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 22, 13, 236000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 22, 12, 779000)}
2018-08-03 11:22:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:23:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:23:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:23:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:23:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:23:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:23:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:23:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:23:01 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:23:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:23:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    s2=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:23:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:23:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398983,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 23, 1, 885000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 23, 1, 457000)}
2018-08-03 11:23:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:23:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:23:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:23:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:23:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:23:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:23:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:23:26 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:23:26 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:23:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:23:26 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    s2=response.xpath('/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()').extract()[0]
IndexError: list index out of range
2018-08-03 11:23:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:23:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 23, 26, 548000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 23, 26, 191000)}
2018-08-03 11:23:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:23:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:23:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:23:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:23:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:23:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:23:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:23:36 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:23:36 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:23:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:23:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    s2=response.xpath('/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()').extract()[0]
IndexError: list index out of range
2018-08-03 11:23:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:23:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 23, 37, 124000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 23, 36, 786000)}
2018-08-03 11:23:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:24:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:24:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:24:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:24:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:24:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:24:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:24:15 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:24:15 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:24:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:24:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:24:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 24, 15, 266000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 24, 15, 28000)}
2018-08-03 11:24:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:24:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:24:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:24:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:24:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:24:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:24:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:24:31 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:24:31 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:24:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:24:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:24:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 24, 32, 241000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 24, 31, 991000)}
2018-08-03 11:24:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:25:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:25:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:25:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:25:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:25:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:25:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:25:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:25:17 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:25:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:25:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    s2=response.xpath('/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()').extract()[0]
IndexError: list index out of range
2018-08-03 11:25:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:25:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 25, 17, 709000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 25, 17, 367000)}
2018-08-03 11:25:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:25:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:25:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:25:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:25:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:25:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:25:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:25:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:25:33 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:25:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:25:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    s2 = response.xpath('/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()').extract()[0]
IndexError: list index out of range
2018-08-03 11:25:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:25:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 25, 33, 423000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 25, 33, 70000)}
2018-08-03 11:25:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:25:46 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:25:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:25:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:25:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:25:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:25:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:25:46 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:25:46 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:25:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:25:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    print(response.xpath('/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()').extract()[0])
IndexError: list index out of range
2018-08-03 11:25:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:25:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 25, 46, 921000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 25, 46, 584000)}
2018-08-03 11:25:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:25:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:25:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:25:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:25:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:25:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:25:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:25:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:25:55 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:25:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:25:55 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    print(response.xpath('/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()').extract()[0])
IndexError: list index out of range
2018-08-03 11:25:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:25:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398987,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 25, 55, 473000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 25, 55, 22000)}
2018-08-03 11:25:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:26:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:26:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:26:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:26:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:26:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:26:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:26:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:26:21 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:26:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:26:21 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 26, in parse
    print(response.xpath('/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[3]/a/text()').extract()[0])
IndexError: list index out of range
2018-08-03 11:26:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:26:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 26, 21, 664000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 26, 21, 316000)}
2018-08-03 11:26:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:26:45 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:26:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:26:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:26:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:26:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:26:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:26:45 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:26:45 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:26:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:26:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:26:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 26, 46, 49000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 26, 45, 808000)}
2018-08-03 11:26:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:27:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:27:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:27:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:27:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:27:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:27:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:27:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:27:11 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:27:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:27:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:27:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 27, 11, 442000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 27, 11, 141000)}
2018-08-03 11:27:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:27:43 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:27:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:27:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:27:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:27:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:27:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:27:43 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:27:43 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:27:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:27:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:27:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398987,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 27, 43, 890000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 27, 43, 605000)}
2018-08-03 11:27:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:29:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:29:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:29:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:29:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:29:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:29:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:29:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:29:56 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:29:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:29:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 27, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:29:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:29:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 29, 57, 280000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 29, 56, 929000)}
2018-08-03 11:29:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:30:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:30:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:30:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:30:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:30:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:30:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:30:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:30:40 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:30:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:30:40 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 28, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:30:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:30:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 30, 40, 575000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 30, 40, 232000)}
2018-08-03 11:30:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:31:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:31:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:31:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:31:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:31:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:31:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:31:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:31:14 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:31:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:31:15 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 28, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:31:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:31:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 31, 15, 170000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 31, 14, 818000)}
2018-08-03 11:31:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:31:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:31:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:31:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:31:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:31:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:31:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:31:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:31:34 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:31:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:31:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 28, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:31:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:31:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 31, 34, 576000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 31, 34, 243000)}
2018-08-03 11:31:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:32:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:32:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:32:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:32:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:32:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:32:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:32:04 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:32:04 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:32:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:32:04 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 28, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:32:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:32:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 32, 4, 733000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 32, 4, 361000)}
2018-08-03 11:32:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:32:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:32:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:32:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:32:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:32:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:32:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:32:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:32:22 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:32:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:32:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 29, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:32:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:32:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 32, 23, 159000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 32, 22, 796000)}
2018-08-03 11:32:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:32:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:32:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:32:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:32:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:32:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:32:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:32:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:32:38 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:32:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:32:38 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 29, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:32:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:32:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 32, 38, 779000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 32, 38, 427000)}
2018-08-03 11:32:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:33:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:33:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:33:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:33:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:33:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:33:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:33:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:33:14 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:33:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:33:14 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 29, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:33:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:33:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 33, 14, 456000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 33, 14, 105000)}
2018-08-03 11:33:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:33:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:33:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:33:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:33:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:33:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:33:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:33:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:33:37 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:33:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:33:37 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 29, in parse
    s3=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[4]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:33:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:33:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 33, 37, 728000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 33, 37, 387000)}
2018-08-03 11:33:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:34:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:34:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:34:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:34:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:34:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:34:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:34:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:34:01 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:34:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:34:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 31, in parse
    s4=response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr[1]/td[5]/a/text()").extract()[0]
IndexError: list index out of range
2018-08-03 11:34:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:34:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 34, 1, 774000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 34, 1, 417000)}
2018-08-03 11:34:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:34:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:34:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:34:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:34:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:34:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:34:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:34:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:34:33 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:34:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:34:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:34:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398986,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 34, 34, 103000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 34, 33, 834000)}
2018-08-03 11:34:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:36:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:36:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:36:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:36:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:36:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:36:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:36:02 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:36:02 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:36:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:36:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:36:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 398997,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 36, 2, 814000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 36, 2, 580000)}
2018-08-03 11:36:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:37:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:37:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:37:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:37:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:37:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:37:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:37:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:37:52 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:37:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:37:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:37:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397625,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 37, 52, 897000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 37, 52, 610000)}
2018-08-03 11:37:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:41:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:41:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:41:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:41:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:41:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:41:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:41:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:41:30 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:41:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:41:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 23, in parse
    s1 = response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr["+i+"]/td[2]/a/text()").extract()[0]
TypeError: must be str, not int
2018-08-03 11:41:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:41:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397640,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 41, 31, 239000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 41, 30, 758000)}
2018-08-03 11:41:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:42:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:42:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:42:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:42:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:42:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:42:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:42:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:42:22 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:42:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:42:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 25, in parse
    s3 = response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr["+i+"]/td[4]/text()").extract()[0]
TypeError: must be str, not int
2018-08-03 11:42:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:42:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397626,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 42, 23, 464000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 42, 22, 554000)}
2018-08-03 11:42:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:43:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:43:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:43:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:43:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:43:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:43:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:43:05 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:43:05 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:43:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:43:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 24, in parse
    s2 = response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr["+i+"]/td[3]/text()").extract()[0]
TypeError: must be str, not int
2018-08-03 11:43:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:43:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397626,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 43, 5, 432000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 43, 5, 78000)}
2018-08-03 11:43:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:43:29 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:43:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:43:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:43:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:43:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:43:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:43:29 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:43:29 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:43:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:43:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:43:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397626,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 43, 29, 990000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 43, 29, 714000)}
2018-08-03 11:43:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:43:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:43:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:43:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:43:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:43:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:43:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:43:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:43:40 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:43:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:43:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:43:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397626,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 43, 40, 636000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 43, 40, 370000)}
2018-08-03 11:43:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:44:09 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:44:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:44:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:44:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:44:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:44:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:44:09 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:44:09 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:44:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:44:09 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.dailuopan.com/data> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\dailuopan_spider.py", line 27, in parse
    s2 = response.xpath("/html/body/div[2]/div[2]/div/div[3]/div/table/tbody/tr["+i+"]/td[3]/text()").extract()[0]
TypeError: must be str, not int
2018-08-03 11:44:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:44:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397626,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 44, 10, 73000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 44, 9, 701000)}
2018-08-03 11:44:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:44:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:44:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:44:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:44:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:44:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:44:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:44:23 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:44:23 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:44:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:44:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:44:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397626,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 44, 23, 888000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 44, 23, 587000)}
2018-08-03 11:44:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 11:46:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 11:46:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 11:46:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 11:46:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 11:46:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 11:46:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 11:46:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 11:46:17 [scrapy.core.engine] INFO: Spider opened
2018-08-03 11:46:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 11:46:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 11:46:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 303,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 397626,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 3, 46, 17, 439000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 3, 46, 17, 24000)}
2018-08-03 11:46:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:44:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:44:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:44:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:44:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:44:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:44:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:44:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:44:30 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:44:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:44:31 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.fanlimofang.com/activity/firstover/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\fanlimofang_spider.py", line 17, in parse
    s1 =  response.xpath("/html/body/div[6]/ul/li[1]/a/div[2]/b/text()").extract()[0]
IndexError: list index out of range
2018-08-03 15:44:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:44:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26786,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 44, 31, 193000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 44, 30, 596000)}
2018-08-03 15:44:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:44:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:44:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:44:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:44:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:44:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:44:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:44:58 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:44:58 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:44:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:44:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:44:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26786,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 44, 59, 222000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 44, 58, 870000)}
2018-08-03 15:44:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:45:09 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:45:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:45:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:45:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:45:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:45:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:45:09 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:45:09 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:45:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:45:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:45:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26790,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 45, 11, 289000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 45, 9, 933000)}
2018-08-03 15:45:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:45:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:45:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:45:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:45:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:45:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:45:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:45:43 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:45:43 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:45:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:45:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:45:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 45, 43, 605000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 45, 43, 175000)}
2018-08-03 15:45:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:46:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:46:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:46:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:46:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:46:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:46:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:46:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:46:12 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:46:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:46:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:46:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 46, 12, 964000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 46, 12, 533000)}
2018-08-03 15:46:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:46:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:46:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:46:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:46:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:46:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:46:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:46:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:46:21 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:46:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:46:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:46:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 46, 22, 604000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 46, 21, 673000)}
2018-08-03 15:46:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:46:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:46:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:46:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:46:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:46:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:46:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:46:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:46:34 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:46:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:46:34 [scrapy.core.scraper] ERROR: Spider error processing <GET http://www.fanlimofang.com/activity/firstover/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\fanlimofang_spider.py", line 17, in parse
    s1 =  response.xpath("/html/body/div[6]/ul/li[2]/a/div[2]/b/")
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/div[6]/ul/li[2]/a/div[2]/b/
2018-08-03 15:46:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:46:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 46, 35, 21000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 46, 34, 613000)}
2018-08-03 15:46:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:46:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:46:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:46:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:46:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:46:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:46:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:46:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:46:57 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:46:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:46:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:46:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 46, 57, 565000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 46, 57, 93000)}
2018-08-03 15:46:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:47:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:47:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:47:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:47:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:47:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:47:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:47:05 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:47:05 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:47:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:47:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:47:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 47, 5, 497000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 47, 5, 186000)}
2018-08-03 15:47:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:47:48 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:47:48 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:47:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:47:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:47:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:47:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:47:48 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:47:48 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:47:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:47:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:47:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 47, 48, 962000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 47, 48, 663000)}
2018-08-03 15:47:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:47:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:47:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:47:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:47:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:47:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:47:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:47:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:47:54 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:47:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:47:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:47:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 47, 54, 829000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 47, 54, 531000)}
2018-08-03 15:47:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:48:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:48:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:48:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:48:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:48:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:48:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:48:31 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:48:31 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:48:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:48:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:48:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26787,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 48, 32, 69000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 48, 31, 588000)}
2018-08-03 15:48:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:50:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:50:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:50:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:50:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:50:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:50:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:50:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:50:52 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:50:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:50:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:50:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26787,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 50, 52, 644000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 50, 52, 127000)}
2018-08-03 15:50:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:51:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:51:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:51:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:51:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:51:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:51:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:51:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:51:01 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:51:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:51:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:51:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 51, 1, 454000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 51, 1, 18000)}
2018-08-03 15:51:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-03 15:51:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-03 15:51:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-03 15:51:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-03 15:51:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-03 15:51:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-03 15:51:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-03 15:51:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-03 15:51:27 [scrapy.core.engine] INFO: Spider opened
2018-08-03 15:51:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-03 15:51:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-03 15:51:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 320,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 26788,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 3, 7, 51, 28, 215000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 3, 7, 51, 27, 781000)}
2018-08-03 15:51:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:16:24 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:16:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:16:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:16:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:16:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:16:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:16:25 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:16:25 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:16:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:16:25 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[3]/div[1]/div[1]/div/div[1]/h1/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:16:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:16:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5143,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 16, 25, 362800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 16, 25, 82800)}
2018-08-06 09:16:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:18:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:18:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:18:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:18:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:18:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:18:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:18:47 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:18:47 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:18:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:18:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/35.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/33.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/32.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/31.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/30.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:55 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/29.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/28.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/27.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/26.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/34.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:18:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/25.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/24.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/23.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/22.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/21.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/20.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/320.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/319.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/318.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/317.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/316.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/315.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/314.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/313.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/312.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/310.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/311.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/309.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/307.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/308.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/306.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/305.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/304.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/303.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/302.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/301.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/300.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/299.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/298.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/297.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/296.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/295.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:19:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/294.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:22:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:22:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:22:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:22:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:22:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:22:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:22:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:22:57 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:22:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:22:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/21.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:22:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/20.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:23:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/19.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:23:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/18.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:23:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/17.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:23:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/16.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:23:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/15.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:23:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/14.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:23:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.csai.cn/kouzi/13.html> (referer: http://daikuan.51kanong.com/daikuan/lists/p/1)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 25, in parse
    appName = response.xpath("/html/body/div[1]/div[3]/table/tbody[2]/tr[1]/td[1]/span/text()").extract()[0]
IndexError: list index out of range
2018-08-06 09:23:19 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:23:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:23:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:23:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:23:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:23:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:23:19 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:23:19 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:23:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:23:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:23:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5144,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 23, 19, 519800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 23, 19, 259800)}
2018-08-06 09:23:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:29:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:29:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:29:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:29:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:29:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:29:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:29:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:29:14 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:29:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:29:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:29:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5146,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 29, 14, 340800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 29, 14, 70800)}
2018-08-06 09:29:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:29:50 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:29:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:29:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:29:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:29:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:29:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:29:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:29:50 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:29:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:29:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:29:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5145,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 29, 50, 913800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 29, 50, 663800)}
2018-08-06 09:29:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:31:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:31:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:31:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:31:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:31:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:31:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:31:36 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:31:36 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:31:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:31:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:31:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5144,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 31, 36, 534800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 31, 36, 304800)}
2018-08-06 09:31:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:32:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:32:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:32:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:32:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:32:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:32:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:32:31 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:32:31 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:32:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:32:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:32:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5145,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 32, 31, 555800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 32, 31, 295800)}
2018-08-06 09:32:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:32:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:32:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:32:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:32:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:32:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:32:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:32:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:32:44 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:32:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:32:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:32:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5142,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 32, 45, 65800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 32, 44, 805800)}
2018-08-06 09:32:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:33:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:33:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:33:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:33:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:33:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:33:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:33:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:33:01 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:33:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:33:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:33:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5144,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 33, 2, 195800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 33, 1, 935800)}
2018-08-06 09:33:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:40:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:40:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:40:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:40:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:40:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:40:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:40:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:40:56 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:40:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:40:56 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 24, in parse
    nae=info.xpath('./td[1]/span/text()').extract()[0]
IndexError: list index out of range
2018-08-06 09:40:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:40:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5144,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 40, 56, 670800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 40, 56, 440800)}
2018-08-06 09:40:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:41:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:41:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:41:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:41:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:41:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:41:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:41:25 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:41:25 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:41:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:41:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:41:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5147,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 41, 25, 750800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 41, 25, 440800)}
2018-08-06 09:41:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:41:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:41:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:41:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:41:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:41:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:41:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:41:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:41:33 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:41:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:41:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:41:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5143,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 41, 33, 790800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 41, 33, 530800)}
2018-08-06 09:41:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:41:45 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:41:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:41:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:41:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:41:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:41:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:41:46 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:41:46 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:41:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:41:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:41:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5144,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 41, 46, 350800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 41, 46, 90800)}
2018-08-06 09:41:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:44:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:44:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:44:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:44:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:44:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:44:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:44:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:44:16 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:44:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:44:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:44:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5145,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 44, 16, 811800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 44, 16, 551800)}
2018-08-06 09:44:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:44:59 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:44:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:44:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:44:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:44:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:44:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:44:59 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:44:59 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:44:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:44:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:44:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5143,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 44, 59, 442800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 44, 59, 172800)}
2018-08-06 09:44:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:46:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:46:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:46:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:46:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:46:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:46:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:46:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:46:20 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:46:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:46:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:46:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5140,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 46, 20, 474800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 46, 20, 194800)}
2018-08-06 09:46:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:55:33 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:55:33 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:55:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:55:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:55:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:55:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:55:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:55:33 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:55:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:55:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 09:55:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:55:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5125,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 55, 33, 738800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 55, 33, 468800)}
2018-08-06 09:55:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:56:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:56:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:56:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:56:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:56:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:56:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:56:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:56:33 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:56:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:56:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 09:56:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:56:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5125,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 56, 33, 370800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 56, 33, 80800)}
2018-08-06 09:56:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:56:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:56:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:56:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:56:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:56:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:56:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:56:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:56:51 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:56:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:56:51 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 09:56:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:56:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5125,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 56, 51, 890800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 56, 51, 590800)}
2018-08-06 09:56:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:57:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:57:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:57:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:57:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:57:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:57:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:57:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:57:08 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:57:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:57:08 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 09:57:08 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:57:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5129,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 57, 8, 470800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 57, 8, 180800)}
2018-08-06 09:57:08 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:57:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:57:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:57:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:57:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:57:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:57:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:57:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:57:16 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:57:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:57:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 09:57:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:57:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5127,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 57, 16, 630800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 57, 16, 370800)}
2018-08-06 09:57:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:59:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:59:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:59:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:59:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:59:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:59:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:59:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:59:00 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:59:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:59:01 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 09:59:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:59:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5128,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 59, 1, 90800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 59, 0, 830800)}
2018-08-06 09:59:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 09:59:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 09:59:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 09:59:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 09:59:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 09:59:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 09:59:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 09:59:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 09:59:54 [scrapy.core.engine] INFO: Spider opened
2018-08-06 09:59:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 09:59:54 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 09:59:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 09:59:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5128,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 1, 59, 54, 802800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 1, 59, 54, 202800)}
2018-08-06 09:59:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:00:26 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:00:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:00:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:00:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:00:26 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:00:26 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:00:26 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:00:26 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:00:26 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:00:27 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 10:00:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:00:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5126,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 0, 27, 143800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 0, 26, 893800)}
2018-08-06 10:00:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:01:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:01:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:01:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:01:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:01:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:01:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:01:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:01:12 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:01:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:01:12 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 10:01:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:01:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5130,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 1, 12, 803800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 1, 12, 543800)}
2018-08-06 10:01:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:03:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:03:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:03:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:03:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:03:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:03:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:03:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:03:16 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:03:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:03:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 10:03:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:03:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5131,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 3, 16, 633800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 3, 16, 363800)}
2018-08-06 10:03:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:05:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:05:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:05:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:05:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:05:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:05:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:05:07 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:05:07 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:05:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:05:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 10:05:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:05:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5127,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 5, 7, 813800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 5, 7, 483800)}
2018-08-06 10:05:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:05:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:05:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:05:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:05:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:05:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:05:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:05:25 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:05:25 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:05:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:05:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:05:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5127,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 5, 26, 173800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 5, 25, 943800)}
2018-08-06 10:05:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:05:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:05:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:05:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:05:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:05:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:05:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:05:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:05:57 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:05:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:05:57 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 30, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 10:05:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:05:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5131,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 5, 57, 613800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 5, 57, 353800)}
2018-08-06 10:05:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:09:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:09:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:09:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:09:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:09:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:09:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:09:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:09:06 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:09:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:09:07 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 27, in parse
    item = LoadSpiderItem
NameError: name 'LoadSpiderItem' is not defined
2018-08-06 10:09:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:09:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5130,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 9, 7, 314800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/NameError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 9, 6, 874800)}
2018-08-06 10:09:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:09:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:09:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:09:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:09:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:09:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:09:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:09:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:09:44 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:09:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:09:45 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 29, in parse
    item['appName'] = info.xpath('./td[1]/span/text()').extract()
TypeError: 'ItemMeta' object does not support item assignment
2018-08-06 10:09:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:09:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5128,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 9, 45, 84800),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 9, 44, 604800)}
2018-08-06 10:09:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:10:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:10:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:10:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:10:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:10:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:10:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:10:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:10:17 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:10:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:10:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:10:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5128,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 10, 17, 654800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 10, 17, 274800)}
2018-08-06 10:10:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:11:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:11:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:11:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:11:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:11:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:11:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:11:02 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:11:02 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:11:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:11:02 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:11:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5127,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 11, 2, 804800),
 'item_scraped_count': 11,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 11, 2, 494800)}
2018-08-06 10:11:02 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:12:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:12:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:12:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:12:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:12:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:12:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:12:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:12:11 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:12:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:12:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:12:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5126,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 12, 11, 814800),
 'item_scraped_count': 11,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 12, 11, 534800)}
2018-08-06 10:12:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:13:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:13:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:13:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:13:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:13:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:13:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:13:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:13:10 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:13:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:13:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:13:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5129,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 13, 10, 604800),
 'item_scraped_count': 11,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 13, 10, 344800)}
2018-08-06 10:13:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:15:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:15:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:15:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:15:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:15:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:15:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:15:13 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:15:13 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:15:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:15:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:15:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5141,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 15, 13, 668800),
 'item_scraped_count': 11,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 15, 13, 387800)}
2018-08-06 10:15:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:15:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:15:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:15:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:15:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:15:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:15:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:15:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:15:52 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:15:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:15:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:15:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5126,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 15, 52, 798800),
 'item_scraped_count': 11,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 15, 52, 358800)}
2018-08-06 10:15:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:20:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:20:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:20:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:20:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:20:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:20:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:20:36 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:20:36 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:20:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:20:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:20:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5128,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 20, 36, 478800),
 'item_scraped_count': 11,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 20, 36, 228800)}
2018-08-06 10:20:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:23:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:23:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:23:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:23:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:23:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:23:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:23:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:23:44 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:23:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:23:44 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 39, in parse
    yield scrapy.Request(url, self.parse)
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\request\__init__.py", line 25, in __init__
    self._set_url(url)
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\request\__init__.py", line 62, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: /daikuan/lists/p/2
2018-08-06 10:23:44 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:23:44 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5127,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 23, 44, 733800),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 23, 44, 463800)}
2018-08-06 10:23:44 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:24:46 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:24:46 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:24:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:24:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:24:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:24:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:24:47 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:24:47 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:24:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:24:47 [scrapy.core.scraper] ERROR: Spider error processing <GET http://daikuan.51kanong.com/daikuan/lists/p/1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\daikuan_spider.py", line 40, in parse
    yield scrapy.Request(url, self.parse)
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\request\__init__.py", line 25, in __init__
    self._set_url(url)
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\request\__init__.py", line 62, in _set_url
    raise ValueError('Missing scheme in request url: %s' % self._url)
ValueError: Missing scheme in request url: /daikuan/lists/p/2
2018-08-06 10:24:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:24:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 319,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 5127,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 24, 47, 373800),
 'item_scraped_count': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 2, 24, 47, 113800)}
2018-08-06 10:24:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:28:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:28:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:28:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:28:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:28:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:28:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:28:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:28:21 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:28:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:29:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:29:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:29:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:29:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:29:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:29:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:29:23 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:29:23 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:29:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:30:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:30:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 10805,
 'downloader/request_count': 34,
 'downloader/request_method_count/GET': 34,
 'downloader/response_bytes': 178433,
 'downloader/response_count': 34,
 'downloader/response_status_count/200': 34,
 'dupefilter/filtered': 1089,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 30, 4, 25800),
 'item_scraped_count': 374,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 34,
 'scheduler/dequeued': 34,
 'scheduler/dequeued/memory': 34,
 'scheduler/enqueued': 34,
 'scheduler/enqueued/memory': 34,
 'start_time': datetime.datetime(2018, 8, 6, 2, 29, 23, 304800)}
2018-08-06 10:30:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:31:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:31:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:31:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:31:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:31:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:31:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:31:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:31:56 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:31:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:32:37 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:32:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 10805,
 'downloader/request_count': 34,
 'downloader/request_method_count/GET': 34,
 'downloader/response_bytes': 178440,
 'downloader/response_count': 34,
 'downloader/response_status_count/200': 34,
 'dupefilter/filtered': 1089,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 32, 37, 516800),
 'item_scraped_count': 374,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 34,
 'scheduler/dequeued': 34,
 'scheduler/dequeued/memory': 34,
 'scheduler/enqueued': 34,
 'scheduler/enqueued/memory': 34,
 'start_time': datetime.datetime(2018, 8, 6, 2, 31, 56, 876800)}
2018-08-06 10:32:37 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 10:32:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 10:32:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 10:32:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 10:32:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 10:32:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 10:32:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 10:32:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 10:32:51 [scrapy.core.engine] INFO: Spider opened
2018-08-06 10:32:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 10:33:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 10:33:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 10805,
 'downloader/request_count': 34,
 'downloader/request_method_count/GET': 34,
 'downloader/response_bytes': 178446,
 'downloader/response_count': 34,
 'downloader/response_status_count/200': 34,
 'dupefilter/filtered': 1089,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 2, 33, 32, 866800),
 'item_scraped_count': 374,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 34,
 'scheduler/dequeued': 34,
 'scheduler/dequeued/memory': 34,
 'scheduler/enqueued': 34,
 'scheduler/enqueued/memory': 34,
 'start_time': datetime.datetime(2018, 8, 6, 2, 32, 51, 566800)}
2018-08-06 10:33:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 11:47:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 11:47:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 11:47:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 11:47:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 11:47:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 11:47:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 11:47:02 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 11:47:02 [scrapy.core.engine] INFO: Spider opened
2018-08-06 11:47:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 11:47:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 11:47:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1032,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 18043,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 3, 47, 3, 538800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 3, 47, 2, 102800)}
2018-08-06 11:47:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 11:47:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 11:47:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 11:47:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 11:47:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 11:47:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 11:47:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 11:47:36 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 11:47:36 [scrapy.core.engine] INFO: Spider opened
2018-08-06 11:47:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 11:47:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 11:47:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16843,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 3, 47, 36, 827800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 3, 47, 36, 297800)}
2018-08-06 11:47:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 11:47:50 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 11:47:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 11:47:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 11:47:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 11:47:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 11:47:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 11:47:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 11:47:50 [scrapy.core.engine] INFO: Spider opened
2018-08-06 11:47:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 11:47:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 11:47:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16843,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 3, 47, 50, 787800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 3, 47, 50, 446800)}
2018-08-06 11:47:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 11:48:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 11:48:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 11:48:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 11:48:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 11:48:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 11:48:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 11:48:15 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 11:48:15 [scrapy.core.engine] INFO: Spider opened
2018-08-06 11:48:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 11:48:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 11:48:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1032,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 18043,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 3, 48, 17, 299800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 3, 48, 15, 490800)}
2018-08-06 11:48:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 11:49:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 11:49:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 11:49:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 11:49:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 11:49:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 11:49:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 11:49:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 11:49:12 [scrapy.core.engine] INFO: Spider opened
2018-08-06 11:49:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 11:49:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 11:49:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1032,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 18042,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 3, 49, 13, 370800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 3, 49, 12, 126800)}
2018-08-06 11:49:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 11:50:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 11:50:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 11:50:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 11:50:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 11:50:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 11:50:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 11:50:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 11:50:16 [scrapy.core.engine] INFO: Spider opened
2018-08-06 11:50:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 11:50:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 11:50:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16843,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 3, 50, 17, 454800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 3, 50, 16, 932800)}
2018-08-06 11:50:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:22:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:22:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:22:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:22:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:22:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:22:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:22:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:22:20 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:22:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:22:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:22:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1032,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 18049,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 22, 22, 422000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 6, 22, 20, 725000)}
2018-08-06 14:22:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:22:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:22:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:22:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:22:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:22:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:22:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:22:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:22:28 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:22:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:22:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:22:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1032,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 18070,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 22, 29, 622000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 6, 22, 28, 600000)}
2018-08-06 14:22:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:22:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:22:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:22:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:22:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:22:36 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:22:36 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:22:36 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:22:36 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:22:36 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:22:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:22:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1032,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 18046,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 22, 38, 612000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 6, 22, 36, 774000)}
2018-08-06 14:22:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:23:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:23:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:23:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:23:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:23:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:23:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:23:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:23:16 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:23:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:23:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:23:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1032,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 18070,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 23, 17, 966000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 6, 23, 16, 191000)}
2018-08-06 14:23:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:24:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:24:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:24:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:24:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:24:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:24:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:24:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:24:01 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:24:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:24:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:24:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1032,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 18049,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 24, 3, 662000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 6, 24, 1, 879000)}
2018-08-06 14:24:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:25:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:25:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:25:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:25:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:25:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:25:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:25:06 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:25:06 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:25:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:25:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:25:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16833,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 25, 6, 632000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 6, 25, 6, 51000)}
2018-08-06 14:25:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:25:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:25:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:25:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:25:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:25:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:25:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:25:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:25:17 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:25:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:25:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/productdetail/14045> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 16, in parse
    print(response.xpath('/html/body/section[1]/div/div[1]/section[1]/div[1]/div[2]/h4/p/span/'))
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/section[1]/div/div[1]/section[1]/div[1]/div[2]/h4/p/span/
2018-08-06 14:25:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:25:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16833,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 25, 17, 675000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 6, 25, 17, 214000)}
2018-08-06 14:25:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:25:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:25:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:25:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:25:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:25:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:25:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:25:23 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:25:23 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:25:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:25:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:25:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16833,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 25, 24, 494000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 6, 25, 23, 963000)}
2018-08-06 14:25:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:25:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:25:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:25:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:25:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:25:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:25:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:25:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:25:30 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:25:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:25:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/productdetail/14045> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 16, in parse
    print(response.xpath('/html/body/section[1]/div/div[1]/section[1]/div[1]/div[2]/h4/p/'))
  File "D:\software\Anaconda\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "D:\software\Anaconda\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "D:\software\Anaconda\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1577, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid expression in /html/body/section[1]/div/div[1]/section[1]/div[1]/div[2]/h4/p/
2018-08-06 14:25:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:25:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16833,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 25, 32, 878000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/ValueError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 6, 25, 30, 933000)}
2018-08-06 14:25:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:25:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:25:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:25:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:25:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:25:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:25:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:25:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:25:37 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:25:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:25:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:25:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16811,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 25, 38, 323000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 6, 6, 25, 37, 782000)}
2018-08-06 14:25:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 14:30:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 14:30:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 14:30:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 14:30:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 14:30:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 14:30:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 14:30:25 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 14:30:25 [scrapy.core.engine] INFO: Spider opened
2018-08-06 14:30:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 14:30:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/productdetail/14045> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\common\service.py", line 76, in start
    stdin=PIPE)
  File "D:\software\Anaconda\lib\subprocess.py", line 709, in __init__
    restore_signals, start_new_session)
  File "D:\software\Anaconda\lib\subprocess.py", line 997, in _execute_child
    startupinfo)
FileNotFoundError: [WinError 2] 系统找不到指定的文件。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 14, in parse
    browser = webdriver.Chrome()
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 68, in __init__
    self.service.start()
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\common\service.py", line 83, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home

2018-08-06 14:30:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 14:30:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 328,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 16833,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 6, 30, 26, 626000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 6, 30, 25, 975000)}
2018-08-06 14:30:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 16:48:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 16:48:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 16:48:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 16:48:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 16:48:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 16:48:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 16:48:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 16:48:12 [scrapy.core.engine] INFO: Spider opened
2018-08-06 16:48:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 16:48:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 16:48:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 8, 48, 14, 636000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 8, 48, 12, 926000)}
2018-08-06 16:48:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 16:51:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 16:51:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 16:51:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 16:51:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 16:51:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 16:51:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 16:51:49 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 16:51:49 [scrapy.core.engine] INFO: Spider opened
2018-08-06 16:51:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 16:51:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 16:51:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43128,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 8, 51, 58, 801000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 8, 51, 49, 825000)}
2018-08-06 16:51:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 16:54:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 16:54:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 16:54:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 16:54:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 16:54:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 16:54:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 16:54:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 16:54:21 [scrapy.core.engine] INFO: Spider opened
2018-08-06 16:54:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 16:54:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 16:54:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43128,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 8, 54, 34, 404000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 8, 54, 21, 608000)}
2018-08-06 16:54:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:05:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:05:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:05:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:05:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:05:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:05:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:05:35 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:05:35 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:05:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:05:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:05:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 5, 47, 728000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 5, 35, 304000)}
2018-08-06 17:05:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:11:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:11:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:11:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:11:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:11:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:11:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:11:18 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:11:18 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:11:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:11:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:11:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 11, 29, 189000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 11, 18, 135000)}
2018-08-06 17:11:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:13:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:13:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:13:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:13:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:13:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:13:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:13:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:13:28 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:13:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:13:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:13:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 13, 42, 967000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 13, 28, 23000)}
2018-08-06 17:13:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:15:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:15:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:15:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:15:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:15:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:15:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:15:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:15:10 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:15:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:15:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 22, in getTitle
    print(driver.find_element_by_xpath('//section[3]/div[2]/div[1]/div['+str[i]+']/div[2]/p[1]/a').text)
TypeError: 'type' object is not subscriptable
2018-08-06 17:15:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:15:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 15, 22, 489000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 15, 10, 491000)}
2018-08-06 17:15:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:16:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:16:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:16:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:16:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:16:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:16:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:16:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:16:37 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:16:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:16:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 22, in getTitle
    strXpath= '//section[3]/div[2]/div[1]/div['+str[i]+']/div[2]/p[1]/a'
TypeError: 'type' object is not subscriptable
2018-08-06 17:16:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:16:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 16, 48, 796000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 16, 37, 890000)}
2018-08-06 17:16:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:17:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:17:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:17:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:17:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:17:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:17:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:17:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:17:08 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:17:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:17:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 22, in getTitle
    strXpath= '//section[3]/div[2]/div[1]/div['+str[i]+']/div[2]/p[1]/a'
TypeError: 'type' object is not subscriptable
2018-08-06 17:17:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:17:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 17, 20, 130000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 17, 8, 576000)}
2018-08-06 17:17:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:18:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:18:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:18:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:18:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:18:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:18:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:18:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:18:10 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:18:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:18:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 23, in getTitle
    strXpath= '//section[3]/div[2]/div[1]/div['+str[i]+']/div[2]/p[1]/a'
TypeError: 'type' object is not subscriptable
2018-08-06 17:18:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:18:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 18, 22, 59000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 18, 10, 239000)}
2018-08-06 17:18:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:18:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:18:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:18:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:18:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:18:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:18:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:18:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:18:44 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:18:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:18:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 23, in getTitle
    strXpath= '//section[3]/div[2]/div[1]/div['+str[i]+']/div[2]/p[1]/a'
TypeError: 'type' object is not subscriptable
2018-08-06 17:18:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:18:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 18, 54, 399000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 18, 44, 289000)}
2018-08-06 17:18:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:19:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:19:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:19:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:19:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:19:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:19:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:19:22 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:19:22 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:19:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:19:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 23, in getTitle
    strXpath= '//section[3]/div[2]/div[1]/div['+str[i]+']/div[2]/p[1]/a'
TypeError: 'type' object is not subscriptable
2018-08-06 17:19:34 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:19:34 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 19, 34, 757000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 19, 22, 837000)}
2018-08-06 17:19:34 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:20:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:20:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:20:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:20:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:20:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:20:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:20:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:20:44 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:20:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:20:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:20:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 20, 56, 703000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 20, 44, 897000)}
2018-08-06 17:20:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:21:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:21:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:21:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:21:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:21:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:21:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:21:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:21:17 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:21:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:21:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 27, in getTitle
    print(driver.find_element_by_xpath(strXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[3]/div[2]/p[1]/a

2018-08-06 17:21:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:21:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 21, 31, 783000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 21, 17, 608000)}
2018-08-06 17:21:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:21:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:21:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:21:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:21:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:21:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:21:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:21:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:21:53 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:21:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:22:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 27, in getTitle
    print(driver.find_element_by_xpath(strXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[3]/div[2]/p[1]/a

2018-08-06 17:22:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:22:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 22, 7, 836000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 21, 53, 384000)}
2018-08-06 17:22:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:25:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:25:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:25:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:25:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:25:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:25:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:25:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:25:40 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:25:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:25:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:25:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 25, 51, 706000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 25, 40, 909000)}
2018-08-06 17:25:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:26:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:26:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:26:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:26:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:26:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:26:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:26:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:26:14 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:26:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:26:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:26:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 26, 26, 178000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 26, 14, 312000)}
2018-08-06 17:26:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:31:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:31:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:31:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:31:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:31:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:31:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:31:15 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:31:15 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:31:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:31:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:31:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 31, 28, 339000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 31, 15, 950000)}
2018-08-06 17:31:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:34:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:34:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:34:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:34:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:34:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:34:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:34:47 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:34:47 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:34:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:34:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:34:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 34, 59, 679000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 34, 47, 894000)}
2018-08-06 17:34:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:37:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:37:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:37:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:37:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:37:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:37:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:37:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:37:01 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:37:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:37:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:37:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 37, 14, 425000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 37, 1, 784000)}
2018-08-06 17:37:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:39:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:39:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:39:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:39:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:39:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:39:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:39:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:39:32 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:39:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:39:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:39:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 39, 43, 898000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 39, 32, 49000)}
2018-08-06 17:39:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:41:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:41:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:41:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:41:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:41:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:41:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:41:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:41:51 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:41:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:42:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 33, in getTitle
    print(driver.find_element_by_xpath(conditionsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[1]/div[2]/p[2]/span/*

2018-08-06 17:42:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:42:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 42, 6, 539000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 41, 51, 701000)}
2018-08-06 17:42:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:42:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:42:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:42:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:42:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:42:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:42:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:42:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:42:17 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:42:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:42:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 33, in getTitle
    print(driver.find_element_by_xpath(conditionsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: Given xpath expression "//section[3]/div[2]/div[1]/div[1]/div[2]/p[2]/*span" is invalid: SyntaxError: The expression is not a legal expression.

2018-08-06 17:42:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:42:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 42, 29, 44000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/InvalidSelectorException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 42, 17, 281000)}
2018-08-06 17:42:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:43:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:43:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:43:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:43:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:43:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:43:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:43:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:43:41 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:43:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:43:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:43:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 43, 53, 219000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 43, 41, 989000)}
2018-08-06 17:43:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:44:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:44:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:44:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:44:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:44:09 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:44:09 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:44:09 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:44:09 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:44:09 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:44:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:44:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 44, 21, 567000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 44, 9, 149000)}
2018-08-06 17:44:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:44:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:44:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:44:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:44:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:44:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:44:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:44:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:44:37 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:44:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:44:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:44:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 44, 48, 618000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 44, 37, 257000)}
2018-08-06 17:44:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:46:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:46:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:46:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:46:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:46:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:46:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:46:47 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:46:47 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:46:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:46:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:46:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 46, 59, 597000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 46, 47, 759000)}
2018-08-06 17:46:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:48:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:48:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:48:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:48:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:48:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:48:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:48:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:48:12 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:48:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:48:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 33, in getTitle
    print(driver.find_element_by_xpath(conditionsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: TypeError: Expected an element or WindowProxy, got: [object Text] {}

2018-08-06 17:48:23 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:48:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 48, 23, 4000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 48, 12, 682000)}
2018-08-06 17:48:23 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:48:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:48:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:48:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:48:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:48:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:48:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:48:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:48:42 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:48:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:48:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:48:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 48, 55, 277000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 48, 42, 904000)}
2018-08-06 17:48:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:49:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:49:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:49:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:49:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:49:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:49:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:49:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:49:16 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:49:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:49:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 33, in getTitle
    print(driver.find_element_by_xpath(conditionsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: TypeError: Expected an element or WindowProxy, got: [object Attr] {}

2018-08-06 17:49:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:49:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 49, 28, 748000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/WebDriverException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 49, 16, 778000)}
2018-08-06 17:49:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:49:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:49:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:49:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:49:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:49:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:49:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:49:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:49:38 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:49:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:49:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:49:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 49, 49, 933000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 49, 38, 228000)}
2018-08-06 17:49:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:50:21 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:50:21 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:50:21 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:50:21 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:50:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:50:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:50:21 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:50:21 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:50:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:50:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 33, in getTitle
    print(driver.find_element_by_xpath(conditionsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.InvalidSelectorException: Message: Given xpath expression "//section[3]/div[2]/div[1]/div[1]/div[2]/p[2]/" is invalid: SyntaxError: The expression is not a legal expression.

2018-08-06 17:50:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:50:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 50, 33, 51000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/InvalidSelectorException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 50, 21, 997000)}
2018-08-06 17:50:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:50:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:50:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:50:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:50:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:50:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:50:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:50:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:50:38 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:50:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:50:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:50:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 50, 50, 717000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 50, 38, 674000)}
2018-08-06 17:50:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:55:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:55:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:55:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:55:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:55:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:55:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:55:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:55:12 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:55:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:55:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:55:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 55, 25, 330000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 9, 55, 12, 436000)}
2018-08-06 17:55:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 17:57:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 17:57:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 17:57:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 17:57:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 17:57:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 17:57:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 17:57:07 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 17:57:07 [scrapy.core.engine] INFO: Spider opened
2018-08-06 17:57:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 17:57:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 36, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[4]/div[1]/div[2]/div/p/a

2018-08-06 17:57:22 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 17:57:22 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 9, 57, 22, 833000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 9, 57, 7, 973000)}
2018-08-06 17:57:22 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:03:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:03:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:03:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:03:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:03:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:03:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:03:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:03:28 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:03:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:03:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[4]/div[1]/div[2]/div/p/a

2018-08-06 18:03:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:03:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 3, 43, 721000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 3, 28, 811000)}
2018-08-06 18:03:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:05:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:05:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:05:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:05:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:05:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:05:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:05:05 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:05:05 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:05:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:05:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[1]/div[2]/div/p/a

2018-08-06 18:05:20 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:05:20 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 5, 20, 608000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 5, 5, 481000)}
2018-08-06 18:05:20 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:05:45 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:05:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:05:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:05:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:05:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:05:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:05:45 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:05:45 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:05:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:05:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[1]/div[2]/div/p/a

2018-08-06 18:06:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:06:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 6, 0, 56000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 5, 45, 308000)}
2018-08-06 18:06:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:06:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:06:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:06:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:06:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:06:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:06:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:06:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:06:14 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:06:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:06:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[1]/div[2]/div/p/a

2018-08-06 18:06:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:06:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 6, 29, 789000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 6, 14, 686000)}
2018-08-06 18:06:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:07:10 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:07:10 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:07:10 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:07:10 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:07:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:07:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:07:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:07:11 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:07:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:07:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[4]/div[1]/div[2]/div/p/a

2018-08-06 18:07:25 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:07:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 7, 25, 140000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 7, 11, 120000)}
2018-08-06 18:07:25 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:40:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:40:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:40:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:40:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:40:17 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:40:17 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:40:17 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:40:17 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:40:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:40:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[1]/div[2]/div/p/a

2018-08-06 18:40:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:40:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 40, 28, 551000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 40, 17, 275000)}
2018-08-06 18:40:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:40:45 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:40:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:40:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:40:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:40:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:40:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:40:46 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:40:46 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:40:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:41:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[1]/div[2]/div/p/a

2018-08-06 18:41:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:41:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 41, 28, 201000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 40, 46, 112000)}
2018-08-06 18:41:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:41:36 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:41:36 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:41:36 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:41:36 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:41:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:41:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:41:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:41:37 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:41:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:41:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[1]/div[2]/div/p/a

2018-08-06 18:41:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:41:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 41, 51, 673000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 41, 37, 82000)}
2018-08-06 18:41:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:42:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:42:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:42:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:42:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:42:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:42:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:42:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:42:38 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:42:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:42:51 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:42:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 42, 51, 443000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 10, 42, 38, 984000)}
2018-08-06 18:42:51 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:43:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:43:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:43:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:43:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:43:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:43:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:43:14 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:43:14 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:43:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:43:26 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:43:26 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 43, 26, 113000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 10, 43, 14, 683000)}
2018-08-06 18:43:26 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:52:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:52:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:52:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:52:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:52:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:52:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:52:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:52:32 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:52:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:52:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:52:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 52, 46, 63000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 10, 52, 32, 992000)}
2018-08-06 18:52:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:52:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:52:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:52:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:52:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:52:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:52:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:52:58 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:52:58 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:52:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:53:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: https://shenzhen.rongzi.com/product/)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 40, in getTitle
    print(driver.find_element_by_xpath(requirementsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[4]/div[1]/div[2]/div/p/a

2018-08-06 18:53:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:53:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 53, 14, 232000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 10, 52, 58, 653000)}
2018-08-06 18:53:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:53:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:53:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:53:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:53:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:53:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:53:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:53:38 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:53:38 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:53:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:53:49 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:53:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 53, 49, 311000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 10, 53, 38, 172000)}
2018-08-06 18:53:49 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:53:59 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:53:59 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:53:59 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:53:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:53:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:53:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:53:59 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:53:59 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:53:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:54:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:54:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 54, 11, 19000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 10, 53, 59, 230000)}
2018-08-06 18:54:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:58:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:58:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:58:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:58:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:58:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:58:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:58:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:58:53 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:58:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:59:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:59:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 59, 5, 708000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 10, 58, 53, 559000)}
2018-08-06 18:59:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 18:59:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 18:59:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 18:59:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 18:59:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 18:59:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 18:59:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 18:59:47 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 18:59:47 [scrapy.core.engine] INFO: Spider opened
2018-08-06 18:59:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 18:59:59 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 18:59:59 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1608,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 43131,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 10, 59, 59, 948000),
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 2,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2018, 8, 6, 10, 59, 47, 773000)}
2018-08-06 18:59:59 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:04:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:04:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:04:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:04:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:04:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:04:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:04:04 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:04:04 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:04:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:04:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:04:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 4, 18, 35000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 4, 4, 510000)}
2018-08-06 19:04:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:09:45 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:09:45 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:09:45 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:09:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:09:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:09:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:09:45 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:09:45 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:09:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:09:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 41, in parse
    item['costs'] = driver.find_element_by_xpath(timeXpath).text
  File "D:\software\Anaconda\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'LoadSpiderItem does not support field: costs'
2018-08-06 19:09:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:09:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 9, 57, 985000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 9, 45, 675000)}
2018-08-06 19:09:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:12:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:12:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:12:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:12:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:12:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:12:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:12:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:12:08 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:12:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:12:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 45, in parse
    item['costs'] = driver.find_element_by_xpath(timeXpath).text
  File "D:\software\Anaconda\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'FinancingSpiderItem does not support field: costs'
2018-08-06 19:12:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:12:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 12, 19, 361000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 12, 8, 836000)}
2018-08-06 19:12:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:13:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:13:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:13:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:13:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:13:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:13:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:13:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:13:08 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:13:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:13:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 45, in parse
    item['costs'] = driver.find_element_by_xpath(timeXpath).text
  File "D:\software\Anaconda\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'FinancingSpiderItem does not support field: costs'
2018-08-06 19:13:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:13:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 13, 19, 451000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 13, 8, 612000)}
2018-08-06 19:13:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:13:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:13:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:13:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:13:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:13:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:13:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:13:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:13:51 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:13:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:14:59 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 1 items (at 1 items/min)
2018-08-06 19:15:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:15:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 15, 0, 161000),
 'item_scraped_count': 9,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 13, 51, 601000)}
2018-08-06 19:15:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:16:55 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:16:55 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:16:55 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:16:55 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:16:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:16:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:16:55 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:16:55 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:16:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:17:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:17:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 17, 9, 906000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 16, 55, 874000)}
2018-08-06 19:17:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:18:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:18:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:18:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:18:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:18:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:18:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:18:02 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:18:02 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:18:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:18:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 36, in parse
    print(driver.find_element_by_xpath(strXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[2]/div[1]/div[2]/p[1]/a

2018-08-06 19:18:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:18:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 18, 16, 60000),
 'item_scraped_count': 37,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 18, 2, 370000)}
2018-08-06 19:18:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:19:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:19:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:19:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:19:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:19:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:19:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:19:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:19:37 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:19:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:19:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:19:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 19, 48, 60000),
 'item_scraped_count': 9,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 19, 37, 381000)}
2018-08-06 19:19:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:20:25 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:20:25 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:20:25 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:20:25 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:20:25 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:20:25 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:20:25 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:20:25 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:20:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:20:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:20:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 20, 39, 107000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 20, 25, 332000)}
2018-08-06 19:20:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:20:50 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:20:50 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:20:50 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:20:50 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:20:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:20:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:20:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:20:51 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:20:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:21:04 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:21:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 21, 4, 361000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 20, 51, 127000)}
2018-08-06 19:21:04 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:21:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:21:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:21:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:21:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:21:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:21:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:21:39 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:21:39 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:21:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:21:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:21:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 21, 52, 67000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 21, 39, 84000)}
2018-08-06 19:21:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:24:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:24:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:24:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:24:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:24:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:24:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:24:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:24:41 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:24:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:24:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:24:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 24, 55, 250000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 24, 41, 262000)}
2018-08-06 19:24:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:26:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:26:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:26:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:26:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:26:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:26:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:26:35 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:26:35 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:26:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:26:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:26:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 26, 56, 924000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 26, 35, 331000)}
2018-08-06 19:26:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:27:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:27:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:27:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:27:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:27:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:27:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:27:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:27:34 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:27:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:28:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:28:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 28, 14, 67000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 27, 34, 326000)}
2018-08-06 19:28:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:29:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:29:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:29:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:29:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:29:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:29:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:29:23 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:29:23 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:29:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:29:57 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:29:57 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 29, 57, 145000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 29, 23, 32000)}
2018-08-06 19:29:57 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:30:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:30:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:30:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:30:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:30:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:30:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:30:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:30:53 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:30:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:31:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:31:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22136,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 31, 27, 91000),
 'item_scraped_count': 36,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 30, 53, 289000)}
2018-08-06 19:31:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:32:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:32:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:32:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:32:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:32:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:32:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:32:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:32:11 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:32:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:33:11 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 73 items (at 73 items/min)
2018-08-06 19:34:12 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 0 pages/min), scraped 163 items (at 90 items/min)
2018-08-06 19:34:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:34:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 34, 18, 77000),
 'item_scraped_count': 171,
 'log_count/INFO': 9,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 32, 11, 675000)}
2018-08-06 19:34:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:36:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:36:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:36:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:36:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:36:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:36:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:36:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:36:12 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:36:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:36:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:36:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 36, 38, 452000),
 'item_scraped_count': 40,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 36, 12, 637000)}
2018-08-06 19:36:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:38:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:38:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:38:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:38:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:38:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:38:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:38:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:38:08 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:38:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:38:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:38:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 38, 30, 366000),
 'item_scraped_count': 40,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 11, 38, 8, 847000)}
2018-08-06 19:38:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:39:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:39:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:39:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:39:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:39:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:39:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:39:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:39:08 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:39:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:39:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 38, in parse
    item['appName'] = driver.find_element_by_xpath(strXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[2]/div[1]/div[2]/p[1]/a

2018-08-06 19:39:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:39:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 39, 29, 110000),
 'item_scraped_count': 41,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 39, 8, 77000)}
2018-08-06 19:39:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:41:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:41:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:41:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:41:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:41:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:41:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:41:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:41:54 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:41:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:42:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 38, in parse
    item['appName'] = driver.find_element_by_xpath(strXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[2]/div[1]/div[2]/p[1]/a

2018-08-06 19:42:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:42:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 42, 16, 346000),
 'item_scraped_count': 41,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 41, 54, 640000)}
2018-08-06 19:42:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:42:31 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:42:31 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:42:31 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:42:31 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:42:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:42:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:42:31 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:42:31 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:42:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:43:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 42, in parse
    item['lines'] = driver.find_element_by_xpath(costsXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 19:43:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:43:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22136,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 43, 6, 847000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 42, 31, 203000)}
2018-08-06 19:43:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:44:30 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:44:30 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:44:30 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:44:30 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:44:30 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:44:30 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:44:30 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:44:30 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:44:30 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:45:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 42, in parse
    item['lines'] = driver.find_element_by_xpath(costsXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 19:45:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:45:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 45, 16, 407000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 44, 30, 345000)}
2018-08-06 19:45:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:47:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:47:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:47:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:47:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:47:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:47:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:47:07 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:47:07 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:47:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:47:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 38, in parse
    item['appName'] = driver.find_element_by_xpath(strXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webelement.py", line 76, in text
    return self._execute(Command.GET_ELEMENT_TEXT)['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webelement.py", line 628, in _execute
    return self._parent.execute(command, params)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.StaleElementReferenceException: Message: The element reference of <a href="/product/productdetail/14726"> is stale; either the element is no longer attached to the DOM, it is not in the current frame context, or the document has been refreshed

2018-08-06 19:47:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:47:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 47, 50, 426000),
 'item_scraped_count': 86,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/StaleElementReferenceException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 47, 7, 763000)}
2018-08-06 19:47:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:50:24 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:50:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:50:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:50:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:50:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:50:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:50:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:50:24 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:50:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:50:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 42, in parse
    item['lines'] = driver.find_element_by_xpath(costsXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 19:50:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:50:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 50, 50, 891000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 50, 24, 338000)}
2018-08-06 19:50:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:51:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:51:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:51:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:51:58 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:51:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:51:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:51:58 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:51:58 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:51:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:52:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 42, in parse
    item['lines'] = driver.find_element_by_xpath(costsXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 19:52:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:52:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 52, 24, 677000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 51, 58, 943000)}
2018-08-06 19:52:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:53:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:53:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:53:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:53:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:53:15 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:53:15 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:53:15 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:53:15 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:53:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:54:15 [scrapy.extensions.logstats] INFO: Crawled 1 pages (at 1 pages/min), scraped 45 items (at 45 items/min)
2018-08-06 19:55:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 42, in parse
    item['lines'] = driver.find_element_by_xpath(costsXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 19:55:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:55:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 55, 6, 400000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 53, 15, 491000)}
2018-08-06 19:55:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:56:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:56:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:56:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:56:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:56:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:56:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:56:28 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:56:28 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:56:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:56:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 38, in parse
    item['appName'] = driver.find_element_by_xpath(strXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[11]/div[1]/div[2]/p[1]/a

2018-08-06 19:56:39 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:56:39 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22136,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 56, 39, 874000),
 'item_scraped_count': 10,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 56, 28, 465000)}
2018-08-06 19:56:39 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 19:58:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 19:58:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 19:58:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 19:58:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 19:58:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 19:58:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 19:58:04 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 19:58:04 [scrapy.core.engine] INFO: Spider opened
2018-08-06 19:58:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 19:58:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 42, in parse
    item['lines'] = driver.find_element_by_xpath(costsXpath).text
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 19:58:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 19:58:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 11, 58, 35, 598000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 11, 58, 4, 816000)}
2018-08-06 19:58:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 20:00:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 20:00:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 20:00:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 20:00:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 20:00:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 20:00:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 20:00:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 20:00:40 [scrapy.core.engine] INFO: Spider opened
2018-08-06 20:00:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 20:01:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 42, in parse
    print(driver.find_element_by_xpath(costsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 20:01:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 20:01:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 12, 1, 11, 168000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 12, 0, 40, 542000)}
2018-08-06 20:01:11 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 20:17:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 20:17:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 20:17:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 20:17:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 20:17:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 20:17:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 20:17:33 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 20:17:33 [scrapy.core.engine] INFO: Spider opened
2018-08-06 20:17:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 20:18:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 43, in parse
    print(driver.find_element_by_xpath(costsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 20:18:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 20:18:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 12, 18, 1, 324000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 12, 17, 33, 74000)}
2018-08-06 20:18:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 20:18:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 20:18:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 20:18:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 20:18:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 20:18:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 20:18:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 20:18:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 20:18:37 [scrapy.core.engine] INFO: Spider opened
2018-08-06 20:18:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 20:19:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 43, in parse
    print(driver.find_element_by_xpath(costsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[1]/div[2]/div[1]/p[1]/span[2]

2018-08-06 20:19:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 20:19:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22136,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 12, 19, 5, 250000),
 'item_scraped_count': 90,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 12, 18, 37, 378000)}
2018-08-06 20:19:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 20:21:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 20:21:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 20:21:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 20:21:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 20:21:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 20:21:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 20:21:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 20:21:08 [scrapy.core.engine] INFO: Spider opened
2018-08-06 20:21:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 20:21:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 20:21:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22144,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 12, 21, 47, 312000),
 'item_scraped_count': 140,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'start_time': datetime.datetime(2018, 8, 6, 12, 21, 8, 480000)}
2018-08-06 20:21:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-06 20:23:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-06 20:23:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-06 20:23:02 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-06 20:23:02 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-06 20:23:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-06 20:23:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-06 20:23:02 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-06 20:23:02 [scrapy.core.engine] INFO: Spider opened
2018-08-06 20:23:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-06 20:23:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://shenzhen.rongzi.com/product/> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\financing_spider.py", line 45, in parse
    print(driver.find_element_by_xpath(costsXpath).text)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 393, in find_element_by_xpath
    return self.find_element(by=By.XPATH, value=xpath)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 966, in find_element
    'value': value})['value']
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 320, in execute
    self.error_handler.check_response(response)
  File "D:\software\Anaconda\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: //section[3]/div[2]/div[6]/div[2]/div[1]/p[1]/span[2]

2018-08-06 20:23:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-06 20:23:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 987,
 'downloader/request_count': 2,
 'downloader/request_method_count/GET': 2,
 'downloader/response_bytes': 22139,
 'downloader/response_count': 2,
 'downloader/response_status_count/200': 1,
 'downloader/response_status_count/302': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 6, 12, 23, 42, 410000),
 'item_scraped_count': 145,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 2,
 'scheduler/dequeued/memory': 2,
 'scheduler/enqueued': 2,
 'scheduler/enqueued/memory': 2,
 'spider_exceptions/NoSuchElementException': 1,
 'start_time': datetime.datetime(2018, 8, 6, 12, 23, 2, 197000)}
2018-08-06 20:23:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:06:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:06:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:06:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:06:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:06:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:06:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:06:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:06:41 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:06:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:06:41 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:06:41 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 6, 41, 590800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 6, 41, 390800)}
2018-08-07 10:06:41 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:16:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:16:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:16:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:16:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:16:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:16:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:16:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:16:00 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:16:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:16:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:16:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 16, 0, 950800),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 16, 0, 770800)}
2018-08-07 10:16:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:20:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:20:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:20:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:20:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:20:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:20:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:20:29 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:20:29 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:20:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:20:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:20:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 20, 29, 301800),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 20, 29, 151800)}
2018-08-07 10:20:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:26:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:26:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:26:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:26:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:26:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:26:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:26:01 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:26:01 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:26:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:26:01 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:26:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 26, 1, 274800),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 26, 1, 114800)}
2018-08-07 10:26:01 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:27:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:27:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:27:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:27:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:27:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:27:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:27:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:27:32 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:27:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:27:32 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:27:32 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 27, 32, 814800),
 'item_scraped_count': 2,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 27, 32, 634800)}
2018-08-07 10:27:32 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:31:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:31:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:31:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:31:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:31:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:31:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:31:07 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:31:07 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:31:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:31:07 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:31:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 31, 7, 714800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 31, 7, 534800)}
2018-08-07 10:31:07 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:31:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:31:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:31:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:31:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:31:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:31:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:31:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:31:52 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:31:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:31:52 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:31:52 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 31, 52, 994800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 31, 52, 824800)}
2018-08-07 10:31:52 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:32:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:32:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:32:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:32:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:32:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:32:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:32:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:32:20 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:32:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:32:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:32:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 32, 21, 4800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 32, 20, 834800)}
2018-08-07 10:32:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:32:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:32:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:32:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:32:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:32:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:32:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:32:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:32:42 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:32:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:32:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:32:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 32, 42, 314800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 32, 42, 144800)}
2018-08-07 10:32:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:32:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:32:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:32:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:32:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:32:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:32:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:32:57 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:32:57 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:32:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:32:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:32:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4157,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 32, 58, 334800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 32, 57, 794800)}
2018-08-07 10:32:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:33:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:33:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:33:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:33:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:33:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:33:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:33:41 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:33:41 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:33:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:33:42 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:33:42 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 33, 42, 44800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 33, 41, 884800)}
2018-08-07 10:33:42 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:33:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:33:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:33:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:33:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:33:50 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:33:50 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:33:50 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:33:50 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:33:50 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:33:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:33:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 33, 50, 234800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 33, 50, 54800)}
2018-08-07 10:33:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:34:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:34:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:34:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:34:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:34:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:34:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:34:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:34:00 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:34:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:34:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:34:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 34, 0, 994800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 34, 0, 824800)}
2018-08-07 10:34:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:34:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:34:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:34:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:34:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:34:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:34:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:34:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:34:56 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:34:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:34:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:34:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 34, 56, 431800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 34, 56, 281800)}
2018-08-07 10:34:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:40:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:40:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:40:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:40:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:40:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:40:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:40:49 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:40:49 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:40:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:40:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:40:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 40, 50, 61800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 40, 49, 841800)}
2018-08-07 10:40:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:41:24 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:41:24 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:41:24 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:41:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:41:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:41:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:41:24 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:41:24 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:41:24 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:41:24 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:41:24 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 41, 24, 851800),
 'item_scraped_count': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 41, 24, 701800)}
2018-08-07 10:41:24 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:42:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:42:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:42:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:42:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:42:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:42:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:42:00 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:42:00 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:42:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:42:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:42:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 42, 0, 501800),
 'item_scraped_count': 16,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 42, 0, 331800)}
2018-08-07 10:42:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:42:29 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:42:29 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:42:29 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:42:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:42:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:42:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:42:29 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:42:29 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:42:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:42:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:42:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 42, 30, 31800),
 'item_scraped_count': 16,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 42, 29, 861800)}
2018-08-07 10:42:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:44:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:44:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:44:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:44:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:44:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:44:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:44:03 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:44:03 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:44:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:44:03 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:44:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 44, 3, 641800),
 'item_scraped_count': 16,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 44, 3, 461800)}
2018-08-07 10:44:03 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:46:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:46:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:46:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:46:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:46:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:46:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:46:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:46:32 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:46:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:46:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:46:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 321,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 46, 33, 101800),
 'item_scraped_count': 16,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 2, 46, 32, 911800)}
2018-08-07 10:46:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:50:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:50:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:50:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:50:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:50:11 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:50:11 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:50:11 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:50:11 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:50:11 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:50:11 [scrapy.core.scraper] ERROR: Error downloading <GET https:///%20//%20www.yetu.net%20/%20product%20/%20list%20-%200%20-%200%20-%200%20-%20--5.html>
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\software\Anaconda\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 65, in download_request
    return handler.download_request(request, spider)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 67, in download_request
    return agent.download_request(request)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 331, in download_request
    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1633, in request
    endpoint = self._getEndpoint(parsedURI)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1617, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1494, in endpointForURI
    uri.port)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 59, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext())
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_sslverify.py", line 1152, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_idna.py", line 30, in _idnaBytes
    return idna.encode(text)
  File "D:\software\Anaconda\lib\site-packages\idna\core.py", line 350, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
2018-08-07 10:50:13 [scrapy.core.scraper] ERROR: Error downloading <GET https:///%20//%20www.yetu.net%20/%20product%20/%20list%20-%200%20-%200%20-%200%20-%20--4.html>
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\software\Anaconda\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 65, in download_request
    return handler.download_request(request, spider)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 67, in download_request
    return agent.download_request(request)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 331, in download_request
    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1633, in request
    endpoint = self._getEndpoint(parsedURI)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1617, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1494, in endpointForURI
    uri.port)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 59, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext())
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_sslverify.py", line 1152, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_idna.py", line 30, in _idnaBytes
    return idna.encode(text)
  File "D:\software\Anaconda\lib\site-packages\idna\core.py", line 350, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
2018-08-07 10:50:13 [scrapy.core.scraper] ERROR: Error downloading <GET https:///%20//%20www.yetu.net%20/%20product%20/%20list%20-%200%20-%200%20-%200%20-%20--3.html>
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\software\Anaconda\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 65, in download_request
    return handler.download_request(request, spider)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 67, in download_request
    return agent.download_request(request)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 331, in download_request
    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1633, in request
    endpoint = self._getEndpoint(parsedURI)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1617, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1494, in endpointForURI
    uri.port)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 59, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext())
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_sslverify.py", line 1152, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_idna.py", line 30, in _idnaBytes
    return idna.encode(text)
  File "D:\software\Anaconda\lib\site-packages\idna\core.py", line 350, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
2018-08-07 10:50:15 [scrapy.core.scraper] ERROR: Error downloading <GET https:///%20//%20www.yetu.net%20/%20product%20/%20list%20-%200%20-%200%20-%200%20-%20--2.html>
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\software\Anaconda\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 65, in download_request
    return handler.download_request(request, spider)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 67, in download_request
    return agent.download_request(request)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 331, in download_request
    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1633, in request
    endpoint = self._getEndpoint(parsedURI)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1617, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1494, in endpointForURI
    uri.port)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 59, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext())
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_sslverify.py", line 1152, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_idna.py", line 30, in _idnaBytes
    return idna.encode(text)
  File "D:\software\Anaconda\lib\site-packages\idna\core.py", line 350, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
2018-08-07 10:50:15 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:50:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 4,
 'downloader/exception_type_count/idna.core.IDNAError': 4,
 'downloader/request_bytes': 1605,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 50, 15, 252800),
 'item_scraped_count': 16,
 'log_count/ERROR': 4,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2018, 8, 7, 2, 50, 11, 232800)}
2018-08-07 10:50:15 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:50:26 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:50:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:50:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:50:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:50:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:50:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:50:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:50:27 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:50:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:50:27 [scrapy.core.scraper] ERROR: Error downloading <GET https:///%20//%20www.yetu.net%20/%20product%20/%20list%20-%200%20-%200%20-%200%20-%20--5.html>
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\software\Anaconda\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 65, in download_request
    return handler.download_request(request, spider)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 67, in download_request
    return agent.download_request(request)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 331, in download_request
    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1633, in request
    endpoint = self._getEndpoint(parsedURI)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1617, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1494, in endpointForURI
    uri.port)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 59, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext())
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_sslverify.py", line 1152, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_idna.py", line 30, in _idnaBytes
    return idna.encode(text)
  File "D:\software\Anaconda\lib\site-packages\idna\core.py", line 350, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
2018-08-07 10:50:28 [scrapy.core.scraper] ERROR: Error downloading <GET https:///%20//%20www.yetu.net%20/%20product%20/%20list%20-%200%20-%200%20-%200%20-%20--4.html>
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\software\Anaconda\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 65, in download_request
    return handler.download_request(request, spider)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 67, in download_request
    return agent.download_request(request)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 331, in download_request
    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1633, in request
    endpoint = self._getEndpoint(parsedURI)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1617, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1494, in endpointForURI
    uri.port)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 59, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext())
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_sslverify.py", line 1152, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_idna.py", line 30, in _idnaBytes
    return idna.encode(text)
  File "D:\software\Anaconda\lib\site-packages\idna\core.py", line 350, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
2018-08-07 10:50:29 [scrapy.core.scraper] ERROR: Error downloading <GET https:///%20//%20www.yetu.net%20/%20product%20/%20list%20-%200%20-%200%20-%200%20-%20--3.html>
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\software\Anaconda\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 65, in download_request
    return handler.download_request(request, spider)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 67, in download_request
    return agent.download_request(request)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 331, in download_request
    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1633, in request
    endpoint = self._getEndpoint(parsedURI)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1617, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1494, in endpointForURI
    uri.port)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 59, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext())
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_sslverify.py", line 1152, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_idna.py", line 30, in _idnaBytes
    return idna.encode(text)
  File "D:\software\Anaconda\lib\site-packages\idna\core.py", line 350, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
2018-08-07 10:50:31 [scrapy.core.scraper] ERROR: Error downloading <GET https:///%20//%20www.yetu.net%20/%20product%20/%20list%20-%200%20-%200%20-%200%20-%20--2.html>
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\defer.py", line 1384, in _inlineCallbacks
    result = result.throwExceptionIntoGenerator(g)
  File "D:\software\Anaconda\lib\site-packages\twisted\python\failure.py", line 393, in throwExceptionIntoGenerator
    return g.throw(self.type, self.value, self.tb)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\middleware.py", line 43, in process_request
    defer.returnValue((yield download_func(request=request,spider=spider)))
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 45, in mustbe_deferred
    result = f(*args, **kw)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\__init__.py", line 65, in download_request
    return handler.download_request(request, spider)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 67, in download_request
    return agent.download_request(request)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\handlers\http11.py", line 331, in download_request
    method, to_bytes(url, encoding='ascii'), headers, bodyproducer)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1633, in request
    endpoint = self._getEndpoint(parsedURI)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1617, in _getEndpoint
    return self._endpointFactory.endpointForURI(uri)
  File "D:\software\Anaconda\lib\site-packages\twisted\web\client.py", line 1494, in endpointForURI
    uri.port)
  File "D:\software\Anaconda\lib\site-packages\scrapy\core\downloader\contextfactory.py", line 59, in creatorForNetloc
    return ScrapyClientTLSOptions(hostname.decode("ascii"), self.getContext())
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_sslverify.py", line 1152, in __init__
    self._hostnameBytes = _idnaBytes(hostname)
  File "D:\software\Anaconda\lib\site-packages\twisted\internet\_idna.py", line 30, in _idnaBytes
    return idna.encode(text)
  File "D:\software\Anaconda\lib\site-packages\idna\core.py", line 350, in encode
    raise IDNAError('Empty domain')
idna.core.IDNAError: Empty domain
2018-08-07 10:50:31 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:50:31 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 4,
 'downloader/exception_type_count/idna.core.IDNAError': 4,
 'downloader/request_bytes': 1605,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 4199,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 50, 31, 112800),
 'item_scraped_count': 16,
 'log_count/ERROR': 4,
 'log_count/INFO': 7,
 'request_depth_max': 1,
 'response_received_count': 1,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2018, 8, 7, 2, 50, 27, 122800)}
2018-08-07 10:50:31 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:50:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:50:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:50:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:50:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:50:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:50:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:50:52 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:50:52 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:50:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:50:58 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:50:58 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1425,
 'downloader/request_count': 5,
 'downloader/request_method_count/GET': 5,
 'downloader/response_bytes': 21301,
 'downloader/response_count': 5,
 'downloader/response_status_count/200': 5,
 'dupefilter/filtered': 16,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 50, 58, 163800),
 'item_scraped_count': 80,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 5,
 'scheduler/dequeued': 5,
 'scheduler/dequeued/memory': 5,
 'scheduler/enqueued': 5,
 'scheduler/enqueued/memory': 5,
 'start_time': datetime.datetime(2018, 8, 7, 2, 50, 52, 833800)}
2018-08-07 10:50:58 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 10:51:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 10:51:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 10:51:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 10:51:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 10:51:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 10:51:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 10:51:54 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 10:51:54 [scrapy.core.engine] INFO: Spider opened
2018-08-07 10:51:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 10:52:06 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 10:52:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2806,
 'downloader/request_count': 10,
 'downloader/request_method_count/GET': 10,
 'downloader/response_bytes': 42848,
 'downloader/response_count': 10,
 'downloader/response_status_count/200': 10,
 'dupefilter/filtered': 81,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 2, 52, 6, 846800),
 'item_scraped_count': 160,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 10,
 'scheduler/dequeued': 10,
 'scheduler/dequeued/memory': 10,
 'scheduler/enqueued': 10,
 'scheduler/enqueued/memory': 10,
 'start_time': datetime.datetime(2018, 8, 7, 2, 51, 54, 646800)}
2018-08-07 10:52:06 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 11:35:20 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 11:35:20 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 11:35:20 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 11:35:20 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 11:35:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 11:35:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 11:35:20 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 11:35:20 [scrapy.core.engine] INFO: Spider opened
2018-08-07 11:35:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 11:35:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 11:35:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21702,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 3, 35, 21, 285800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 3, 35, 20, 745800)}
2018-08-07 11:35:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 11:35:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 11:35:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 11:35:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 11:35:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 11:35:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 11:35:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 11:35:37 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 11:35:37 [scrapy.core.engine] INFO: Spider opened
2018-08-07 11:35:37 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 11:35:38 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 11:35:38 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21702,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 3, 35, 38, 465800),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 3, 35, 37, 895800)}
2018-08-07 11:35:38 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:18:52 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:18:52 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:18:52 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:18:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:18:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:18:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:18:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:18:53 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:18:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:18:53 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:18:53 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 18, 53, 836000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 18, 53, 235000)}
2018-08-07 14:18:53 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:19:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:19:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:19:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:19:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:19:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:19:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:19:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:19:12 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:19:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:19:13 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:19:13 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 19, 13, 217000),
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 19, 12, 782000)}
2018-08-07 14:19:13 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:19:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:19:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:19:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:19:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:19:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:19:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:19:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:19:40 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:19:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:19:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:19:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 19, 40, 895000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 19, 40, 315000)}
2018-08-07 14:19:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:21:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:21:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:21:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:21:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:21:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:21:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:21:47 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:21:47 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:21:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:21:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:21:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 21, 48, 1000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 21, 47, 410000)}
2018-08-07 14:21:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:22:34 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:22:34 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:22:34 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:22:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:22:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:22:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:22:34 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:22:34 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:22:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:22:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:22:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 22, 35, 665000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 22, 34, 726000)}
2018-08-07 14:22:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:27:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:27:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:27:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:27:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:27:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:27:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:27:08 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:27:08 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:27:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:27:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:27:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 27, 9, 522000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 27, 8, 821000)}
2018-08-07 14:27:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:32:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:32:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:32:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:32:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:32:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:32:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:32:13 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:32:13 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:32:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:32:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wdzj.com/dangan/search?filter=e1&currentPage=1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\wdzj_spider.py", line 34, in parse
    print(na.split(':')[1])
AttributeError: 'list' object has no attribute 'split'
2018-08-07 14:32:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:32:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 32, 14, 500000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 32, 13, 851000)}
2018-08-07 14:32:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:32:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:32:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:32:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:32:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:32:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:32:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:32:53 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:32:53 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:32:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:32:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wdzj.com/dangan/search?filter=e1&currentPage=1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\wdzj_spider.py", line 34, in parse
    print(na.split()[1])
AttributeError: 'list' object has no attribute 'split'
2018-08-07 14:32:54 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:32:54 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 32, 54, 339000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 32, 53, 712000)}
2018-08-07 14:32:54 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:33:09 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:33:09 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:33:09 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:33:09 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:33:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:33:10 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:33:10 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:33:10 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:33:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:33:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wdzj.com/dangan/search?filter=e1&currentPage=1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\wdzj_spider.py", line 34, in parse
    print(na.split())
AttributeError: 'list' object has no attribute 'split'
2018-08-07 14:33:10 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:33:10 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 33, 10, 712000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/AttributeError': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 33, 10, 128000)}
2018-08-07 14:33:10 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:33:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:33:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:33:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:33:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:33:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:33:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:33:40 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:33:40 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:33:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:33:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:33:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 33, 40, 881000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 33, 40, 390000)}
2018-08-07 14:33:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:33:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:33:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:33:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:33:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:33:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:33:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:33:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:33:56 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:33:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:33:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wdzj.com/dangan/search?filter=e1&currentPage=1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\wdzj_spider.py", line 34, in parse
    print(na.split()[1])
IndexError: list index out of range
2018-08-07 14:33:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:33:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 33, 56, 930000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 33, 56, 307000)}
2018-08-07 14:33:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:34:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:34:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:34:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:34:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:34:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:34:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:34:04 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:34:04 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:34:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:34:05 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:34:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 34, 5, 535000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 34, 4, 673000)}
2018-08-07 14:34:05 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:34:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:34:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:34:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:34:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:34:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:34:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:34:27 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:34:27 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:34:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:34:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:34:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 34, 28, 62000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 34, 27, 432000)}
2018-08-07 14:34:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:34:44 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:34:44 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:34:44 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:34:44 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:34:44 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:34:44 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:34:44 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:34:44 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:34:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:34:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:34:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 34, 45, 692000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 34, 44, 936000)}
2018-08-07 14:34:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:34:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:34:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:34:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:34:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:34:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:34:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:34:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:34:56 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:34:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:34:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.wdzj.com/dangan/search?filter=e1&currentPage=1> (referer: http://search.cnki.net/search.aspx?q=qw:%e9%92%99%e9%92%9b%e7%9f%bf&cluster=all&val=&p=033735)
Traceback (most recent call last):
  File "D:\software\Anaconda\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\software\Anaconda\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\project\pachong\David-master\CnkiSpider1_0\CnkiSpider1_0\spiders\wdzj_spider.py", line 34, in parse
    print(na.split(":")[1])
IndexError: list index out of range
2018-08-07 14:34:56 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:34:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 34, 56, 883000),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/IndexError': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 34, 56, 258000)}
2018-08-07 14:34:56 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:36:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:36:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:36:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:36:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:36:47 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:36:47 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:36:47 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:36:47 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:36:47 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:36:48 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:36:48 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 36, 48, 647000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 36, 47, 950000)}
2018-08-07 14:36:48 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:37:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:37:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:37:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:37:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:37:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:37:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:37:16 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:37:16 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:37:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:37:17 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:37:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 37, 17, 492000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 37, 16, 715000)}
2018-08-07 14:37:17 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:38:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:38:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:38:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:38:12 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:38:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:38:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:38:12 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:38:12 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:38:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:38:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:38:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 38, 12, 900000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 38, 12, 285000)}
2018-08-07 14:38:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:38:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:38:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:38:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:38:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:38:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:38:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:38:32 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:38:32 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:38:32 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:38:33 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:38:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 38, 33, 314000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 38, 32, 523000)}
2018-08-07 14:38:33 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:41:18 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:41:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:41:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:41:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:41:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:41:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:41:18 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:41:18 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:41:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:41:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:41:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 41, 19, 297000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 41, 18, 534000)}
2018-08-07 14:41:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 14:43:35 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 14:43:35 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 14:43:35 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 14:43:35 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 14:43:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 14:43:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 14:43:35 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 14:43:35 [scrapy.core.engine] INFO: Spider opened
2018-08-07 14:43:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 14:43:36 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 14:43:36 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 331,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 21724,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 6, 43, 36, 25000),
 'item_scraped_count': 25,
 'log_count/INFO': 7,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 8, 7, 6, 43, 35, 458000)}
2018-08-07 14:43:36 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 15:01:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 15:01:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 15:01:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 15:01:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 15:01:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 15:01:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 15:01:42 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 15:01:42 [scrapy.core.engine] INFO: Spider opened
2018-08-07 15:01:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 15:01:47 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 15:01:47 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1372,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 84183,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'dupefilter/filtered': 9,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 7, 1, 47, 103200),
 'item_scraped_count': 100,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2018, 8, 7, 7, 1, 42, 803200)}
2018-08-07 15:01:47 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 15:03:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 15:03:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 15:03:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 15:03:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 15:03:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 15:03:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 15:03:56 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 15:03:56 [scrapy.core.engine] INFO: Spider opened
2018-08-07 15:03:56 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 15:04:00 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 15:04:00 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1372,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 84205,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'dupefilter/filtered': 9,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 7, 4, 0, 695200),
 'item_scraped_count': 100,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2018, 8, 7, 7, 3, 56, 825200)}
2018-08-07 15:04:00 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 15:04:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 15:04:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 15:04:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 15:04:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 15:04:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 15:04:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 15:04:23 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 15:04:23 [scrapy.core.engine] INFO: Spider opened
2018-08-07 15:04:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 15:04:27 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 15:04:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1372,
 'downloader/request_count': 4,
 'downloader/request_method_count/GET': 4,
 'downloader/response_bytes': 84205,
 'downloader/response_count': 4,
 'downloader/response_status_count/200': 4,
 'dupefilter/filtered': 9,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 7, 4, 27, 815200),
 'item_scraped_count': 100,
 'log_count/INFO': 7,
 'request_depth_max': 2,
 'response_received_count': 4,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2018, 8, 7, 7, 4, 23, 205200)}
2018-08-07 15:04:27 [scrapy.core.engine] INFO: Spider closed (finished)
2018-08-07 15:05:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: CnkiSpider1_0)
2018-08-07 15:05:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.8, cssselect 1.0.3, parsel 1.5.0, w3lib 1.19.0, Twisted 17.5.0, Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 18.0.0 (OpenSSL 1.0.2o  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-08-07 15:05:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'CnkiSpider1_0', 'DOWNLOAD_DELAY': 1, 'LOG_FILE': 'LOG.text', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'CnkiSpider1_0.spiders', 'SPIDER_MODULES': ['CnkiSpider1_0.spiders']}
2018-08-07 15:05:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-08-07 15:05:51 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-08-07 15:05:51 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-08-07 15:05:51 [scrapy.middleware] INFO: Enabled item pipelines:
['CnkiSpider1_0.pipelines.JsonWithEncodingCnblogsPipeline']
2018-08-07 15:05:51 [scrapy.core.engine] INFO: Spider opened
2018-08-07 15:05:51 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-08-07 15:06:51 [scrapy.extensions.logstats] INFO: Crawled 49 pages (at 49 pages/min), scraped 1208 items (at 1208 items/min)
2018-08-07 15:07:11 [scrapy.core.engine] INFO: Closing spider (finished)
2018-08-07 15:07:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 22943,
 'downloader/request_count': 66,
 'downloader/request_method_count/GET': 66,
 'downloader/response_bytes': 1278590,
 'downloader/response_count': 66,
 'downloader/response_status_count/200': 66,
 'dupefilter/filtered': 4225,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 8, 7, 7, 7, 11, 642200),
 'item_scraped_count': 1633,
 'log_count/INFO': 8,
 'request_depth_max': 2,
 'response_received_count': 66,
 'scheduler/dequeued': 66,
 'scheduler/dequeued/memory': 66,
 'scheduler/enqueued': 66,
 'scheduler/enqueued/memory': 66,
 'start_time': datetime.datetime(2018, 8, 7, 7, 5, 51, 708200)}
2018-08-07 15:07:11 [scrapy.core.engine] INFO: Spider closed (finished)
